{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T06:50:09.157340600Z",
     "start_time": "2024-07-18T06:50:08.734314400Z"
    },
    "executionInfo": {
     "elapsed": 5215,
     "status": "ok",
     "timestamp": 1716270565797,
     "user": {
      "displayName": "Min-Seung Kim",
      "userId": "02665668529052517993"
     },
     "user_tz": -540
    },
    "id": "1syG3FRe5zp5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error, \n",
    "    mean_squared_error, \n",
    "    mean_absolute_percentage_error, \n",
    "    root_mean_squared_error\n",
    ")\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor, plot_importance\n",
    "import lightgbm as lgb\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanAbsoluteError\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "import keras_tuner as kt\n",
    "from keras_tuner import Hyperband\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "from hyperopt.pyll.base import scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T09:12:04.827566300Z",
     "start_time": "2024-07-18T09:12:04.819565900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.9.3'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T06:50:09.172844100Z",
     "start_time": "2024-07-18T06:50:09.158340800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_test_results(y_t, pred):\n",
    "    print(f'[Test results]\\n'\n",
    "          f'MAPE: {round(mean_absolute_percentage_error(y_t, pred), 2)}\\n'\n",
    "          f'MAE: {round(mean_absolute_error(y_t, pred), 2)}\\n'\n",
    "          f'MSE: {round(mean_squared_error(y_t, pred), 2)}\\n'\n",
    "          f'RMSE: {round(root_mean_squared_error(y_t, pred), 2)}\\n')\n",
    "\n",
    "def print_test_results2(y_t, pred):\n",
    "    print(f'[Test results]\\n'\n",
    "          f'MAPE: {round(mean_absolute_percentage_error(y_t, pred), 4)}\\n'\n",
    "          f'MAE: {round(mean_absolute_error(y_t, pred), 4)}\\n'\n",
    "          f'MSE: {\"%.4e\"%mean_squared_error(y_t, pred)}\\n'\n",
    "          f'MSE: {round(mean_squared_error(y_t, pred), 4)}\\n'\n",
    "          f'RMSE: {round(root_mean_squared_error(y_t, pred), 4)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T06:50:52.770390Z",
     "start_time": "2024-07-18T06:50:09.299899700Z"
    },
    "executionInfo": {
     "elapsed": 99485,
     "status": "ok",
     "timestamp": 1716277688237,
     "user": {
      "displayName": "Min-Seung Kim",
      "userId": "02665668529052517993"
     },
     "user_tz": -540
    },
    "id": "D98OzHHq53uo"
   },
   "outputs": [],
   "source": [
    "raw_df = pd.read_excel('Data_평가만료일_특허유지일.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T06:50:52.860895800Z",
     "start_time": "2024-07-18T06:50:52.771389600Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1716277688237,
     "user": {
      "displayName": "Min-Seung Kim",
      "userId": "02665668529052517993"
     },
     "user_tz": -540
    },
    "id": "JAOLvhtu57Vz",
    "outputId": "92f0f00d-5a51-46f5-cd24-95a453799519"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>출원인수</th>\n",
       "      <th>대리인수</th>\n",
       "      <th>패밀리특허수</th>\n",
       "      <th>IPC 수</th>\n",
       "      <th>청구항 수</th>\n",
       "      <th>독립청구항의 비율</th>\n",
       "      <th>출원-등록일까지의 기간(일)</th>\n",
       "      <th>IPC_A</th>\n",
       "      <th>IPC_B</th>\n",
       "      <th>IPC_C</th>\n",
       "      <th>...</th>\n",
       "      <th>IPC활동성 평균(등록)</th>\n",
       "      <th>IPC활동성 비율(등록)</th>\n",
       "      <th>IPC 경쟁정도(등록)</th>\n",
       "      <th>특허 권리이전 횟수</th>\n",
       "      <th>평가-만료일까지의 기간(일)</th>\n",
       "      <th>피인용 수</th>\n",
       "      <th>피인용 특허 지수</th>\n",
       "      <th>TCT 지수</th>\n",
       "      <th>특허 청구항 지수</th>\n",
       "      <th>기술다양성 지수</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1266</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>239.8</td>\n",
       "      <td>0.712842</td>\n",
       "      <td>1770</td>\n",
       "      <td>4</td>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>1.191367</td>\n",
       "      <td>0.386555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>930</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>834.8</td>\n",
       "      <td>0.815712</td>\n",
       "      <td>5438</td>\n",
       "      <td>2</td>\n",
       "      <td>162</td>\n",
       "      <td>15</td>\n",
       "      <td>2.146172</td>\n",
       "      <td>6</td>\n",
       "      <td>1.371265</td>\n",
       "      <td>0.614334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>675.2</td>\n",
       "      <td>0.895016</td>\n",
       "      <td>3988</td>\n",
       "      <td>2</td>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.235829</td>\n",
       "      <td>1.056587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>329</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.485528</td>\n",
       "      <td>1115</td>\n",
       "      <td>2</td>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.455272</td>\n",
       "      <td>0.380000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>775</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1871.2</td>\n",
       "      <td>0.708681</td>\n",
       "      <td>14210</td>\n",
       "      <td>0</td>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.834862</td>\n",
       "      <td>0.733083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235772</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>2629</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2870.2</td>\n",
       "      <td>0.463279</td>\n",
       "      <td>33307</td>\n",
       "      <td>3</td>\n",
       "      <td>-1788</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>1.057376</td>\n",
       "      <td>0.469958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235773</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>2494</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7022.4</td>\n",
       "      <td>0.542538</td>\n",
       "      <td>67836</td>\n",
       "      <td>3</td>\n",
       "      <td>233</td>\n",
       "      <td>3</td>\n",
       "      <td>0.602033</td>\n",
       "      <td>6</td>\n",
       "      <td>1.360796</td>\n",
       "      <td>0.495727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235774</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1288</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>47.4</td>\n",
       "      <td>0.429348</td>\n",
       "      <td>621</td>\n",
       "      <td>0</td>\n",
       "      <td>-497</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.087488</td>\n",
       "      <td>0.534483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235775</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>2228</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>176.8</td>\n",
       "      <td>0.460177</td>\n",
       "      <td>2060</td>\n",
       "      <td>2</td>\n",
       "      <td>-606</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>1.503632</td>\n",
       "      <td>0.512658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235776</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>1838</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>17.2</td>\n",
       "      <td>0.401869</td>\n",
       "      <td>229</td>\n",
       "      <td>5</td>\n",
       "      <td>385</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>1.885714</td>\n",
       "      <td>0.989011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>235777 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        출원인수  대리인수  패밀리특허수  IPC 수  청구항 수  독립청구항의 비율  출원-등록일까지의 기간(일)  IPC_A  \\\n",
       "0          1     1       8      1      6   0.666667             1266      0   \n",
       "1          1     1      16      1     16   0.187500              930      0   \n",
       "2          1     1       1      3      2   0.500000             1001      0   \n",
       "3          1     3       9      1      5   1.000000              329      0   \n",
       "4          1     3       7      1      9   0.333333              775      0   \n",
       "...      ...   ...     ...    ...    ...        ...              ...    ...   \n",
       "235772     1     1      13      1     18   0.111111             2629      0   \n",
       "235773     1     1       8      1     19   0.263158             2494      0   \n",
       "235774     1     1      18      1      1   1.000000             1288      0   \n",
       "235775     1     1      25      1     23   0.173913             2228      0   \n",
       "235776     1     1      20      3     11   0.181818             1838      0   \n",
       "\n",
       "        IPC_B  IPC_C  ...  IPC활동성 평균(등록)  IPC활동성 비율(등록)  IPC 경쟁정도(등록)  \\\n",
       "0           0      0  ...          239.8       0.712842          1770   \n",
       "1           0      0  ...          834.8       0.815712          5438   \n",
       "2           0      0  ...          675.2       0.895016          3988   \n",
       "3           0      1  ...          104.0       0.485528          1115   \n",
       "4           0      0  ...         1871.2       0.708681         14210   \n",
       "...       ...    ...  ...            ...            ...           ...   \n",
       "235772      0      0  ...         2870.2       0.463279         33307   \n",
       "235773      0      0  ...         7022.4       0.542538         67836   \n",
       "235774      0      1  ...           47.4       0.429348           621   \n",
       "235775      0      1  ...          176.8       0.460177          2060   \n",
       "235776      0      0  ...           17.2       0.401869           229   \n",
       "\n",
       "        특허 권리이전 횟수  평가-만료일까지의 기간(일)  피인용 수  피인용 특허 지수  TCT 지수  특허 청구항 지수  \\\n",
       "0                4              162      0   0.000000       7   1.191367   \n",
       "1                2              162     15   2.146172       6   1.371265   \n",
       "2                2              162      0   0.000000       6   0.235829   \n",
       "3                2              162      0   0.000000       8   0.455272   \n",
       "4                0              162      0   0.000000       6   0.834862   \n",
       "...            ...              ...    ...        ...     ...        ...   \n",
       "235772           3            -1788      0   0.000000       6   1.057376   \n",
       "235773           3              233      3   0.602033       6   1.360796   \n",
       "235774           0             -497      0   0.000000       7   0.087488   \n",
       "235775           2             -606      0   0.000000       9   1.503632   \n",
       "235776           5              385      0   0.000000      11   1.885714   \n",
       "\n",
       "        기술다양성 지수  \n",
       "0       0.386555  \n",
       "1       0.614334  \n",
       "2       1.056587  \n",
       "3       0.380000  \n",
       "4       0.733083  \n",
       "...          ...  \n",
       "235772  0.469958  \n",
       "235773  0.495727  \n",
       "235774  0.534483  \n",
       "235775  0.512658  \n",
       "235776  0.989011  \n",
       "\n",
       "[235777 rows x 27 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = raw_df.iloc[:,2:-1]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T06:50:52.924959200Z",
     "start_time": "2024-07-18T06:50:52.861895700Z"
    },
    "executionInfo": {
     "elapsed": 297,
     "status": "ok",
     "timestamp": 1716277754581,
     "user": {
      "displayName": "Min-Seung Kim",
      "userId": "02665668529052517993"
     },
     "user_tz": -540
    },
    "id": "ZUyGe0g86Idl"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train,y_test = train_test_split(df, raw_df.iloc[:,-1], test_size = 0.2, random_state=7)\n",
    "train_cnt = y_train.count()\n",
    "test_cnt = y_test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T06:50:53.044138700Z",
     "start_time": "2024-07-18T06:50:52.906959Z"
    },
    "executionInfo": {
     "elapsed": 441,
     "status": "ok",
     "timestamp": 1716277757753,
     "user": {
      "displayName": "Min-Seung Kim",
      "userId": "02665668529052517993"
     },
     "user_tz": -540
    },
    "id": "8DVDpBEF7HgJ"
   },
   "outputs": [],
   "source": [
    "\n",
    "# scaler = StandardScaler()\n",
    "# scaler = MinMaxScaler()\n",
    "scaler = RobustScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T06:50:53.057138700Z",
     "start_time": "2024-07-18T06:50:53.043138400Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1716277759321,
     "user": {
      "displayName": "Min-Seung Kim",
      "userId": "02665668529052517993"
     },
     "user_tz": -540
    },
    "id": "034ymoLL6J_w",
    "outputId": "4823e94c-009d-45ea-fe34-a99147d5ff9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(188621, 27)\n",
      "(47156, 27)\n",
      "(188621,)\n",
      "(47156,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.3\n",
      "==========================================\n",
      "WARNING:tensorflow:From C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_29588\\4057006721.py:4: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "True\n",
      "==========================================\n",
      "True\n",
      "==========================================\n",
      "/device:GPU:0\n",
      "==========================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 14819614093422308885\n",
       " xla_global_id: -1,\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 10057940992\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 13004242559693112844\n",
       " physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\"\n",
       " xla_global_id: 416903419]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GPU Test\n",
    "print(tf.__version__)\n",
    "print(\"==========================================\")\n",
    "print(tf.test.is_gpu_available())\n",
    "print(\"==========================================\")\n",
    "print(tf.test.is_built_with_cuda())\n",
    "print(\"==========================================\")\n",
    "print(tf.test.gpu_device_name())\n",
    "print(\"==========================================\")\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0-1. RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestRegressor(n_estimators=280, \n",
    "                                 max_depth=30, \n",
    "                                 min_samples_split=2, \n",
    "                                 min_samples_leaf=1)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_pred = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0-2. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBRegressor(n_estimators=290, \n",
    "                             max_depth=14, \n",
    "                             learning_rate=0.03259162240984821, \n",
    "                             subsample=0.7206064233722951, \n",
    "                             colsample_bytree=0.9229737811346409)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "xgb_pred = xgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0-3. DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/200\n",
      "1474/1474 [==============================] - 3s 2ms/step - loss: 1186.1288 - mae: 1186.1288 - val_loss: 962.2440 - val_mae: 962.2440\n",
      "Epoch 69/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 1053.8406 - mae: 1053.8406 - val_loss: 956.8305 - val_mae: 956.8305\n",
      "Epoch 70/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 1046.4242 - mae: 1046.4242 - val_loss: 946.1011 - val_mae: 946.1011\n",
      "Epoch 71/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 1041.5195 - mae: 1041.5195 - val_loss: 954.5012 - val_mae: 954.5012\n",
      "Epoch 72/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 1038.3125 - mae: 1038.3125 - val_loss: 942.5836 - val_mae: 942.5836\n",
      "Epoch 73/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 1038.7908 - mae: 1038.7908 - val_loss: 946.9658 - val_mae: 946.9658\n",
      "Epoch 74/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 1037.0133 - mae: 1037.0133 - val_loss: 942.3601 - val_mae: 942.3601\n",
      "Epoch 75/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 1031.1936 - mae: 1031.1936 - val_loss: 945.9568 - val_mae: 945.9568\n",
      "Epoch 76/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 1029.6316 - mae: 1029.6316 - val_loss: 955.2161 - val_mae: 955.2161\n",
      "Epoch 77/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 1029.1422 - mae: 1029.1422 - val_loss: 940.6333 - val_mae: 940.6333\n",
      "Epoch 78/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 1023.3282 - mae: 1023.3282 - val_loss: 939.2830 - val_mae: 939.2830\n",
      "Epoch 79/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 1018.9963 - mae: 1018.9963 - val_loss: 945.5345 - val_mae: 945.5345\n",
      "Epoch 80/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 1016.9584 - mae: 1016.9584 - val_loss: 935.6511 - val_mae: 935.6511\n",
      "Epoch 81/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 1012.1263 - mae: 1012.1263 - val_loss: 944.2598 - val_mae: 944.2598\n",
      "Epoch 82/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 1011.8463 - mae: 1011.8463 - val_loss: 935.5449 - val_mae: 935.5449\n",
      "Epoch 83/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 1008.3289 - mae: 1008.3289 - val_loss: 936.8967 - val_mae: 936.8967\n",
      "Epoch 84/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 1007.1069 - mae: 1007.1069 - val_loss: 932.1271 - val_mae: 932.1271\n",
      "Epoch 85/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 1004.9975 - mae: 1004.9975 - val_loss: 938.8295 - val_mae: 938.8295\n",
      "Epoch 86/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 1003.5184 - mae: 1003.5184 - val_loss: 935.7153 - val_mae: 935.7153\n",
      "Epoch 87/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 1002.2562 - mae: 1002.2562 - val_loss: 943.9191 - val_mae: 943.9191\n",
      "Epoch 88/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 999.4509 - mae: 999.4509 - val_loss: 950.3373 - val_mae: 950.3373\n",
      "Epoch 89/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 997.5026 - mae: 997.5026 - val_loss: 944.4074 - val_mae: 944.4074\n",
      "Epoch 90/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 994.5403 - mae: 994.5403 - val_loss: 955.6537 - val_mae: 955.6537\n",
      "Epoch 91/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 989.9901 - mae: 989.9901 - val_loss: 970.8769 - val_mae: 970.8769\n",
      "Epoch 92/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 986.2256 - mae: 986.2256 - val_loss: 939.2281 - val_mae: 939.2281\n",
      "Epoch 93/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 983.7538 - mae: 983.7538 - val_loss: 956.1302 - val_mae: 956.1302\n",
      "Epoch 94/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 980.7493 - mae: 980.7493 - val_loss: 970.0451 - val_mae: 970.0451\n",
      "Epoch 95/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 978.3410 - mae: 978.3410 - val_loss: 957.7521 - val_mae: 957.7521\n",
      "Epoch 96/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 977.4860 - mae: 977.4860 - val_loss: 973.4445 - val_mae: 973.4445\n",
      "Epoch 97/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 976.7101 - mae: 976.7101 - val_loss: 952.9603 - val_mae: 952.9603\n",
      "Epoch 98/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 975.5894 - mae: 975.5894 - val_loss: 952.6326 - val_mae: 952.6326\n",
      "Epoch 99/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 972.9478 - mae: 972.9478 - val_loss: 956.1284 - val_mae: 956.1284\n",
      "Epoch 100/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 972.1147 - mae: 972.1147 - val_loss: 953.6609 - val_mae: 953.6609\n",
      "Epoch 101/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 971.0009 - mae: 971.0009 - val_loss: 937.1236 - val_mae: 937.1236\n",
      "Epoch 102/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 969.7874 - mae: 969.7874 - val_loss: 931.1164 - val_mae: 931.1164\n",
      "Epoch 103/200\n",
      "1474/1474 [==============================] - 2s 1ms/step - loss: 968.5714 - mae: 968.5714 - val_loss: 966.5438 - val_mae: 966.5438\n",
      "Epoch 104/200\n",
      "1474/1474 [==============================] - 2s 1ms/step - loss: 967.8354 - mae: 967.8354 - val_loss: 930.7176 - val_mae: 930.7176\n",
      "Epoch 105/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 965.3297 - mae: 965.3297 - val_loss: 940.1147 - val_mae: 940.1147\n",
      "Epoch 106/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 964.3591 - mae: 964.3591 - val_loss: 917.7336 - val_mae: 917.7336\n",
      "Epoch 107/200\n",
      "1474/1474 [==============================] - 2s 1ms/step - loss: 960.9210 - mae: 960.9210 - val_loss: 949.9390 - val_mae: 949.9390\n",
      "Epoch 108/200\n",
      "1474/1474 [==============================] - 2s 1ms/step - loss: 957.5319 - mae: 957.5319 - val_loss: 967.6510 - val_mae: 967.6510\n",
      "Epoch 109/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 956.9339 - mae: 956.9339 - val_loss: 922.0366 - val_mae: 922.0366\n",
      "Epoch 110/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 958.2730 - mae: 958.2730 - val_loss: 950.1396 - val_mae: 950.1396\n",
      "Epoch 111/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 955.5408 - mae: 955.5408 - val_loss: 954.6163 - val_mae: 954.6163\n",
      "Epoch 112/200\n",
      "1474/1474 [==============================] - 2s 1ms/step - loss: 953.8268 - mae: 953.8268 - val_loss: 930.8829 - val_mae: 930.8829\n",
      "Epoch 113/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 950.9391 - mae: 950.9391 - val_loss: 931.6491 - val_mae: 931.6491\n",
      "Epoch 114/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 947.6042 - mae: 947.6042 - val_loss: 920.1331 - val_mae: 920.1331\n",
      "Epoch 115/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 946.0227 - mae: 946.0227 - val_loss: 928.9323 - val_mae: 928.9323\n",
      "Epoch 116/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 945.6265 - mae: 945.6265 - val_loss: 917.6328 - val_mae: 917.6328\n",
      "Epoch 117/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 942.5792 - mae: 942.5792 - val_loss: 917.9362 - val_mae: 917.9362\n",
      "Epoch 118/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 942.7935 - mae: 942.7935 - val_loss: 901.6346 - val_mae: 901.6346\n",
      "Epoch 119/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 941.9720 - mae: 941.9720 - val_loss: 901.0920 - val_mae: 901.0920\n",
      "Epoch 120/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 938.6047 - mae: 938.6047 - val_loss: 904.3219 - val_mae: 904.3219\n",
      "Epoch 121/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 936.3285 - mae: 936.3285 - val_loss: 895.2028 - val_mae: 895.2028\n",
      "Epoch 122/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 937.2445 - mae: 937.2445 - val_loss: 907.4283 - val_mae: 907.4283\n",
      "Epoch 123/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 933.7117 - mae: 933.7117 - val_loss: 907.0406 - val_mae: 907.0406\n",
      "Epoch 124/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 933.9508 - mae: 933.9508 - val_loss: 901.9325 - val_mae: 901.9325\n",
      "Epoch 125/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 932.8163 - mae: 932.8163 - val_loss: 896.6759 - val_mae: 896.6759\n",
      "Epoch 126/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 933.0290 - mae: 933.0290 - val_loss: 891.3780 - val_mae: 891.3780\n",
      "Epoch 127/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 931.8474 - mae: 931.8474 - val_loss: 904.7290 - val_mae: 904.7290\n",
      "Epoch 128/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 932.9168 - mae: 932.9168 - val_loss: 903.3854 - val_mae: 903.3854\n",
      "Epoch 129/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 932.0593 - mae: 932.0593 - val_loss: 892.0146 - val_mae: 892.0146\n",
      "Epoch 130/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 928.6790 - mae: 928.6790 - val_loss: 895.6894 - val_mae: 895.6894\n",
      "Epoch 131/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 929.6806 - mae: 929.6806 - val_loss: 897.1166 - val_mae: 897.1166\n",
      "Epoch 132/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 928.8336 - mae: 928.8336 - val_loss: 895.6868 - val_mae: 895.6868\n",
      "Epoch 133/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 929.4961 - mae: 929.4961 - val_loss: 896.4792 - val_mae: 896.4792\n",
      "Epoch 134/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 928.1746 - mae: 928.1746 - val_loss: 894.6655 - val_mae: 894.6655\n",
      "Epoch 135/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 927.9142 - mae: 927.9142 - val_loss: 891.2118 - val_mae: 891.2118\n",
      "Epoch 136/200\n",
      "1474/1474 [==============================] - 2s 1ms/step - loss: 926.8903 - mae: 926.8903 - val_loss: 893.0028 - val_mae: 893.0028\n",
      "Epoch 137/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 927.5593 - mae: 927.5593 - val_loss: 897.6453 - val_mae: 897.6453\n",
      "Epoch 138/200\n",
      "1474/1474 [==============================] - 2s 1ms/step - loss: 925.4061 - mae: 925.4061 - val_loss: 894.6974 - val_mae: 894.6974\n",
      "Epoch 139/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 926.3892 - mae: 926.3892 - val_loss: 896.5240 - val_mae: 896.5240\n",
      "Epoch 140/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 925.8705 - mae: 925.8705 - val_loss: 889.1957 - val_mae: 889.1957\n",
      "Epoch 141/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 925.7217 - mae: 925.7217 - val_loss: 897.9030 - val_mae: 897.9030\n",
      "Epoch 142/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 923.2983 - mae: 923.2983 - val_loss: 891.6539 - val_mae: 891.6539\n",
      "Epoch 143/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 924.1978 - mae: 924.1978 - val_loss: 887.8699 - val_mae: 887.8699\n",
      "Epoch 144/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 923.4300 - mae: 923.4300 - val_loss: 891.1212 - val_mae: 891.1212\n",
      "Epoch 145/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 922.8748 - mae: 922.8748 - val_loss: 882.6126 - val_mae: 882.6126\n",
      "Epoch 146/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 923.8731 - mae: 923.8731 - val_loss: 894.0576 - val_mae: 894.0576\n",
      "Epoch 147/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 922.3547 - mae: 922.3547 - val_loss: 884.1854 - val_mae: 884.1854\n",
      "Epoch 148/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 922.2623 - mae: 922.2623 - val_loss: 884.5900 - val_mae: 884.5900\n",
      "Epoch 149/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 923.7865 - mae: 923.7865 - val_loss: 891.4933 - val_mae: 891.4933\n",
      "Epoch 150/200\n",
      "1474/1474 [==============================] - 2s 1ms/step - loss: 921.7176 - mae: 921.7176 - val_loss: 882.4892 - val_mae: 882.4892\n",
      "Epoch 151/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 921.9041 - mae: 921.9041 - val_loss: 889.2489 - val_mae: 889.2489\n",
      "Epoch 152/200\n",
      "1474/1474 [==============================] - 2s 1ms/step - loss: 921.4805 - mae: 921.4805 - val_loss: 886.0925 - val_mae: 886.0925\n",
      "Epoch 153/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 921.2952 - mae: 921.2952 - val_loss: 886.7664 - val_mae: 886.7664\n",
      "Epoch 154/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 919.8480 - mae: 919.8480 - val_loss: 894.4050 - val_mae: 894.4050\n",
      "Epoch 155/200\n",
      "1474/1474 [==============================] - 3s 2ms/step - loss: 920.5217 - mae: 920.5217 - val_loss: 889.1339 - val_mae: 889.1339\n",
      "Epoch 156/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 918.1625 - mae: 918.1625 - val_loss: 897.4646 - val_mae: 897.4646\n",
      "Epoch 157/200\n",
      "1474/1474 [==============================] - 3s 2ms/step - loss: 919.1885 - mae: 919.1885 - val_loss: 887.3464 - val_mae: 887.3464\n",
      "Epoch 158/200\n",
      "1474/1474 [==============================] - 3s 2ms/step - loss: 918.6840 - mae: 918.6840 - val_loss: 880.9745 - val_mae: 880.9745\n",
      "Epoch 159/200\n",
      "1474/1474 [==============================] - 3s 2ms/step - loss: 919.3616 - mae: 919.3616 - val_loss: 891.6020 - val_mae: 891.6020\n",
      "Epoch 160/200\n",
      "1474/1474 [==============================] - 3s 2ms/step - loss: 919.6785 - mae: 919.6785 - val_loss: 884.9963 - val_mae: 884.9963\n",
      "Epoch 161/200\n",
      "1474/1474 [==============================] - 3s 2ms/step - loss: 919.0626 - mae: 919.0626 - val_loss: 884.8340 - val_mae: 884.8340\n",
      "Epoch 162/200\n",
      "1474/1474 [==============================] - 3s 2ms/step - loss: 919.1912 - mae: 919.1912 - val_loss: 881.8691 - val_mae: 881.8691\n",
      "Epoch 163/200\n",
      "1474/1474 [==============================] - 2s 2ms/step - loss: 917.2193 - mae: 917.2193 - val_loss: 892.1337 - val_mae: 892.1337\n",
      "Epoch 164/200\n",
      "1474/1474 [==============================] - 3s 2ms/step - loss: 918.5776 - mae: 918.5776 - val_loss: 886.4695 - val_mae: 886.4695\n",
      "Epoch 165/200\n",
      "1474/1474 [==============================] - 3s 2ms/step - loss: 916.5619 - mae: 916.5619 - val_loss: 878.1309 - val_mae: 878.1309\n",
      "Epoch 166/200\n",
      "1474/1474 [==============================] - 3s 2ms/step - loss: 917.4938 - mae: 917.4938 - val_loss: 889.2118 - val_mae: 889.2118\n",
      "Epoch 167/200\n",
      "1474/1474 [==============================] - 3s 2ms/step - loss: 915.7278 - mae: 915.7278 - val_loss: 884.8814 - val_mae: 884.8814\n",
      "Epoch 168/200\n",
      "1474/1474 [==============================] - 3s 2ms/step - loss: 917.7858 - mae: 917.7858 - val_loss: 884.8986 - val_mae: 884.8986\n",
      "Epoch 169/200\n",
      "1474/1474 [==============================] - 3s 2ms/step - loss: 916.4781 - mae: 916.4781 - val_loss: 883.2496 - val_mae: 883.2496\n",
      "Epoch 170/200\n",
      "1474/1474 [==============================] - 3s 2ms/step - loss: 915.5389 - mae: 915.5389 - val_loss: 878.2054 - val_mae: 878.2054\n",
      "Epoch 171/200\n",
      "1474/1474 [==============================] - 3s 2ms/step - loss: 916.5146 - mae: 916.5146 - val_loss: 878.6613 - val_mae: 878.6613\n",
      "Epoch 172/200\n",
      "1474/1474 [==============================] - 3s 2ms/step - loss: 915.3917 - mae: 915.3917 - val_loss: 882.6923 - val_mae: 882.6923\n",
      "Epoch 173/200\n",
      "1474/1474 [==============================] - 3s 2ms/step - loss: 915.8414 - mae: 915.8414 - val_loss: 886.9994 - val_mae: 886.9994\n",
      "Epoch 174/200\n",
      "1474/1474 [==============================] - 3s 2ms/step - loss: 914.7894 - mae: 914.7894 - val_loss: 880.7448 - val_mae: 880.7448\n",
      "Epoch 175/200\n",
      "1474/1474 [==============================] - 3s 2ms/step - loss: 914.4509 - mae: 914.4509 - val_loss: 877.4415 - val_mae: 877.4415\n",
      "Epoch 176/200\n",
      "1474/1474 [==============================] - 3s 2ms/step - loss: 915.6953 - mae: 915.6953 - val_loss: 891.6072 - val_mae: 891.6072\n",
      "Epoch 177/200\n",
      "1474/1474 [==============================] - 3s 2ms/step - loss: 914.7503 - mae: 914.7503 - val_loss: 881.6768 - val_mae: 881.6768\n",
      "Epoch 178/200\n",
      "1474/1474 [==============================] - 3s 2ms/step - loss: 915.3647 - mae: 915.3647 - val_loss: 880.3123 - val_mae: 880.3123\n",
      "Epoch 179/200\n",
      "1474/1474 [==============================] - 3s 2ms/step - loss: 915.4528 - mae: 915.4528 - val_loss: 887.5925 - val_mae: 887.5925\n",
      "Epoch 180/200\n",
      "1474/1474 [==============================] - 3s 2ms/step - loss: 916.2062 - mae: 916.2062 - val_loss: 899.0128 - val_mae: 899.0128\n",
      "Epoch 181/200\n",
      "1474/1474 [==============================] - 3s 2ms/step - loss: 915.4647 - mae: 915.4647 - val_loss: 882.2705 - val_mae: 882.2705\n",
      "Epoch 182/200\n",
      "1474/1474 [==============================] - 3s 2ms/step - loss: 914.0275 - mae: 914.0275 - val_loss: 887.4649 - val_mae: 887.4649\n",
      "Epoch 183/200\n",
      "1474/1474 [==============================] - 3s 2ms/step - loss: 912.4792 - mae: 912.4792 - val_loss: 882.5120 - val_mae: 882.5120\n",
      "Epoch 184/200\n",
      "1474/1474 [==============================] - 3s 2ms/step - loss: 913.5444 - mae: 913.5444 - val_loss: 889.8453 - val_mae: 889.8453\n",
      "Epoch 185/200\n",
      "1474/1474 [==============================] - 3s 2ms/step - loss: 916.0809 - mae: 916.0809 - val_loss: 882.6345 - val_mae: 882.6345\n",
      "Epoch 186/200\n",
      "1474/1474 [==============================] - 3s 2ms/step - loss: 913.6201 - mae: 913.6201 - val_loss: 881.4367 - val_mae: 881.4367\n",
      "Epoch 187/200\n",
      "1474/1474 [==============================] - 3s 2ms/step - loss: 914.2002 - mae: 914.2002 - val_loss: 883.0522 - val_mae: 883.0522\n",
      "Epoch 188/200\n",
      "1474/1474 [==============================] - 3s 2ms/step - loss: 913.3014 - mae: 913.3014 - val_loss: 882.0455 - val_mae: 882.0455\n",
      "Epoch 189/200\n",
      "1474/1474 [==============================] - 3s 2ms/step - loss: 911.8290 - mae: 911.8290 - val_loss: 888.1987 - val_mae: 888.1987\n",
      "Epoch 190/200\n",
      "1474/1474 [==============================] - 3s 2ms/step - loss: 913.3038 - mae: 913.3038 - val_loss: 880.5819 - val_mae: 880.5819\n",
      "Epoch 191/200\n",
      "1474/1474 [==============================] - 3s 2ms/step - loss: 912.9034 - mae: 912.9034 - val_loss: 884.4542 - val_mae: 884.4542\n",
      "Epoch 192/200\n",
      "1474/1474 [==============================] - 3s 2ms/step - loss: 911.8701 - mae: 911.8701 - val_loss: 880.5948 - val_mae: 880.5948\n",
      "Epoch 193/200\n",
      "1474/1474 [==============================] - 3s 2ms/step - loss: 912.6973 - mae: 912.6973 - val_loss: 884.8657 - val_mae: 884.8657\n",
      "Epoch 194/200\n",
      "1474/1474 [==============================] - 3s 2ms/step - loss: 914.5121 - mae: 914.5121 - val_loss: 884.4964 - val_mae: 884.4964\n",
      "Epoch 195/200\n",
      "1474/1474 [==============================] - 3s 2ms/step - loss: 912.8984 - mae: 912.8984 - val_loss: 883.4531 - val_mae: 883.4531\n",
      "Epoch 196/200\n",
      "1474/1474 [==============================] - 3s 2ms/step - loss: 911.7689 - mae: 911.7689 - val_loss: 883.5901 - val_mae: 883.5901\n",
      "Epoch 197/200\n",
      "1474/1474 [==============================] - 3s 2ms/step - loss: 912.4764 - mae: 912.4764 - val_loss: 880.8848 - val_mae: 880.8848\n",
      "Epoch 198/200\n",
      "1474/1474 [==============================] - 3s 2ms/step - loss: 911.8294 - mae: 911.8294 - val_loss: 881.9950 - val_mae: 881.9950\n",
      "Epoch 199/200\n",
      "1474/1474 [==============================] - 3s 2ms/step - loss: 913.6158 - mae: 913.6158 - val_loss: 889.5903 - val_mae: 889.5903\n",
      "Epoch 200/200\n",
      "1474/1474 [==============================] - 3s 2ms/step - loss: 911.7507 - mae: 911.7507 - val_loss: 876.3472 - val_mae: 876.3472\n",
      "1474/1474 [==============================] - 1s 582us/step\n"
     ]
    }
   ],
   "source": [
    "units_1 = 128\n",
    "dropout_1 = 0.3\n",
    "units_2 = 96\n",
    "dropout_2 = 0.2\n",
    "units_3 = 56\n",
    "dropout_3 = 0.5\n",
    "units_4 = 24\n",
    "dropout_4 = 0.2\n",
    "learning_rate = 0.0012536297097257307\n",
    "epochs = 200\n",
    "initial_epoch = 67\n",
    "\n",
    "# 모델 정의\n",
    "def create_dnn_model():\n",
    "    model = Sequential([\n",
    "        Dense(units_1, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "        Dropout(dropout_1),\n",
    "        Dense(units_2, activation='relu'),\n",
    "        Dropout(dropout_2),\n",
    "        Dense(units_3, activation='relu'),\n",
    "        Dropout(dropout_3),\n",
    "        Dense(units_4, activation='relu'),\n",
    "        Dropout(dropout_4),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# 모델 생성\n",
    "dnn_model = create_dnn_model()\n",
    "\n",
    "# 옵티마이저 및 손실 함수 설정\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "dnn_model.compile(optimizer=optimizer, loss='mae', metrics=['mae'])\n",
    "\n",
    "# 모델 학습\n",
    "history = dnn_model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=epochs,\n",
    "    initial_epoch=initial_epoch,\n",
    "    batch_size=128\n",
    ")\n",
    "\n",
    "dnn_pred = dnn_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Stacking Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test to df\n",
    "df_y_test = y_test.reset_index(drop=True).to_frame()\n",
    "df_y_test\n",
    "\n",
    "# pred result to df\n",
    "df_rf_predict = pd.DataFrame(rf_pred)\n",
    "df_xgb_predict = pd.DataFrame(xgb_pred)\n",
    "df_dnn_predict = pd.DataFrame(dnn_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-1. No K-Fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47156, 2) <class 'pandas.core.frame.DataFrame'>\n",
      "(47156,) <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "df_concat_0 = pd.concat([df_rf_predict, df_dnn_predict, df_y_test], axis=1)\n",
    "df_concat_0.columns = ['RF', 'DNN', 'True']\n",
    "\n",
    "X0 = df_concat_0[['RF', 'DNN']]\n",
    "y0 = df_concat_0['True']\n",
    "\n",
    "print(X0.shape, type(X0))\n",
    "print(y0.shape, type(y0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train0, X_test0, y_train0, y_test0 = train_test_split(X0, y0, test_size=0.2, random_state=7)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train0 = scaler.fit_transform(X_train0)\n",
    "X_test0 = scaler.transform(X_test0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "295/295 [==============================] - 1s 2ms/step - loss: 1828.2286 - mae: 1828.2286 - val_loss: 955.7838 - val_mae: 955.7838\n",
      "Epoch 2/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 911.1678 - mae: 911.1678 - val_loss: 867.5570 - val_mae: 867.5570\n",
      "Epoch 3/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 888.8002 - mae: 888.8002 - val_loss: 861.1876 - val_mae: 861.1876\n",
      "Epoch 4/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 886.2305 - mae: 886.2305 - val_loss: 859.9473 - val_mae: 859.9473\n",
      "Epoch 5/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 886.2003 - mae: 886.2003 - val_loss: 862.2205 - val_mae: 862.2205\n",
      "Epoch 6/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 884.3283 - mae: 884.3283 - val_loss: 858.7069 - val_mae: 858.7069\n",
      "Epoch 7/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 886.7310 - mae: 886.7310 - val_loss: 858.3950 - val_mae: 858.3950\n",
      "Epoch 8/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 886.6464 - mae: 886.6464 - val_loss: 858.5643 - val_mae: 858.5643\n",
      "Epoch 9/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 882.5579 - mae: 882.5579 - val_loss: 860.9787 - val_mae: 860.9787\n",
      "Epoch 10/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 883.0125 - mae: 883.0125 - val_loss: 857.9466 - val_mae: 857.9466\n",
      "Epoch 11/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 885.0306 - mae: 885.0306 - val_loss: 863.0315 - val_mae: 863.0315\n",
      "Epoch 12/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 887.2642 - mae: 887.2642 - val_loss: 863.3151 - val_mae: 863.3151\n",
      "Epoch 13/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 885.1996 - mae: 885.1996 - val_loss: 864.1520 - val_mae: 864.1520\n",
      "Epoch 14/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 884.3604 - mae: 884.3604 - val_loss: 858.9700 - val_mae: 858.9700\n",
      "Epoch 15/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 884.0942 - mae: 884.0942 - val_loss: 861.2482 - val_mae: 861.2482\n",
      "Epoch 16/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 882.8211 - mae: 882.8211 - val_loss: 856.3919 - val_mae: 856.3919\n",
      "Epoch 17/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 882.7102 - mae: 882.7102 - val_loss: 858.4454 - val_mae: 858.4454\n",
      "Epoch 18/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 884.3705 - mae: 884.3705 - val_loss: 856.6436 - val_mae: 856.6436\n",
      "Epoch 19/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 882.3922 - mae: 882.3922 - val_loss: 861.6002 - val_mae: 861.6002\n",
      "Epoch 20/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 882.5207 - mae: 882.5207 - val_loss: 859.4095 - val_mae: 859.4095\n",
      "Epoch 21/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 885.4692 - mae: 885.4692 - val_loss: 858.8173 - val_mae: 858.8173\n",
      "Epoch 22/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 884.1231 - mae: 884.1231 - val_loss: 862.1180 - val_mae: 862.1180\n",
      "Epoch 23/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 884.8259 - mae: 884.8259 - val_loss: 858.8633 - val_mae: 858.8633\n",
      "Epoch 24/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 885.9284 - mae: 885.9284 - val_loss: 857.3367 - val_mae: 857.3367\n",
      "Epoch 25/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 883.5589 - mae: 883.5589 - val_loss: 857.9562 - val_mae: 857.9562\n",
      "Epoch 26/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 882.3753 - mae: 882.3753 - val_loss: 859.3978 - val_mae: 859.3978\n",
      "Epoch 27/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 883.8996 - mae: 883.8996 - val_loss: 862.5630 - val_mae: 862.5630\n",
      "Epoch 28/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 881.2827 - mae: 881.2827 - val_loss: 860.0954 - val_mae: 860.0954\n",
      "Epoch 29/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 882.2727 - mae: 882.2727 - val_loss: 858.6042 - val_mae: 858.6042\n",
      "Epoch 30/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 885.1185 - mae: 885.1185 - val_loss: 856.8318 - val_mae: 856.8318\n",
      "Epoch 31/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 882.6421 - mae: 882.6421 - val_loss: 855.7961 - val_mae: 855.7961\n",
      "Epoch 32/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 883.6946 - mae: 883.6946 - val_loss: 858.9656 - val_mae: 858.9656\n",
      "Epoch 33/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 882.8924 - mae: 882.8924 - val_loss: 863.4474 - val_mae: 863.4474\n",
      "Epoch 34/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 882.4304 - mae: 882.4304 - val_loss: 860.5253 - val_mae: 860.5253\n",
      "Epoch 35/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 883.8840 - mae: 883.8840 - val_loss: 857.0255 - val_mae: 857.0255\n",
      "Epoch 36/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 883.1650 - mae: 883.1650 - val_loss: 858.5482 - val_mae: 858.5482\n",
      "Epoch 37/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 882.7324 - mae: 882.7324 - val_loss: 859.8966 - val_mae: 859.8966\n",
      "Epoch 38/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 882.0829 - mae: 882.0829 - val_loss: 856.2916 - val_mae: 856.2916\n",
      "Epoch 39/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 879.9414 - mae: 879.9414 - val_loss: 855.9449 - val_mae: 855.9449\n",
      "Epoch 40/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 882.3045 - mae: 882.3045 - val_loss: 858.5737 - val_mae: 858.5737\n",
      "Epoch 41/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 880.4356 - mae: 880.4356 - val_loss: 860.7468 - val_mae: 860.7468\n",
      "Epoch 42/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 879.4973 - mae: 879.4973 - val_loss: 860.2835 - val_mae: 860.2835\n",
      "Epoch 43/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 882.2097 - mae: 882.2097 - val_loss: 856.5588 - val_mae: 856.5588\n",
      "Epoch 44/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 881.0996 - mae: 881.0996 - val_loss: 860.2183 - val_mae: 860.2183\n",
      "Epoch 45/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 883.6141 - mae: 883.6141 - val_loss: 857.6704 - val_mae: 857.6704\n",
      "Epoch 46/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 879.9895 - mae: 879.9895 - val_loss: 856.0731 - val_mae: 856.0731\n",
      "Epoch 47/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 883.7888 - mae: 883.7888 - val_loss: 856.4379 - val_mae: 856.4379\n",
      "Epoch 48/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 882.5622 - mae: 882.5622 - val_loss: 854.5198 - val_mae: 854.5198\n",
      "Epoch 49/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 880.7255 - mae: 880.7255 - val_loss: 864.5518 - val_mae: 864.5518\n",
      "Epoch 50/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 879.6768 - mae: 879.6768 - val_loss: 853.9109 - val_mae: 853.9109\n",
      "Epoch 51/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 878.7150 - mae: 878.7150 - val_loss: 857.1249 - val_mae: 857.1249\n",
      "Epoch 52/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 881.2976 - mae: 881.2976 - val_loss: 858.5281 - val_mae: 858.5281\n",
      "Epoch 53/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 881.7784 - mae: 881.7784 - val_loss: 852.9889 - val_mae: 852.9889\n",
      "Epoch 54/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 880.7136 - mae: 880.7136 - val_loss: 858.8797 - val_mae: 858.8797\n",
      "Epoch 55/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 880.0964 - mae: 880.0964 - val_loss: 852.7458 - val_mae: 852.7458\n",
      "Epoch 56/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 879.1868 - mae: 879.1868 - val_loss: 853.6235 - val_mae: 853.6235\n",
      "Epoch 57/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 879.0505 - mae: 879.0505 - val_loss: 857.0795 - val_mae: 857.0795\n",
      "Epoch 58/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 880.4448 - mae: 880.4448 - val_loss: 852.7286 - val_mae: 852.7286\n",
      "Epoch 59/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 878.9091 - mae: 878.9091 - val_loss: 856.1183 - val_mae: 856.1183\n",
      "Epoch 60/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 880.7466 - mae: 880.7466 - val_loss: 854.3339 - val_mae: 854.3339\n",
      "Epoch 61/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 877.2100 - mae: 877.2100 - val_loss: 853.3206 - val_mae: 853.3206\n",
      "Epoch 62/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 880.4160 - mae: 880.4160 - val_loss: 859.1700 - val_mae: 859.1700\n",
      "Epoch 63/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 879.5630 - mae: 879.5630 - val_loss: 852.3938 - val_mae: 852.3938\n",
      "Epoch 64/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 878.7290 - mae: 878.7290 - val_loss: 853.2706 - val_mae: 853.2706\n",
      "Epoch 65/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 877.9637 - mae: 877.9637 - val_loss: 854.2903 - val_mae: 854.2903\n",
      "Epoch 66/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 876.9465 - mae: 876.9465 - val_loss: 857.2409 - val_mae: 857.2409\n",
      "Epoch 67/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 878.3214 - mae: 878.3214 - val_loss: 853.0985 - val_mae: 853.0985\n",
      "Epoch 68/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 879.8344 - mae: 879.8344 - val_loss: 852.5593 - val_mae: 852.5593\n",
      "Epoch 69/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 878.5685 - mae: 878.5685 - val_loss: 853.7224 - val_mae: 853.7224\n",
      "Epoch 70/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 878.6144 - mae: 878.6144 - val_loss: 852.8927 - val_mae: 852.8927\n",
      "Epoch 71/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 877.6450 - mae: 877.6450 - val_loss: 852.1198 - val_mae: 852.1198\n",
      "Epoch 72/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 877.4480 - mae: 877.4480 - val_loss: 853.4838 - val_mae: 853.4838\n",
      "Epoch 73/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 878.5870 - mae: 878.5870 - val_loss: 850.9741 - val_mae: 850.9741\n",
      "Epoch 74/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 878.2906 - mae: 878.2906 - val_loss: 852.7101 - val_mae: 852.7101\n",
      "Epoch 75/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 876.6808 - mae: 876.6808 - val_loss: 852.7419 - val_mae: 852.7419\n",
      "Epoch 76/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 876.4003 - mae: 876.4003 - val_loss: 851.1157 - val_mae: 851.1157\n",
      "Epoch 77/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 878.0630 - mae: 878.0630 - val_loss: 853.6060 - val_mae: 853.6060\n",
      "Epoch 78/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 877.5417 - mae: 877.5417 - val_loss: 851.8053 - val_mae: 851.8053\n",
      "Epoch 79/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 875.2344 - mae: 875.2344 - val_loss: 855.1502 - val_mae: 855.1502\n",
      "Epoch 80/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 877.1240 - mae: 877.1240 - val_loss: 851.0448 - val_mae: 851.0448\n",
      "Epoch 81/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 878.3446 - mae: 878.3446 - val_loss: 852.5757 - val_mae: 852.5757\n",
      "Epoch 82/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 878.2644 - mae: 878.2644 - val_loss: 851.2095 - val_mae: 851.2095\n",
      "Epoch 83/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 876.2706 - mae: 876.2706 - val_loss: 852.5831 - val_mae: 852.5831\n",
      "Epoch 84/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 878.5922 - mae: 878.5922 - val_loss: 852.1796 - val_mae: 852.1796\n",
      "Epoch 85/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 877.9264 - mae: 877.9264 - val_loss: 851.7556 - val_mae: 851.7556\n",
      "Epoch 86/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 878.0818 - mae: 878.0818 - val_loss: 852.7421 - val_mae: 852.7421\n",
      "Epoch 87/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 877.6343 - mae: 877.6343 - val_loss: 853.9198 - val_mae: 853.9198\n",
      "Epoch 88/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 878.3210 - mae: 878.3210 - val_loss: 858.4473 - val_mae: 858.4473\n",
      "Epoch 89/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 876.0196 - mae: 876.0196 - val_loss: 853.6815 - val_mae: 853.6815\n",
      "Epoch 90/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 876.3502 - mae: 876.3502 - val_loss: 852.2062 - val_mae: 852.2062\n",
      "Epoch 91/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 877.4448 - mae: 877.4448 - val_loss: 851.3550 - val_mae: 851.3550\n",
      "Epoch 92/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 876.8070 - mae: 876.8070 - val_loss: 853.1699 - val_mae: 853.1699\n",
      "Epoch 93/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 877.2695 - mae: 877.2695 - val_loss: 854.9002 - val_mae: 854.9002\n",
      "Epoch 94/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 875.7133 - mae: 875.7133 - val_loss: 856.2692 - val_mae: 856.2692\n",
      "Epoch 95/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 876.8408 - mae: 876.8408 - val_loss: 854.3906 - val_mae: 854.3906\n",
      "Epoch 96/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 877.1322 - mae: 877.1322 - val_loss: 853.1570 - val_mae: 853.1570\n",
      "Epoch 97/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 874.7990 - mae: 874.7990 - val_loss: 851.3773 - val_mae: 851.3773\n",
      "Epoch 98/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 877.5960 - mae: 877.5960 - val_loss: 855.7341 - val_mae: 855.7341\n",
      "Epoch 99/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 875.2047 - mae: 875.2047 - val_loss: 852.1984 - val_mae: 852.1984\n",
      "Epoch 100/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 877.6445 - mae: 877.6445 - val_loss: 851.6901 - val_mae: 851.6901\n",
      "Epoch 101/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 876.2556 - mae: 876.2556 - val_loss: 851.9502 - val_mae: 851.9502\n",
      "Epoch 102/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 874.2252 - mae: 874.2252 - val_loss: 851.3937 - val_mae: 851.3937\n",
      "Epoch 103/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 876.5766 - mae: 876.5766 - val_loss: 854.7332 - val_mae: 854.7332\n",
      "Epoch 104/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 876.3327 - mae: 876.3327 - val_loss: 851.3450 - val_mae: 851.3450\n",
      "Epoch 105/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 875.2476 - mae: 875.2476 - val_loss: 852.1017 - val_mae: 852.1017\n",
      "Epoch 106/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 874.6052 - mae: 874.6052 - val_loss: 851.9828 - val_mae: 851.9828\n",
      "Epoch 107/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 874.5167 - mae: 874.5167 - val_loss: 850.7646 - val_mae: 850.7646\n",
      "Epoch 108/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 874.5971 - mae: 874.5971 - val_loss: 851.9471 - val_mae: 851.9471\n",
      "Epoch 109/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 875.3268 - mae: 875.3268 - val_loss: 858.7183 - val_mae: 858.7183\n",
      "Epoch 110/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 874.4070 - mae: 874.4070 - val_loss: 851.5663 - val_mae: 851.5663\n",
      "Epoch 111/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 872.9428 - mae: 872.9428 - val_loss: 855.7916 - val_mae: 855.7916\n",
      "Epoch 112/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 875.7194 - mae: 875.7194 - val_loss: 851.0822 - val_mae: 851.0822\n",
      "Epoch 113/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 875.1199 - mae: 875.1199 - val_loss: 855.9963 - val_mae: 855.9963\n",
      "Epoch 114/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 876.3728 - mae: 876.3728 - val_loss: 856.6485 - val_mae: 856.6485\n",
      "Epoch 115/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 873.4966 - mae: 873.4966 - val_loss: 852.4869 - val_mae: 852.4869\n",
      "Epoch 116/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 875.2271 - mae: 875.2271 - val_loss: 854.3065 - val_mae: 854.3065\n",
      "Epoch 117/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 874.7161 - mae: 874.7161 - val_loss: 859.7210 - val_mae: 859.7210\n",
      "Epoch 118/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 874.5966 - mae: 874.5966 - val_loss: 852.1570 - val_mae: 852.1570\n",
      "Epoch 119/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 874.2726 - mae: 874.2726 - val_loss: 852.2318 - val_mae: 852.2318\n",
      "Epoch 120/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 874.9173 - mae: 874.9173 - val_loss: 851.9019 - val_mae: 851.9019\n",
      "Epoch 121/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 873.6865 - mae: 873.6865 - val_loss: 852.6974 - val_mae: 852.6974\n",
      "Epoch 122/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 871.6079 - mae: 871.6079 - val_loss: 855.9420 - val_mae: 855.9420\n",
      "Epoch 123/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 874.4490 - mae: 874.4490 - val_loss: 850.8083 - val_mae: 850.8083\n",
      "Epoch 124/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 872.9028 - mae: 872.9028 - val_loss: 853.5453 - val_mae: 853.5453\n",
      "Epoch 125/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 873.7505 - mae: 873.7505 - val_loss: 853.6726 - val_mae: 853.6726\n",
      "Epoch 126/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 874.0428 - mae: 874.0428 - val_loss: 851.6243 - val_mae: 851.6243\n",
      "Epoch 127/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 872.9622 - mae: 872.9622 - val_loss: 851.8191 - val_mae: 851.8191\n",
      "Epoch 128/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 870.9268 - mae: 870.9268 - val_loss: 850.8553 - val_mae: 850.8553\n",
      "Epoch 129/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 874.3745 - mae: 874.3745 - val_loss: 851.0823 - val_mae: 851.0823\n",
      "Epoch 130/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 872.9473 - mae: 872.9473 - val_loss: 851.6878 - val_mae: 851.6878\n",
      "Epoch 131/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 871.5052 - mae: 871.5052 - val_loss: 854.6486 - val_mae: 854.6486\n",
      "Epoch 132/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 873.0138 - mae: 873.0138 - val_loss: 853.8860 - val_mae: 853.8860\n",
      "Epoch 133/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 869.3946 - mae: 869.3946 - val_loss: 850.8790 - val_mae: 850.8790\n",
      "Epoch 134/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 872.3131 - mae: 872.3131 - val_loss: 854.1789 - val_mae: 854.1789\n",
      "Epoch 135/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 872.7169 - mae: 872.7169 - val_loss: 850.5814 - val_mae: 850.5814\n",
      "Epoch 136/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 872.8434 - mae: 872.8434 - val_loss: 856.7159 - val_mae: 856.7159\n",
      "Epoch 137/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 871.0941 - mae: 871.0941 - val_loss: 851.1573 - val_mae: 851.1573\n",
      "Epoch 138/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 872.8959 - mae: 872.8959 - val_loss: 851.1398 - val_mae: 851.1398\n",
      "Epoch 139/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 872.8369 - mae: 872.8369 - val_loss: 852.1950 - val_mae: 852.1950\n",
      "Epoch 140/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 870.6885 - mae: 870.6885 - val_loss: 853.1489 - val_mae: 853.1489\n",
      "Epoch 141/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 872.4939 - mae: 872.4939 - val_loss: 853.6238 - val_mae: 853.6238\n",
      "Epoch 142/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 873.2179 - mae: 873.2179 - val_loss: 857.9308 - val_mae: 857.9308\n",
      "Epoch 143/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 871.0231 - mae: 871.0231 - val_loss: 855.2392 - val_mae: 855.2392\n",
      "Epoch 144/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 873.2544 - mae: 873.2544 - val_loss: 854.4628 - val_mae: 854.4628\n",
      "Epoch 145/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 872.0852 - mae: 872.0852 - val_loss: 856.9889 - val_mae: 856.9889\n",
      "Epoch 146/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 871.4479 - mae: 871.4479 - val_loss: 852.9003 - val_mae: 852.9003\n",
      "Epoch 147/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 873.7791 - mae: 873.7791 - val_loss: 851.8115 - val_mae: 851.8115\n",
      "Epoch 148/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 871.7274 - mae: 871.7274 - val_loss: 852.9741 - val_mae: 852.9741\n",
      "Epoch 149/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 872.4187 - mae: 872.4187 - val_loss: 851.5537 - val_mae: 851.5537\n",
      "Epoch 150/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 870.9847 - mae: 870.9847 - val_loss: 854.7466 - val_mae: 854.7466\n",
      "Epoch 151/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 872.0197 - mae: 872.0197 - val_loss: 852.4337 - val_mae: 852.4337\n",
      "Epoch 152/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 871.1327 - mae: 871.1327 - val_loss: 853.5612 - val_mae: 853.5612\n",
      "Epoch 153/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 868.3328 - mae: 868.3328 - val_loss: 859.2325 - val_mae: 859.2325\n",
      "Epoch 154/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 872.7721 - mae: 872.7721 - val_loss: 855.2625 - val_mae: 855.2625\n",
      "Epoch 155/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 870.5089 - mae: 870.5089 - val_loss: 850.5623 - val_mae: 850.5623\n",
      "Epoch 156/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 871.8290 - mae: 871.8290 - val_loss: 853.2968 - val_mae: 853.2968\n",
      "Epoch 157/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 871.5422 - mae: 871.5422 - val_loss: 850.7040 - val_mae: 850.7040\n",
      "Epoch 158/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 872.0466 - mae: 872.0466 - val_loss: 853.3107 - val_mae: 853.3107\n",
      "Epoch 159/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 871.0296 - mae: 871.0296 - val_loss: 855.2305 - val_mae: 855.2305\n",
      "Epoch 160/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 871.8843 - mae: 871.8843 - val_loss: 850.9993 - val_mae: 850.9993\n",
      "Epoch 161/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 869.1028 - mae: 869.1028 - val_loss: 850.0219 - val_mae: 850.0219\n",
      "Epoch 162/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 868.3594 - mae: 868.3594 - val_loss: 855.7250 - val_mae: 855.7250\n",
      "Epoch 163/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 870.8244 - mae: 870.8244 - val_loss: 854.7812 - val_mae: 854.7812\n",
      "Epoch 164/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 869.1989 - mae: 869.1989 - val_loss: 853.8339 - val_mae: 853.8339\n",
      "Epoch 165/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 870.8948 - mae: 870.8948 - val_loss: 852.9692 - val_mae: 852.9692\n",
      "Epoch 166/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 871.0028 - mae: 871.0028 - val_loss: 852.3123 - val_mae: 852.3123\n",
      "Epoch 167/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 868.6896 - mae: 868.6896 - val_loss: 853.8726 - val_mae: 853.8726\n",
      "Epoch 168/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 869.2748 - mae: 869.2748 - val_loss: 852.6617 - val_mae: 852.6617\n",
      "Epoch 169/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 871.4400 - mae: 871.4400 - val_loss: 852.2289 - val_mae: 852.2289\n",
      "Epoch 170/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 869.4252 - mae: 869.4252 - val_loss: 853.7079 - val_mae: 853.7079\n",
      "Epoch 171/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 869.9534 - mae: 869.9534 - val_loss: 858.8482 - val_mae: 858.8482\n",
      "Epoch 172/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 869.0837 - mae: 869.0837 - val_loss: 854.2296 - val_mae: 854.2296\n",
      "Epoch 173/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 869.8474 - mae: 869.8474 - val_loss: 853.0793 - val_mae: 853.0793\n",
      "Epoch 174/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 869.8183 - mae: 869.8183 - val_loss: 853.6400 - val_mae: 853.6400\n",
      "Epoch 175/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 868.3433 - mae: 868.3433 - val_loss: 853.7266 - val_mae: 853.7266\n",
      "Epoch 176/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 870.9301 - mae: 870.9301 - val_loss: 854.6288 - val_mae: 854.6288\n",
      "Epoch 177/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 870.1565 - mae: 870.1565 - val_loss: 853.9861 - val_mae: 853.9861\n",
      "Epoch 178/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 869.9970 - mae: 869.9970 - val_loss: 861.7233 - val_mae: 861.7233\n",
      "Epoch 179/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 867.8318 - mae: 867.8318 - val_loss: 856.1909 - val_mae: 856.1909\n",
      "Epoch 180/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 868.3511 - mae: 868.3511 - val_loss: 852.7282 - val_mae: 852.7282\n",
      "Epoch 181/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 870.4105 - mae: 870.4105 - val_loss: 854.6513 - val_mae: 854.6513\n",
      "Epoch 182/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 869.8978 - mae: 869.8978 - val_loss: 859.5360 - val_mae: 859.5360\n",
      "Epoch 183/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 869.1194 - mae: 869.1194 - val_loss: 855.0565 - val_mae: 855.0565\n",
      "Epoch 184/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 867.8395 - mae: 867.8395 - val_loss: 851.9755 - val_mae: 851.9755\n",
      "Epoch 185/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 868.9130 - mae: 868.9130 - val_loss: 852.4255 - val_mae: 852.4255\n",
      "Epoch 186/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 869.0557 - mae: 869.0557 - val_loss: 854.8360 - val_mae: 854.8360\n",
      "Epoch 187/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 869.6655 - mae: 869.6655 - val_loss: 854.5637 - val_mae: 854.5637\n",
      "Epoch 188/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 868.9288 - mae: 868.9288 - val_loss: 855.1005 - val_mae: 855.1005\n",
      "Epoch 189/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 869.0789 - mae: 869.0789 - val_loss: 850.3746 - val_mae: 850.3746\n",
      "Epoch 190/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 869.5289 - mae: 869.5289 - val_loss: 860.1855 - val_mae: 860.1855\n",
      "Epoch 191/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 869.4030 - mae: 869.4030 - val_loss: 858.0079 - val_mae: 858.0079\n",
      "Epoch 192/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 869.7109 - mae: 869.7109 - val_loss: 857.6619 - val_mae: 857.6619\n",
      "Epoch 193/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 870.6475 - mae: 870.6475 - val_loss: 855.6172 - val_mae: 855.6172\n",
      "Epoch 194/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 867.4938 - mae: 867.4938 - val_loss: 859.4917 - val_mae: 859.4917\n",
      "Epoch 195/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 866.9926 - mae: 866.9926 - val_loss: 861.3589 - val_mae: 861.3589\n",
      "Epoch 196/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 867.2929 - mae: 867.2929 - val_loss: 861.3641 - val_mae: 861.3641\n",
      "Epoch 197/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 867.6211 - mae: 867.6211 - val_loss: 855.4560 - val_mae: 855.4560\n",
      "Epoch 198/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 867.7718 - mae: 867.7718 - val_loss: 863.8884 - val_mae: 863.8884\n",
      "Epoch 199/200\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 866.6745 - mae: 866.6745 - val_loss: 868.1140 - val_mae: 868.1140\n",
      "Epoch 200/200\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 866.9733 - mae: 866.9733 - val_loss: 864.6459 - val_mae: 864.6459\n"
     ]
    }
   ],
   "source": [
    "# DNN 모델 정의\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train0.shape[1],)),\n",
    "    Dropout(0.3),  \n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation='relu'), \n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                loss='mae',\n",
    "                metrics=['mae'])\n",
    "\n",
    "# 학습 (GPU 사용)\n",
    "with tf.device(\"/device:GPU:0\"):\n",
    "    history = model.fit(X_train0, y_train0, \n",
    "                        epochs=200,  # 폴드마다 학습 횟수를 조정 가능\n",
    "                        batch_size=128, \n",
    "                        validation_data=(X_test0, y_test0), \n",
    "                        verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "295/295 [==============================] - 0s 671us/step\n",
      "[Test results]\n",
      "MAPE: 0.329\n",
      "MAE: 864.6461\n",
      "MSE: 1.2521e+06\n",
      "MSE: 1252113.8208\n",
      "RMSE: 1118.9789\n",
      "\n"
     ]
    }
   ],
   "source": [
    "no_kfold_pred = model.predict(X_test0)\n",
    "print_test_results2(y_test0, no_kfold_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1-2. RF + XGBoost + DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47156, 3) <class 'pandas.core.frame.DataFrame'>\n",
      "(47156,) <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "df_concat_1 = pd.concat([df_rf_predict, df_xgb_predict, df_dnn_predict, df_y_test], axis=1)\n",
    "df_concat_1.columns = ['RF', 'DNN', 'XGBoost', 'True']\n",
    "\n",
    "X1 = df_concat_1[['RF', 'DNN', 'XGBoost']]\n",
    "y1 = df_concat_1['True']\n",
    "\n",
    "print(X1.shape, type(X1))\n",
    "print(y1.shape, type(y1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size=0.2, random_state=7)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train1 = scaler.fit_transform(X_train1)\n",
    "X_test1 = scaler.transform(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Cross Validation: 3-Fold 시작 ---\n",
      "\n",
      "Fold 1 / 3\n",
      "Epoch 1/100\n",
      "197/197 [==============================] - 1s 2ms/step - loss: 2400.3469 - mae: 2400.3469 - val_loss: 1259.7412 - val_mae: 1259.7412\n",
      "Epoch 2/100\n",
      "197/197 [==============================] - 0s 1ms/step - loss: 1082.2333 - mae: 1082.2333 - val_loss: 951.2248 - val_mae: 951.2248\n",
      "Epoch 3/100\n",
      "197/197 [==============================] - 0s 1ms/step - loss: 916.3088 - mae: 916.3088 - val_loss: 870.2824 - val_mae: 870.2824\n",
      "Epoch 4/100\n",
      "197/197 [==============================] - 0s 1ms/step - loss: 891.4794 - mae: 891.4794 - val_loss: 862.1047 - val_mae: 862.1047\n",
      "Epoch 5/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 887.8734 - mae: 887.8734 - val_loss: 859.6470 - val_mae: 859.6470\n",
      "Epoch 6/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.9587 - mae: 884.9587 - val_loss: 859.9461 - val_mae: 859.9461\n",
      "Epoch 7/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 887.0154 - mae: 887.0154 - val_loss: 861.5334 - val_mae: 861.5334\n",
      "Epoch 8/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.8510 - mae: 884.8510 - val_loss: 855.9908 - val_mae: 855.9908\n",
      "Epoch 9/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 886.2635 - mae: 886.2635 - val_loss: 856.9431 - val_mae: 856.9431\n",
      "Epoch 10/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 887.0944 - mae: 887.0944 - val_loss: 855.9931 - val_mae: 855.9931\n",
      "Epoch 11/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.7890 - mae: 884.7890 - val_loss: 859.3568 - val_mae: 859.3568\n",
      "Epoch 12/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.6325 - mae: 883.6325 - val_loss: 863.0425 - val_mae: 863.0425\n",
      "Epoch 13/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.1475 - mae: 885.1475 - val_loss: 855.4784 - val_mae: 855.4784\n",
      "Epoch 14/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 888.3612 - mae: 888.3612 - val_loss: 854.8380 - val_mae: 854.8380\n",
      "Epoch 15/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.0922 - mae: 884.0922 - val_loss: 857.5800 - val_mae: 857.5800\n",
      "Epoch 16/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.5270 - mae: 885.5270 - val_loss: 854.1085 - val_mae: 854.1085\n",
      "Epoch 17/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.8572 - mae: 884.8572 - val_loss: 855.9281 - val_mae: 855.9281\n",
      "Epoch 18/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.2618 - mae: 884.2618 - val_loss: 856.7380 - val_mae: 856.7380\n",
      "Epoch 19/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.3269 - mae: 884.3269 - val_loss: 856.5545 - val_mae: 856.5545\n",
      "Epoch 20/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.9163 - mae: 883.9163 - val_loss: 856.1003 - val_mae: 856.1003\n",
      "Epoch 21/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.5554 - mae: 885.5554 - val_loss: 854.5800 - val_mae: 854.5800\n",
      "Epoch 22/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.6440 - mae: 883.6440 - val_loss: 855.2479 - val_mae: 855.2479\n",
      "Epoch 23/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.9996 - mae: 884.9996 - val_loss: 860.6639 - val_mae: 860.6639\n",
      "Epoch 24/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 887.1736 - mae: 887.1736 - val_loss: 856.1381 - val_mae: 856.1381\n",
      "Epoch 25/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.1139 - mae: 885.1139 - val_loss: 855.4339 - val_mae: 855.4339\n",
      "Epoch 26/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.5711 - mae: 884.5711 - val_loss: 858.2542 - val_mae: 858.2542\n",
      "Epoch 27/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.9351 - mae: 883.9351 - val_loss: 857.6868 - val_mae: 857.6868\n",
      "Epoch 28/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.1925 - mae: 884.1925 - val_loss: 857.6996 - val_mae: 857.6996\n",
      "Epoch 29/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.3713 - mae: 885.3713 - val_loss: 853.9822 - val_mae: 853.9822\n",
      "Epoch 30/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.7745 - mae: 883.7745 - val_loss: 857.8293 - val_mae: 857.8293\n",
      "Epoch 31/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.4688 - mae: 884.4688 - val_loss: 860.3201 - val_mae: 860.3201\n",
      "Epoch 32/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.7486 - mae: 885.7486 - val_loss: 855.2355 - val_mae: 855.2355\n",
      "Epoch 33/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.5460 - mae: 884.5460 - val_loss: 854.9501 - val_mae: 854.9501\n",
      "Epoch 34/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.4433 - mae: 883.4433 - val_loss: 855.0151 - val_mae: 855.0151\n",
      "Epoch 35/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 887.1470 - mae: 887.1470 - val_loss: 856.2819 - val_mae: 856.2819\n",
      "Epoch 36/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.7238 - mae: 883.7238 - val_loss: 856.5655 - val_mae: 856.5655\n",
      "Epoch 37/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.3690 - mae: 884.3690 - val_loss: 856.9861 - val_mae: 856.9861\n",
      "Epoch 38/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.4100 - mae: 883.4100 - val_loss: 858.8105 - val_mae: 858.8105\n",
      "Epoch 39/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.1603 - mae: 885.1603 - val_loss: 853.9117 - val_mae: 853.9117\n",
      "Epoch 40/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.9325 - mae: 884.9325 - val_loss: 856.7244 - val_mae: 856.7244\n",
      "Epoch 41/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.7609 - mae: 884.7609 - val_loss: 856.2855 - val_mae: 856.2855\n",
      "Epoch 42/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.2672 - mae: 882.2672 - val_loss: 856.1053 - val_mae: 856.1053\n",
      "Epoch 43/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.4670 - mae: 881.4670 - val_loss: 855.3674 - val_mae: 855.3674\n",
      "Epoch 44/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.3757 - mae: 884.3757 - val_loss: 859.9210 - val_mae: 859.9210\n",
      "Epoch 45/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.5564 - mae: 881.5564 - val_loss: 858.2375 - val_mae: 858.2375\n",
      "Epoch 46/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.4617 - mae: 882.4617 - val_loss: 859.2905 - val_mae: 859.2905\n",
      "Epoch 47/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 886.7898 - mae: 886.7898 - val_loss: 857.4680 - val_mae: 857.4680\n",
      "Epoch 48/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.7947 - mae: 883.7947 - val_loss: 860.7185 - val_mae: 860.7185\n",
      "Epoch 49/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.5718 - mae: 884.5718 - val_loss: 855.7107 - val_mae: 855.7107\n",
      "Epoch 50/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.2907 - mae: 883.2907 - val_loss: 854.4778 - val_mae: 854.4778\n",
      "Epoch 51/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.5375 - mae: 883.5375 - val_loss: 857.4293 - val_mae: 857.4293\n",
      "Epoch 52/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.7734 - mae: 883.7734 - val_loss: 855.9318 - val_mae: 855.9318\n",
      "Epoch 53/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.3973 - mae: 881.3973 - val_loss: 857.1748 - val_mae: 857.1748\n",
      "Epoch 54/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.8696 - mae: 881.8696 - val_loss: 858.4067 - val_mae: 858.4067\n",
      "Epoch 55/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.0861 - mae: 883.0861 - val_loss: 857.4753 - val_mae: 857.4753\n",
      "Epoch 56/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.9884 - mae: 882.9884 - val_loss: 867.1412 - val_mae: 867.1412\n",
      "Epoch 57/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.1116 - mae: 882.1116 - val_loss: 855.6028 - val_mae: 855.6028\n",
      "Epoch 58/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.7194 - mae: 880.7194 - val_loss: 863.3496 - val_mae: 863.3496\n",
      "Epoch 59/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.0020 - mae: 883.0020 - val_loss: 855.9127 - val_mae: 855.9127\n",
      "Epoch 60/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.0745 - mae: 884.0745 - val_loss: 856.3936 - val_mae: 856.3936\n",
      "Epoch 61/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.6368 - mae: 882.6368 - val_loss: 857.8752 - val_mae: 857.8752\n",
      "Epoch 62/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.7468 - mae: 881.7468 - val_loss: 856.8877 - val_mae: 856.8877\n",
      "Epoch 63/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.2166 - mae: 880.2166 - val_loss: 863.4871 - val_mae: 863.4871\n",
      "Epoch 64/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.2695 - mae: 883.2695 - val_loss: 854.7915 - val_mae: 854.7915\n",
      "Epoch 65/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.7541 - mae: 882.7541 - val_loss: 860.0389 - val_mae: 860.0389\n",
      "Epoch 66/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.7410 - mae: 880.7410 - val_loss: 861.8541 - val_mae: 861.8541\n",
      "Epoch 67/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.3195 - mae: 884.3195 - val_loss: 855.6032 - val_mae: 855.6032\n",
      "Epoch 68/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.8466 - mae: 882.8466 - val_loss: 861.1914 - val_mae: 861.1914\n",
      "Epoch 69/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.1712 - mae: 884.1712 - val_loss: 858.9294 - val_mae: 858.9294\n",
      "Epoch 70/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.0207 - mae: 883.0207 - val_loss: 859.5637 - val_mae: 859.5637\n",
      "Epoch 71/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.0381 - mae: 880.0381 - val_loss: 860.2822 - val_mae: 860.2822\n",
      "Epoch 72/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.7045 - mae: 882.7045 - val_loss: 854.3513 - val_mae: 854.3513\n",
      "Epoch 73/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.4263 - mae: 884.4263 - val_loss: 858.8218 - val_mae: 858.8218\n",
      "Epoch 74/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.3466 - mae: 884.3466 - val_loss: 860.5438 - val_mae: 860.5438\n",
      "Epoch 75/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.8494 - mae: 880.8494 - val_loss: 860.9005 - val_mae: 860.9005\n",
      "Epoch 76/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.4542 - mae: 883.4542 - val_loss: 855.1158 - val_mae: 855.1158\n",
      "Epoch 77/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.9609 - mae: 881.9609 - val_loss: 854.4925 - val_mae: 854.4925\n",
      "Epoch 78/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.7355 - mae: 881.7355 - val_loss: 859.3777 - val_mae: 859.3777\n",
      "Epoch 79/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.1188 - mae: 883.1188 - val_loss: 857.6171 - val_mae: 857.6171\n",
      "Epoch 80/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.2849 - mae: 883.2849 - val_loss: 857.2088 - val_mae: 857.2088\n",
      "Epoch 81/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.7551 - mae: 881.7551 - val_loss: 858.4844 - val_mae: 858.4844\n",
      "Epoch 82/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.7762 - mae: 880.7762 - val_loss: 854.7954 - val_mae: 854.7954\n",
      "Epoch 83/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.5166 - mae: 882.5166 - val_loss: 857.6487 - val_mae: 857.6487\n",
      "Epoch 84/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.2247 - mae: 882.2247 - val_loss: 864.4838 - val_mae: 864.4838\n",
      "Epoch 85/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.8034 - mae: 883.8034 - val_loss: 855.6469 - val_mae: 855.6469\n",
      "Epoch 86/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.4642 - mae: 881.4642 - val_loss: 853.9421 - val_mae: 853.9421\n",
      "Epoch 87/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.7148 - mae: 879.7148 - val_loss: 854.0989 - val_mae: 854.0989\n",
      "Epoch 88/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.8883 - mae: 880.8883 - val_loss: 860.9480 - val_mae: 860.9480\n",
      "Epoch 89/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.7945 - mae: 879.7945 - val_loss: 856.8721 - val_mae: 856.8721\n",
      "Epoch 90/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.1078 - mae: 882.1078 - val_loss: 859.9986 - val_mae: 859.9986\n",
      "Epoch 91/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.1129 - mae: 882.1129 - val_loss: 859.8692 - val_mae: 859.8692\n",
      "Epoch 92/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.2962 - mae: 881.2962 - val_loss: 855.4419 - val_mae: 855.4419\n",
      "Epoch 93/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.2349 - mae: 882.2349 - val_loss: 854.0948 - val_mae: 854.0948\n",
      "Epoch 94/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.0193 - mae: 882.0193 - val_loss: 856.6600 - val_mae: 856.6600\n",
      "Epoch 95/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.1722 - mae: 879.1722 - val_loss: 862.7531 - val_mae: 862.7531\n",
      "Epoch 96/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.6720 - mae: 882.6720 - val_loss: 857.3116 - val_mae: 857.3116\n",
      "Epoch 97/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.3087 - mae: 883.3087 - val_loss: 857.2078 - val_mae: 857.2078\n",
      "Epoch 98/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.5366 - mae: 880.5366 - val_loss: 853.3833 - val_mae: 853.3833\n",
      "Epoch 99/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.6890 - mae: 882.6890 - val_loss: 853.8779 - val_mae: 853.8779\n",
      "Epoch 100/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.5256 - mae: 882.5256 - val_loss: 854.3062 - val_mae: 854.3062\n",
      "Fold 1 - Loss: 854.3061, MAE: 854.3061\n",
      "Fold 2 / 3\n",
      "Epoch 1/100\n",
      "197/197 [==============================] - 1s 2ms/step - loss: 2312.7922 - mae: 2312.7922 - val_loss: 1192.7114 - val_mae: 1192.7114\n",
      "Epoch 2/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 1066.5311 - mae: 1066.5311 - val_loss: 922.0506 - val_mae: 922.0506\n",
      "Epoch 3/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 903.0232 - mae: 903.0232 - val_loss: 872.8042 - val_mae: 872.8042\n",
      "Epoch 4/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.2481 - mae: 885.2481 - val_loss: 865.5366 - val_mae: 865.5366\n",
      "Epoch 5/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.1333 - mae: 884.1333 - val_loss: 867.1704 - val_mae: 867.1704\n",
      "Epoch 6/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.2999 - mae: 880.2999 - val_loss: 866.9169 - val_mae: 866.9169\n",
      "Epoch 7/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.4837 - mae: 881.4837 - val_loss: 867.7797 - val_mae: 867.7797\n",
      "Epoch 8/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.1752 - mae: 879.1752 - val_loss: 870.1024 - val_mae: 870.1024\n",
      "Epoch 9/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.6730 - mae: 881.6730 - val_loss: 863.6165 - val_mae: 863.6165\n",
      "Epoch 10/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.3547 - mae: 880.3547 - val_loss: 868.1390 - val_mae: 868.1390\n",
      "Epoch 11/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.6620 - mae: 879.6620 - val_loss: 866.9250 - val_mae: 866.9250\n",
      "Epoch 12/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.2975 - mae: 879.2975 - val_loss: 865.7041 - val_mae: 865.7041\n",
      "Epoch 13/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.7562 - mae: 881.7562 - val_loss: 866.8550 - val_mae: 866.8550\n",
      "Epoch 14/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.8011 - mae: 880.8011 - val_loss: 864.4975 - val_mae: 864.4975\n",
      "Epoch 15/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.5369 - mae: 883.5369 - val_loss: 866.7158 - val_mae: 866.7158\n",
      "Epoch 16/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.0735 - mae: 880.0735 - val_loss: 870.0475 - val_mae: 870.0475\n",
      "Epoch 17/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.7826 - mae: 879.7826 - val_loss: 865.7930 - val_mae: 865.7930\n",
      "Epoch 18/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.8800 - mae: 880.8800 - val_loss: 865.3126 - val_mae: 865.3126\n",
      "Epoch 19/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.0927 - mae: 883.0927 - val_loss: 863.9364 - val_mae: 863.9364\n",
      "Epoch 20/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.4711 - mae: 878.4711 - val_loss: 864.0648 - val_mae: 864.0648\n",
      "Epoch 21/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.7012 - mae: 882.7012 - val_loss: 867.5535 - val_mae: 867.5535\n",
      "Epoch 22/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.6597 - mae: 880.6597 - val_loss: 865.1625 - val_mae: 865.1625\n",
      "Epoch 23/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.4125 - mae: 879.4125 - val_loss: 864.3722 - val_mae: 864.3722\n",
      "Epoch 24/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.5921 - mae: 881.5921 - val_loss: 865.5503 - val_mae: 865.5503\n",
      "Epoch 25/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.7286 - mae: 877.7286 - val_loss: 868.3041 - val_mae: 868.3041\n",
      "Epoch 26/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.9026 - mae: 880.9026 - val_loss: 864.3780 - val_mae: 864.3780\n",
      "Epoch 27/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.7198 - mae: 880.7198 - val_loss: 864.1678 - val_mae: 864.1678\n",
      "Epoch 28/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.2695 - mae: 881.2695 - val_loss: 863.9677 - val_mae: 863.9677\n",
      "Epoch 29/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.0662 - mae: 880.0662 - val_loss: 863.0192 - val_mae: 863.0192\n",
      "Epoch 30/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.7316 - mae: 880.7316 - val_loss: 868.2500 - val_mae: 868.2500\n",
      "Epoch 31/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.3973 - mae: 879.3973 - val_loss: 868.1372 - val_mae: 868.1372\n",
      "Epoch 32/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.8730 - mae: 877.8730 - val_loss: 863.5865 - val_mae: 863.5865\n",
      "Epoch 33/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.0720 - mae: 879.0720 - val_loss: 865.8546 - val_mae: 865.8546\n",
      "Epoch 34/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.7488 - mae: 879.7488 - val_loss: 862.7690 - val_mae: 862.7690\n",
      "Epoch 35/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.0660 - mae: 881.0660 - val_loss: 865.5148 - val_mae: 865.5148\n",
      "Epoch 36/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.9556 - mae: 881.9556 - val_loss: 864.3765 - val_mae: 864.3765\n",
      "Epoch 37/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.9314 - mae: 879.9314 - val_loss: 866.9551 - val_mae: 866.9551\n",
      "Epoch 38/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.9722 - mae: 879.9722 - val_loss: 868.1396 - val_mae: 868.1396\n",
      "Epoch 39/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.1302 - mae: 879.1302 - val_loss: 862.2648 - val_mae: 862.2648\n",
      "Epoch 40/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.6108 - mae: 880.6108 - val_loss: 863.3436 - val_mae: 863.3436\n",
      "Epoch 41/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.2767 - mae: 880.2767 - val_loss: 868.5185 - val_mae: 868.5185\n",
      "Epoch 42/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.9180 - mae: 878.9180 - val_loss: 864.3008 - val_mae: 864.3008\n",
      "Epoch 43/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.1816 - mae: 880.1816 - val_loss: 869.2769 - val_mae: 869.2769\n",
      "Epoch 44/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.6295 - mae: 878.6295 - val_loss: 864.1178 - val_mae: 864.1178\n",
      "Epoch 45/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.3022 - mae: 879.3022 - val_loss: 869.0475 - val_mae: 869.0475\n",
      "Epoch 46/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.1009 - mae: 879.1009 - val_loss: 867.5164 - val_mae: 867.5164\n",
      "Epoch 47/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.2253 - mae: 881.2253 - val_loss: 863.2056 - val_mae: 863.2056\n",
      "Epoch 48/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.6793 - mae: 877.6793 - val_loss: 863.4169 - val_mae: 863.4169\n",
      "Epoch 49/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.2656 - mae: 882.2656 - val_loss: 863.4057 - val_mae: 863.4057\n",
      "Epoch 50/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.9465 - mae: 878.9465 - val_loss: 865.2814 - val_mae: 865.2814\n",
      "Epoch 51/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.7239 - mae: 882.7239 - val_loss: 863.9644 - val_mae: 863.9644\n",
      "Epoch 52/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.8477 - mae: 877.8477 - val_loss: 864.7286 - val_mae: 864.7286\n",
      "Epoch 53/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.6591 - mae: 878.6591 - val_loss: 865.9869 - val_mae: 865.9869\n",
      "Epoch 54/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.2196 - mae: 877.2196 - val_loss: 866.5588 - val_mae: 866.5588\n",
      "Epoch 55/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.9412 - mae: 879.9412 - val_loss: 862.2844 - val_mae: 862.2844\n",
      "Epoch 56/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.9029 - mae: 879.9029 - val_loss: 865.8425 - val_mae: 865.8425\n",
      "Epoch 57/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.0822 - mae: 879.0822 - val_loss: 863.9379 - val_mae: 863.9379\n",
      "Epoch 58/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.8294 - mae: 879.8294 - val_loss: 864.4677 - val_mae: 864.4677\n",
      "Epoch 59/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.3653 - mae: 879.3653 - val_loss: 867.3038 - val_mae: 867.3038\n",
      "Epoch 60/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.2270 - mae: 877.2270 - val_loss: 865.2289 - val_mae: 865.2289\n",
      "Epoch 61/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.9562 - mae: 879.9562 - val_loss: 866.1107 - val_mae: 866.1107\n",
      "Epoch 62/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 876.4827 - mae: 876.4827 - val_loss: 864.9966 - val_mae: 864.9966\n",
      "Epoch 63/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.7908 - mae: 879.7908 - val_loss: 869.8149 - val_mae: 869.8149\n",
      "Epoch 64/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.6503 - mae: 879.6503 - val_loss: 869.0145 - val_mae: 869.0145\n",
      "Epoch 65/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.3768 - mae: 880.3768 - val_loss: 862.3276 - val_mae: 862.3276\n",
      "Epoch 66/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.7473 - mae: 878.7473 - val_loss: 862.6745 - val_mae: 862.6745\n",
      "Epoch 67/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.2022 - mae: 880.2022 - val_loss: 864.4825 - val_mae: 864.4825\n",
      "Epoch 68/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.8465 - mae: 878.8465 - val_loss: 865.0342 - val_mae: 865.0342\n",
      "Epoch 69/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.3022 - mae: 879.3022 - val_loss: 865.8658 - val_mae: 865.8658\n",
      "Epoch 70/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.0881 - mae: 877.0881 - val_loss: 866.9167 - val_mae: 866.9167\n",
      "Epoch 71/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.4698 - mae: 878.4698 - val_loss: 864.0641 - val_mae: 864.0641\n",
      "Epoch 72/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.7066 - mae: 877.7066 - val_loss: 865.2191 - val_mae: 865.2191\n",
      "Epoch 73/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.6777 - mae: 879.6777 - val_loss: 864.5710 - val_mae: 864.5710\n",
      "Epoch 74/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 874.1083 - mae: 874.1083 - val_loss: 862.6049 - val_mae: 862.6049\n",
      "Epoch 75/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.4561 - mae: 878.4561 - val_loss: 864.9662 - val_mae: 864.9662\n",
      "Epoch 76/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.2602 - mae: 879.2602 - val_loss: 864.8578 - val_mae: 864.8578\n",
      "Epoch 77/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.9087 - mae: 878.9087 - val_loss: 864.6196 - val_mae: 864.6196\n",
      "Epoch 78/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.5393 - mae: 879.5393 - val_loss: 863.8309 - val_mae: 863.8309\n",
      "Epoch 79/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.4282 - mae: 878.4282 - val_loss: 864.3951 - val_mae: 864.3951\n",
      "Epoch 80/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.6603 - mae: 879.6603 - val_loss: 863.3499 - val_mae: 863.3499\n",
      "Epoch 81/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.6046 - mae: 880.6046 - val_loss: 863.2938 - val_mae: 863.2938\n",
      "Epoch 82/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.9133 - mae: 878.9133 - val_loss: 861.2169 - val_mae: 861.2169\n",
      "Epoch 83/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.7386 - mae: 877.7386 - val_loss: 865.3597 - val_mae: 865.3597\n",
      "Epoch 84/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.0403 - mae: 879.0403 - val_loss: 860.4289 - val_mae: 860.4289\n",
      "Epoch 85/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 875.9930 - mae: 875.9930 - val_loss: 865.3356 - val_mae: 865.3356\n",
      "Epoch 86/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.3481 - mae: 878.3481 - val_loss: 861.1956 - val_mae: 861.1956\n",
      "Epoch 87/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.2915 - mae: 877.2915 - val_loss: 861.9982 - val_mae: 861.9982\n",
      "Epoch 88/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.8797 - mae: 877.8797 - val_loss: 861.8576 - val_mae: 861.8576\n",
      "Epoch 89/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.5381 - mae: 877.5381 - val_loss: 863.2775 - val_mae: 863.2775\n",
      "Epoch 90/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 876.9232 - mae: 876.9232 - val_loss: 862.2711 - val_mae: 862.2711\n",
      "Epoch 91/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 876.3281 - mae: 876.3281 - val_loss: 859.9872 - val_mae: 859.9872\n",
      "Epoch 92/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 875.6454 - mae: 875.6454 - val_loss: 863.3047 - val_mae: 863.3047\n",
      "Epoch 93/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.1859 - mae: 878.1859 - val_loss: 861.0173 - val_mae: 861.0173\n",
      "Epoch 94/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 876.3116 - mae: 876.3116 - val_loss: 863.8910 - val_mae: 863.8910\n",
      "Epoch 95/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 876.1086 - mae: 876.1086 - val_loss: 862.3232 - val_mae: 862.3232\n",
      "Epoch 96/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 875.6812 - mae: 875.6812 - val_loss: 861.7640 - val_mae: 861.7640\n",
      "Epoch 97/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 875.6878 - mae: 875.6878 - val_loss: 859.3458 - val_mae: 859.3458\n",
      "Epoch 98/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.0186 - mae: 877.0186 - val_loss: 860.9664 - val_mae: 860.9664\n",
      "Epoch 99/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 873.8498 - mae: 873.8498 - val_loss: 864.4395 - val_mae: 864.4395\n",
      "Epoch 100/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 874.8873 - mae: 874.8873 - val_loss: 859.8306 - val_mae: 859.8306\n",
      "Fold 2 - Loss: 859.8303, MAE: 859.8303\n",
      "Fold 3 / 3\n",
      "Epoch 1/100\n",
      "197/197 [==============================] - 1s 2ms/step - loss: 2374.4434 - mae: 2374.4434 - val_loss: 1210.3710 - val_mae: 1210.3710\n",
      "Epoch 2/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 1089.7814 - mae: 1089.7814 - val_loss: 930.1942 - val_mae: 930.1942\n",
      "Epoch 3/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 917.5383 - mae: 917.5383 - val_loss: 864.2363 - val_mae: 864.2363\n",
      "Epoch 4/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 894.8322 - mae: 894.8322 - val_loss: 856.9186 - val_mae: 856.9186\n",
      "Epoch 5/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 891.3382 - mae: 891.3382 - val_loss: 855.0121 - val_mae: 855.0121\n",
      "Epoch 6/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 889.4728 - mae: 889.4728 - val_loss: 854.5034 - val_mae: 854.5034\n",
      "Epoch 7/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 889.6661 - mae: 889.6661 - val_loss: 852.4260 - val_mae: 852.4260\n",
      "Epoch 8/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 887.5675 - mae: 887.5675 - val_loss: 856.4751 - val_mae: 856.4751\n",
      "Epoch 9/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 889.0934 - mae: 889.0934 - val_loss: 854.8154 - val_mae: 854.8154\n",
      "Epoch 10/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.5112 - mae: 885.5112 - val_loss: 852.7399 - val_mae: 852.7399\n",
      "Epoch 11/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 889.2688 - mae: 889.2688 - val_loss: 856.2714 - val_mae: 856.2714\n",
      "Epoch 12/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.1549 - mae: 884.1549 - val_loss: 853.5569 - val_mae: 853.5569\n",
      "Epoch 13/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 888.6083 - mae: 888.6083 - val_loss: 854.1414 - val_mae: 854.1414\n",
      "Epoch 14/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 889.4988 - mae: 889.4988 - val_loss: 854.5614 - val_mae: 854.5614\n",
      "Epoch 15/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 888.8370 - mae: 888.8370 - val_loss: 854.8149 - val_mae: 854.8149\n",
      "Epoch 16/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 887.9261 - mae: 887.9261 - val_loss: 859.2590 - val_mae: 859.2590\n",
      "Epoch 17/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 886.7624 - mae: 886.7624 - val_loss: 854.5923 - val_mae: 854.5923\n",
      "Epoch 18/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 887.3973 - mae: 887.3973 - val_loss: 852.5139 - val_mae: 852.5139\n",
      "Epoch 19/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 886.5217 - mae: 886.5217 - val_loss: 856.0507 - val_mae: 856.0507\n",
      "Epoch 20/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 886.0730 - mae: 886.0730 - val_loss: 852.8721 - val_mae: 852.8721\n",
      "Epoch 21/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.8406 - mae: 884.8406 - val_loss: 853.0417 - val_mae: 853.0417\n",
      "Epoch 22/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.7134 - mae: 884.7134 - val_loss: 853.0787 - val_mae: 853.0787\n",
      "Epoch 23/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 889.8857 - mae: 889.8857 - val_loss: 853.6779 - val_mae: 853.6779\n",
      "Epoch 24/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 888.0018 - mae: 888.0018 - val_loss: 851.2803 - val_mae: 851.2803\n",
      "Epoch 25/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.3383 - mae: 885.3383 - val_loss: 852.4904 - val_mae: 852.4904\n",
      "Epoch 26/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 886.0684 - mae: 886.0684 - val_loss: 853.9979 - val_mae: 853.9979\n",
      "Epoch 27/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.1282 - mae: 885.1282 - val_loss: 855.0649 - val_mae: 855.0649\n",
      "Epoch 28/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.4698 - mae: 885.4698 - val_loss: 854.5912 - val_mae: 854.5912\n",
      "Epoch 29/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 886.8248 - mae: 886.8248 - val_loss: 853.8857 - val_mae: 853.8857\n",
      "Epoch 30/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.9988 - mae: 884.9988 - val_loss: 855.8377 - val_mae: 855.8377\n",
      "Epoch 31/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.1111 - mae: 885.1111 - val_loss: 854.3524 - val_mae: 854.3524\n",
      "Epoch 32/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 887.5287 - mae: 887.5287 - val_loss: 853.5446 - val_mae: 853.5446\n",
      "Epoch 33/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 889.7745 - mae: 889.7745 - val_loss: 853.2449 - val_mae: 853.2449\n",
      "Epoch 34/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 887.6425 - mae: 887.6425 - val_loss: 853.7065 - val_mae: 853.7065\n",
      "Epoch 35/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 886.6784 - mae: 886.6784 - val_loss: 852.0392 - val_mae: 852.0392\n",
      "Epoch 36/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 886.5358 - mae: 886.5358 - val_loss: 860.7766 - val_mae: 860.7766\n",
      "Epoch 37/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.0604 - mae: 885.0604 - val_loss: 855.3817 - val_mae: 855.3817\n",
      "Epoch 38/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 886.9540 - mae: 886.9540 - val_loss: 851.4478 - val_mae: 851.4478\n",
      "Epoch 39/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.5074 - mae: 885.5074 - val_loss: 853.4396 - val_mae: 853.4396\n",
      "Epoch 40/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.2518 - mae: 885.2518 - val_loss: 852.5375 - val_mae: 852.5375\n",
      "Epoch 41/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.5102 - mae: 883.5102 - val_loss: 852.6617 - val_mae: 852.6617\n",
      "Epoch 42/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 886.7178 - mae: 886.7178 - val_loss: 855.1769 - val_mae: 855.1769\n",
      "Epoch 43/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 886.9395 - mae: 886.9395 - val_loss: 852.6467 - val_mae: 852.6467\n",
      "Epoch 44/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 887.4775 - mae: 887.4775 - val_loss: 851.5331 - val_mae: 851.5331\n",
      "Epoch 45/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 887.4534 - mae: 887.4534 - val_loss: 852.8436 - val_mae: 852.8436\n",
      "Epoch 46/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.1570 - mae: 884.1570 - val_loss: 851.0834 - val_mae: 851.0834\n",
      "Epoch 47/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.0337 - mae: 884.0337 - val_loss: 854.3011 - val_mae: 854.3011\n",
      "Epoch 48/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 886.2247 - mae: 886.2247 - val_loss: 852.1646 - val_mae: 852.1646\n",
      "Epoch 49/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.8063 - mae: 884.8063 - val_loss: 854.8918 - val_mae: 854.8918\n",
      "Epoch 50/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 887.0327 - mae: 887.0327 - val_loss: 853.7812 - val_mae: 853.7812\n",
      "Epoch 51/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.8431 - mae: 884.8431 - val_loss: 851.3023 - val_mae: 851.3023\n",
      "Epoch 52/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.7519 - mae: 884.7519 - val_loss: 850.6688 - val_mae: 850.6688\n",
      "Epoch 53/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 886.8773 - mae: 886.8773 - val_loss: 852.0504 - val_mae: 852.0504\n",
      "Epoch 54/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.4100 - mae: 884.4100 - val_loss: 855.2231 - val_mae: 855.2231\n",
      "Epoch 55/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.6007 - mae: 884.6007 - val_loss: 852.0028 - val_mae: 852.0028\n",
      "Epoch 56/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 887.0886 - mae: 887.0886 - val_loss: 856.1296 - val_mae: 856.1296\n",
      "Epoch 57/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.4014 - mae: 885.4014 - val_loss: 850.6058 - val_mae: 850.6058\n",
      "Epoch 58/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.0438 - mae: 885.0438 - val_loss: 851.8076 - val_mae: 851.8076\n",
      "Epoch 59/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.2255 - mae: 882.2255 - val_loss: 855.5583 - val_mae: 855.5583\n",
      "Epoch 60/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 886.6185 - mae: 886.6185 - val_loss: 855.1989 - val_mae: 855.1989\n",
      "Epoch 61/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.4158 - mae: 885.4158 - val_loss: 856.6236 - val_mae: 856.6236\n",
      "Epoch 62/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.4704 - mae: 882.4704 - val_loss: 853.1410 - val_mae: 853.1410\n",
      "Epoch 63/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 886.0255 - mae: 886.0255 - val_loss: 851.4689 - val_mae: 851.4689\n",
      "Epoch 64/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.7710 - mae: 882.7710 - val_loss: 855.3428 - val_mae: 855.3428\n",
      "Epoch 65/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 886.0178 - mae: 886.0178 - val_loss: 851.5649 - val_mae: 851.5649\n",
      "Epoch 66/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.9669 - mae: 885.9669 - val_loss: 851.5667 - val_mae: 851.5667\n",
      "Epoch 67/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 887.0165 - mae: 887.0165 - val_loss: 852.6968 - val_mae: 852.6968\n",
      "Epoch 68/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.6538 - mae: 883.6538 - val_loss: 850.5036 - val_mae: 850.5036\n",
      "Epoch 69/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.1400 - mae: 884.1400 - val_loss: 851.6066 - val_mae: 851.6066\n",
      "Epoch 70/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.7526 - mae: 885.7526 - val_loss: 851.8247 - val_mae: 851.8247\n",
      "Epoch 71/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.1635 - mae: 884.1635 - val_loss: 853.9999 - val_mae: 853.9999\n",
      "Epoch 72/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.9325 - mae: 883.9325 - val_loss: 857.4581 - val_mae: 857.4581\n",
      "Epoch 73/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.5282 - mae: 885.5282 - val_loss: 853.4744 - val_mae: 853.4744\n",
      "Epoch 74/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.9633 - mae: 884.9633 - val_loss: 852.6917 - val_mae: 852.6917\n",
      "Epoch 75/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.3373 - mae: 883.3373 - val_loss: 854.8735 - val_mae: 854.8735\n",
      "Epoch 76/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 886.1785 - mae: 886.1785 - val_loss: 851.7698 - val_mae: 851.7698\n",
      "Epoch 77/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.5090 - mae: 884.5090 - val_loss: 851.3932 - val_mae: 851.3932\n",
      "Epoch 78/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.4956 - mae: 881.4956 - val_loss: 855.4943 - val_mae: 855.4943\n",
      "Epoch 79/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.1368 - mae: 884.1368 - val_loss: 853.3753 - val_mae: 853.3753\n",
      "Epoch 80/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.4652 - mae: 879.4652 - val_loss: 851.6871 - val_mae: 851.6871\n",
      "Epoch 81/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 886.0961 - mae: 886.0961 - val_loss: 849.3746 - val_mae: 849.3746\n",
      "Epoch 82/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.9540 - mae: 884.9540 - val_loss: 849.4683 - val_mae: 849.4683\n",
      "Epoch 83/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 886.0396 - mae: 886.0396 - val_loss: 849.1997 - val_mae: 849.1997\n",
      "Epoch 84/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.7046 - mae: 881.7046 - val_loss: 853.1987 - val_mae: 853.1987\n",
      "Epoch 85/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.6915 - mae: 884.6915 - val_loss: 854.3121 - val_mae: 854.3121\n",
      "Epoch 86/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.6325 - mae: 885.6325 - val_loss: 851.6944 - val_mae: 851.6944\n",
      "Epoch 87/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.8546 - mae: 881.8546 - val_loss: 848.5598 - val_mae: 848.5598\n",
      "Epoch 88/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.1300 - mae: 884.1300 - val_loss: 852.8785 - val_mae: 852.8785\n",
      "Epoch 89/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.9588 - mae: 883.9588 - val_loss: 852.7690 - val_mae: 852.7690\n",
      "Epoch 90/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.6744 - mae: 883.6744 - val_loss: 852.0039 - val_mae: 852.0039\n",
      "Epoch 91/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.0234 - mae: 882.0234 - val_loss: 850.7443 - val_mae: 850.7443\n",
      "Epoch 92/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.2747 - mae: 883.2747 - val_loss: 848.5452 - val_mae: 848.5452\n",
      "Epoch 93/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.2042 - mae: 883.2042 - val_loss: 849.1031 - val_mae: 849.1031\n",
      "Epoch 94/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.0418 - mae: 881.0418 - val_loss: 849.0424 - val_mae: 849.0424\n",
      "Epoch 95/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.9751 - mae: 884.9751 - val_loss: 849.9890 - val_mae: 849.9890\n",
      "Epoch 96/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.6807 - mae: 883.6807 - val_loss: 849.2137 - val_mae: 849.2137\n",
      "Epoch 97/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.7624 - mae: 883.7624 - val_loss: 848.1530 - val_mae: 848.1530\n",
      "Epoch 98/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.2620 - mae: 880.2620 - val_loss: 849.2241 - val_mae: 849.2241\n",
      "Epoch 99/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.7321 - mae: 879.7321 - val_loss: 847.5385 - val_mae: 847.5385\n",
      "Epoch 100/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.9386 - mae: 883.9386 - val_loss: 850.3737 - val_mae: 850.3737\n",
      "Fold 3 - Loss: 850.3737, MAE: 850.3737\n",
      "\n",
      "Cross Validation 3-Fold 결과:\n",
      "MAE 평균: 854.8367, 표준편차: 3.8788\n",
      "\n",
      "\n",
      "--- Cross Validation: 5-Fold 시작 ---\n",
      "\n",
      "Fold 1 / 5\n",
      "Epoch 1/100\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 2143.6670 - mae: 2143.6670 - val_loss: 1152.9855 - val_mae: 1152.9855\n",
      "Epoch 2/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 1010.3150 - mae: 1010.3150 - val_loss: 890.4536 - val_mae: 890.4536\n",
      "Epoch 3/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 896.0977 - mae: 896.0977 - val_loss: 862.7177 - val_mae: 862.7177\n",
      "Epoch 4/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 886.2421 - mae: 886.2421 - val_loss: 857.8156 - val_mae: 857.8156\n",
      "Epoch 5/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 887.2390 - mae: 887.2390 - val_loss: 862.0868 - val_mae: 862.0868\n",
      "Epoch 6/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 886.4147 - mae: 886.4147 - val_loss: 859.3746 - val_mae: 859.3746\n",
      "Epoch 7/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.2923 - mae: 885.2923 - val_loss: 860.8086 - val_mae: 860.8086\n",
      "Epoch 8/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 884.7599 - mae: 884.7599 - val_loss: 858.6801 - val_mae: 858.6801\n",
      "Epoch 9/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 884.7630 - mae: 884.7630 - val_loss: 861.3199 - val_mae: 861.3199\n",
      "Epoch 10/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.3807 - mae: 884.3807 - val_loss: 858.0391 - val_mae: 858.0391\n",
      "Epoch 11/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 884.8488 - mae: 884.8488 - val_loss: 857.3606 - val_mae: 857.3606\n",
      "Epoch 12/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 881.1772 - mae: 881.1772 - val_loss: 855.6125 - val_mae: 855.6125\n",
      "Epoch 13/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.8344 - mae: 884.8344 - val_loss: 855.6943 - val_mae: 855.6943\n",
      "Epoch 14/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.2076 - mae: 884.2076 - val_loss: 858.7736 - val_mae: 858.7736\n",
      "Epoch 15/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.2342 - mae: 885.2342 - val_loss: 858.8074 - val_mae: 858.8074\n",
      "Epoch 16/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.4107 - mae: 882.4107 - val_loss: 857.5088 - val_mae: 857.5088\n",
      "Epoch 17/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 886.4673 - mae: 886.4673 - val_loss: 859.8643 - val_mae: 859.8643\n",
      "Epoch 18/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 886.3777 - mae: 886.3777 - val_loss: 855.1510 - val_mae: 855.1510\n",
      "Epoch 19/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.5281 - mae: 884.5281 - val_loss: 858.9603 - val_mae: 858.9603\n",
      "Epoch 20/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 883.4175 - mae: 883.4175 - val_loss: 864.0493 - val_mae: 864.0493\n",
      "Epoch 21/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 882.5894 - mae: 882.5894 - val_loss: 856.2469 - val_mae: 856.2469\n",
      "Epoch 22/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 882.1196 - mae: 882.1196 - val_loss: 859.8741 - val_mae: 859.8741\n",
      "Epoch 23/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.0176 - mae: 885.0176 - val_loss: 855.2800 - val_mae: 855.2800\n",
      "Epoch 24/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.3755 - mae: 883.3755 - val_loss: 855.2219 - val_mae: 855.2219\n",
      "Epoch 25/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.9648 - mae: 883.9648 - val_loss: 857.4084 - val_mae: 857.4084\n",
      "Epoch 26/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.2320 - mae: 883.2320 - val_loss: 855.0594 - val_mae: 855.0594\n",
      "Epoch 27/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.8253 - mae: 883.8253 - val_loss: 855.1915 - val_mae: 855.1915\n",
      "Epoch 28/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.9666 - mae: 883.9666 - val_loss: 855.3440 - val_mae: 855.3440\n",
      "Epoch 29/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.6482 - mae: 883.6482 - val_loss: 855.2512 - val_mae: 855.2512\n",
      "Epoch 30/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.6114 - mae: 884.6114 - val_loss: 856.2963 - val_mae: 856.2963\n",
      "Epoch 31/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.9329 - mae: 885.9329 - val_loss: 854.7253 - val_mae: 854.7253\n",
      "Epoch 32/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.8161 - mae: 882.8161 - val_loss: 859.5742 - val_mae: 859.5742\n",
      "Epoch 33/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.9218 - mae: 884.9218 - val_loss: 855.6863 - val_mae: 855.6863\n",
      "Epoch 34/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.4197 - mae: 881.4197 - val_loss: 854.9520 - val_mae: 854.9520\n",
      "Epoch 35/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 884.7467 - mae: 884.7467 - val_loss: 854.5660 - val_mae: 854.5660\n",
      "Epoch 36/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 882.8740 - mae: 882.8740 - val_loss: 857.8738 - val_mae: 857.8738\n",
      "Epoch 37/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.1718 - mae: 884.1718 - val_loss: 856.2193 - val_mae: 856.2193\n",
      "Epoch 38/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 882.0742 - mae: 882.0742 - val_loss: 856.7195 - val_mae: 856.7195\n",
      "Epoch 39/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 883.3621 - mae: 883.3621 - val_loss: 856.2930 - val_mae: 856.2930\n",
      "Epoch 40/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.8618 - mae: 882.8618 - val_loss: 855.7571 - val_mae: 855.7571\n",
      "Epoch 41/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 883.3246 - mae: 883.3246 - val_loss: 855.7579 - val_mae: 855.7579\n",
      "Epoch 42/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 885.8725 - mae: 885.8725 - val_loss: 861.4887 - val_mae: 861.4887\n",
      "Epoch 43/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.1634 - mae: 883.1634 - val_loss: 855.0052 - val_mae: 855.0052\n",
      "Epoch 44/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.5397 - mae: 884.5397 - val_loss: 862.6771 - val_mae: 862.6771\n",
      "Epoch 45/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.2489 - mae: 884.2489 - val_loss: 860.2747 - val_mae: 860.2747\n",
      "Epoch 46/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 883.3837 - mae: 883.3837 - val_loss: 859.9572 - val_mae: 859.9572\n",
      "Epoch 47/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.5601 - mae: 883.5601 - val_loss: 859.6111 - val_mae: 859.6111\n",
      "Epoch 48/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.6559 - mae: 881.6559 - val_loss: 856.3276 - val_mae: 856.3276\n",
      "Epoch 49/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.9974 - mae: 883.9974 - val_loss: 858.4498 - val_mae: 858.4498\n",
      "Epoch 50/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.5656 - mae: 884.5656 - val_loss: 856.8951 - val_mae: 856.8951\n",
      "Epoch 51/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.6805 - mae: 882.6805 - val_loss: 856.3809 - val_mae: 856.3809\n",
      "Epoch 52/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.7850 - mae: 882.7850 - val_loss: 860.1981 - val_mae: 860.1981\n",
      "Epoch 53/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.3862 - mae: 882.3862 - val_loss: 857.9882 - val_mae: 857.9882\n",
      "Epoch 54/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.2695 - mae: 881.2695 - val_loss: 860.2018 - val_mae: 860.2018\n",
      "Epoch 55/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.9995 - mae: 881.9995 - val_loss: 857.0303 - val_mae: 857.0303\n",
      "Epoch 56/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.3781 - mae: 884.3781 - val_loss: 865.4415 - val_mae: 865.4415\n",
      "Epoch 57/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.6405 - mae: 882.6405 - val_loss: 857.3798 - val_mae: 857.3798\n",
      "Epoch 58/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 881.7379 - mae: 881.7379 - val_loss: 856.5129 - val_mae: 856.5129\n",
      "Epoch 59/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.1729 - mae: 883.1729 - val_loss: 862.2024 - val_mae: 862.2024\n",
      "Epoch 60/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.6071 - mae: 882.6071 - val_loss: 857.8556 - val_mae: 857.8556\n",
      "Epoch 61/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.0937 - mae: 881.0937 - val_loss: 855.3038 - val_mae: 855.3038\n",
      "Epoch 62/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.5320 - mae: 883.5320 - val_loss: 860.1015 - val_mae: 860.1015\n",
      "Epoch 63/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.7705 - mae: 882.7705 - val_loss: 861.6301 - val_mae: 861.6301\n",
      "Epoch 64/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.2719 - mae: 880.2719 - val_loss: 856.5119 - val_mae: 856.5119\n",
      "Epoch 65/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.1910 - mae: 882.1910 - val_loss: 855.0018 - val_mae: 855.0018\n",
      "Epoch 66/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.8210 - mae: 880.8210 - val_loss: 855.1484 - val_mae: 855.1484\n",
      "Epoch 67/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.3275 - mae: 883.3275 - val_loss: 856.3638 - val_mae: 856.3638\n",
      "Epoch 68/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.4626 - mae: 882.4626 - val_loss: 855.3291 - val_mae: 855.3291\n",
      "Epoch 69/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.5946 - mae: 881.5946 - val_loss: 859.1653 - val_mae: 859.1653\n",
      "Epoch 70/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.8752 - mae: 884.8752 - val_loss: 857.1174 - val_mae: 857.1174\n",
      "Epoch 71/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.1777 - mae: 880.1777 - val_loss: 860.7288 - val_mae: 860.7288\n",
      "Epoch 72/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.6283 - mae: 880.6283 - val_loss: 854.9147 - val_mae: 854.9147\n",
      "Epoch 73/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.5938 - mae: 882.5938 - val_loss: 860.7875 - val_mae: 860.7875\n",
      "Epoch 74/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.5414 - mae: 881.5414 - val_loss: 855.5760 - val_mae: 855.5760\n",
      "Epoch 75/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.7458 - mae: 881.7458 - val_loss: 859.0766 - val_mae: 859.0766\n",
      "Epoch 76/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.4055 - mae: 882.4055 - val_loss: 856.6774 - val_mae: 856.6774\n",
      "Epoch 77/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.8986 - mae: 880.8986 - val_loss: 858.8596 - val_mae: 858.8596\n",
      "Epoch 78/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.1028 - mae: 881.1028 - val_loss: 856.1615 - val_mae: 856.1615\n",
      "Epoch 79/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.5990 - mae: 882.5990 - val_loss: 854.6168 - val_mae: 854.6168\n",
      "Epoch 80/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 881.7777 - mae: 881.7777 - val_loss: 859.6780 - val_mae: 859.6780\n",
      "Epoch 81/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 884.6296 - mae: 884.6296 - val_loss: 857.7234 - val_mae: 857.7234\n",
      "Epoch 82/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.7787 - mae: 881.7787 - val_loss: 857.2556 - val_mae: 857.2556\n",
      "Epoch 83/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.0802 - mae: 885.0802 - val_loss: 858.6491 - val_mae: 858.6491\n",
      "Epoch 84/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.3151 - mae: 882.3151 - val_loss: 857.5636 - val_mae: 857.5636\n",
      "Epoch 85/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.7465 - mae: 881.7465 - val_loss: 858.0040 - val_mae: 858.0040\n",
      "Epoch 86/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.1500 - mae: 882.1500 - val_loss: 860.9528 - val_mae: 860.9528\n",
      "Epoch 87/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.7762 - mae: 881.7762 - val_loss: 858.6008 - val_mae: 858.6008\n",
      "Epoch 88/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.6791 - mae: 880.6791 - val_loss: 861.0507 - val_mae: 861.0507\n",
      "Epoch 89/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.0020 - mae: 881.0020 - val_loss: 860.8643 - val_mae: 860.8643\n",
      "Epoch 90/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.3937 - mae: 880.3937 - val_loss: 855.5671 - val_mae: 855.5671\n",
      "Epoch 91/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.4604 - mae: 880.4604 - val_loss: 854.7744 - val_mae: 854.7744\n",
      "Epoch 92/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.1055 - mae: 881.1055 - val_loss: 855.1680 - val_mae: 855.1680\n",
      "Epoch 93/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.7534 - mae: 881.7534 - val_loss: 856.6514 - val_mae: 856.6514\n",
      "Epoch 94/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.3191 - mae: 880.3191 - val_loss: 860.8455 - val_mae: 860.8455\n",
      "Epoch 95/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.0706 - mae: 881.0706 - val_loss: 856.2327 - val_mae: 856.2327\n",
      "Epoch 96/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.0023 - mae: 883.0023 - val_loss: 858.1652 - val_mae: 858.1652\n",
      "Epoch 97/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.2708 - mae: 881.2708 - val_loss: 859.2891 - val_mae: 859.2891\n",
      "Epoch 98/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.5175 - mae: 880.5175 - val_loss: 857.3479 - val_mae: 857.3479\n",
      "Epoch 99/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.4200 - mae: 881.4200 - val_loss: 855.0391 - val_mae: 855.0391\n",
      "Epoch 100/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.6499 - mae: 880.6499 - val_loss: 855.5558 - val_mae: 855.5558\n",
      "Fold 1 - Loss: 855.5561, MAE: 855.5561\n",
      "Fold 2 / 5\n",
      "Epoch 1/100\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 2074.3684 - mae: 2074.3684 - val_loss: 1134.5205 - val_mae: 1134.5205\n",
      "Epoch 2/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 979.6486 - mae: 979.6486 - val_loss: 884.0308 - val_mae: 884.0308\n",
      "Epoch 3/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 891.9704 - mae: 891.9704 - val_loss: 861.5289 - val_mae: 861.5289\n",
      "Epoch 4/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.2917 - mae: 883.2917 - val_loss: 861.8554 - val_mae: 861.8554\n",
      "Epoch 5/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 887.0653 - mae: 887.0653 - val_loss: 864.4793 - val_mae: 864.4793\n",
      "Epoch 6/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 886.2548 - mae: 886.2548 - val_loss: 855.9253 - val_mae: 855.9253\n",
      "Epoch 7/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 886.3175 - mae: 886.3175 - val_loss: 855.5369 - val_mae: 855.5369\n",
      "Epoch 8/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.3212 - mae: 885.3212 - val_loss: 859.2169 - val_mae: 859.2169\n",
      "Epoch 9/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.8712 - mae: 883.8712 - val_loss: 858.7345 - val_mae: 858.7345\n",
      "Epoch 10/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.1688 - mae: 885.1688 - val_loss: 860.6509 - val_mae: 860.6509\n",
      "Epoch 11/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 885.5690 - mae: 885.5690 - val_loss: 858.0020 - val_mae: 858.0020\n",
      "Epoch 12/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.5823 - mae: 884.5823 - val_loss: 858.1285 - val_mae: 858.1285\n",
      "Epoch 13/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.9929 - mae: 884.9929 - val_loss: 857.6143 - val_mae: 857.6143\n",
      "Epoch 14/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.3679 - mae: 884.3679 - val_loss: 860.9385 - val_mae: 860.9385\n",
      "Epoch 15/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.5847 - mae: 885.5847 - val_loss: 860.8499 - val_mae: 860.8499\n",
      "Epoch 16/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.6646 - mae: 883.6646 - val_loss: 855.6669 - val_mae: 855.6669\n",
      "Epoch 17/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.2969 - mae: 882.2969 - val_loss: 857.1654 - val_mae: 857.1654\n",
      "Epoch 18/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.1284 - mae: 884.1284 - val_loss: 855.4835 - val_mae: 855.4835\n",
      "Epoch 19/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.1906 - mae: 883.1906 - val_loss: 856.1475 - val_mae: 856.1475\n",
      "Epoch 20/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.7175 - mae: 882.7175 - val_loss: 856.3471 - val_mae: 856.3471\n",
      "Epoch 21/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.4673 - mae: 880.4673 - val_loss: 856.5466 - val_mae: 856.5466\n",
      "Epoch 22/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.9941 - mae: 883.9941 - val_loss: 856.1165 - val_mae: 856.1165\n",
      "Epoch 23/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.8793 - mae: 883.8793 - val_loss: 857.3942 - val_mae: 857.3942\n",
      "Epoch 24/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.6024 - mae: 881.6024 - val_loss: 856.6328 - val_mae: 856.6328\n",
      "Epoch 25/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.2210 - mae: 884.2210 - val_loss: 859.6270 - val_mae: 859.6270\n",
      "Epoch 26/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.2191 - mae: 882.2191 - val_loss: 860.0548 - val_mae: 860.0548\n",
      "Epoch 27/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.8349 - mae: 883.8349 - val_loss: 865.5624 - val_mae: 865.5624\n",
      "Epoch 28/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.6495 - mae: 885.6495 - val_loss: 855.9470 - val_mae: 855.9470\n",
      "Epoch 29/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.6198 - mae: 884.6198 - val_loss: 857.1811 - val_mae: 857.1811\n",
      "Epoch 30/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.8724 - mae: 879.8724 - val_loss: 857.4664 - val_mae: 857.4664\n",
      "Epoch 31/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.4150 - mae: 882.4150 - val_loss: 855.2448 - val_mae: 855.2448\n",
      "Epoch 32/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.4311 - mae: 883.4311 - val_loss: 861.6057 - val_mae: 861.6057\n",
      "Epoch 33/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.1708 - mae: 882.1708 - val_loss: 855.3932 - val_mae: 855.3932\n",
      "Epoch 34/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.2415 - mae: 884.2415 - val_loss: 856.1686 - val_mae: 856.1686\n",
      "Epoch 35/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.9841 - mae: 882.9841 - val_loss: 861.6180 - val_mae: 861.6180\n",
      "Epoch 36/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.3108 - mae: 878.3108 - val_loss: 857.3174 - val_mae: 857.3174\n",
      "Epoch 37/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.6808 - mae: 882.6808 - val_loss: 857.2658 - val_mae: 857.2658\n",
      "Epoch 38/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.4818 - mae: 880.4818 - val_loss: 857.8110 - val_mae: 857.8110\n",
      "Epoch 39/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.3182 - mae: 881.3182 - val_loss: 860.5519 - val_mae: 860.5519\n",
      "Epoch 40/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.4042 - mae: 883.4042 - val_loss: 856.1713 - val_mae: 856.1713\n",
      "Epoch 41/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.5751 - mae: 883.5751 - val_loss: 855.5552 - val_mae: 855.5552\n",
      "Epoch 42/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.7773 - mae: 880.7773 - val_loss: 856.6552 - val_mae: 856.6552\n",
      "Epoch 43/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.7976 - mae: 881.7976 - val_loss: 856.4491 - val_mae: 856.4491\n",
      "Epoch 44/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.1672 - mae: 882.1672 - val_loss: 857.2772 - val_mae: 857.2772\n",
      "Epoch 45/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.1465 - mae: 881.1465 - val_loss: 858.1108 - val_mae: 858.1108\n",
      "Epoch 46/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 882.6643 - mae: 882.6643 - val_loss: 861.8289 - val_mae: 861.8289\n",
      "Epoch 47/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.8781 - mae: 880.8781 - val_loss: 862.8507 - val_mae: 862.8507\n",
      "Epoch 48/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.9595 - mae: 883.9595 - val_loss: 860.9153 - val_mae: 860.9153\n",
      "Epoch 49/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.2673 - mae: 882.2673 - val_loss: 858.5065 - val_mae: 858.5065\n",
      "Epoch 50/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.9825 - mae: 881.9825 - val_loss: 860.8639 - val_mae: 860.8639\n",
      "Epoch 51/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.1463 - mae: 882.1463 - val_loss: 854.6630 - val_mae: 854.6630\n",
      "Epoch 52/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.1592 - mae: 883.1592 - val_loss: 861.4594 - val_mae: 861.4594\n",
      "Epoch 53/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.3073 - mae: 880.3073 - val_loss: 854.2634 - val_mae: 854.2634\n",
      "Epoch 54/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 880.9569 - mae: 880.9569 - val_loss: 860.5021 - val_mae: 860.5021\n",
      "Epoch 55/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.8684 - mae: 880.8684 - val_loss: 853.9593 - val_mae: 853.9593\n",
      "Epoch 56/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 880.1716 - mae: 880.1716 - val_loss: 855.4033 - val_mae: 855.4033\n",
      "Epoch 57/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 883.0233 - mae: 883.0233 - val_loss: 857.1709 - val_mae: 857.1709\n",
      "Epoch 58/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.0030 - mae: 881.0030 - val_loss: 859.8190 - val_mae: 859.8190\n",
      "Epoch 59/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 882.8181 - mae: 882.8181 - val_loss: 856.0129 - val_mae: 856.0129\n",
      "Epoch 60/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 882.0031 - mae: 882.0031 - val_loss: 857.5115 - val_mae: 857.5115\n",
      "Epoch 61/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 882.0679 - mae: 882.0679 - val_loss: 856.4963 - val_mae: 856.4963\n",
      "Epoch 62/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.8920 - mae: 880.8920 - val_loss: 855.6752 - val_mae: 855.6752\n",
      "Epoch 63/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.6860 - mae: 882.6860 - val_loss: 860.0670 - val_mae: 860.0670\n",
      "Epoch 64/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.7271 - mae: 879.7271 - val_loss: 856.3808 - val_mae: 856.3808\n",
      "Epoch 65/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.3381 - mae: 883.3381 - val_loss: 857.9954 - val_mae: 857.9954\n",
      "Epoch 66/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.9440 - mae: 879.9440 - val_loss: 854.3936 - val_mae: 854.3936\n",
      "Epoch 67/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.4723 - mae: 883.4723 - val_loss: 859.9118 - val_mae: 859.9118\n",
      "Epoch 68/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.8804 - mae: 879.8804 - val_loss: 854.5547 - val_mae: 854.5547\n",
      "Epoch 69/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.6600 - mae: 879.6600 - val_loss: 858.4160 - val_mae: 858.4160\n",
      "Epoch 70/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.4720 - mae: 882.4720 - val_loss: 857.0724 - val_mae: 857.0724\n",
      "Epoch 71/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.2307 - mae: 880.2307 - val_loss: 858.2660 - val_mae: 858.2660\n",
      "Epoch 72/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.6379 - mae: 881.6379 - val_loss: 862.6445 - val_mae: 862.6445\n",
      "Epoch 73/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.1318 - mae: 881.1318 - val_loss: 854.3134 - val_mae: 854.3134\n",
      "Epoch 74/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 878.9821 - mae: 878.9821 - val_loss: 856.6370 - val_mae: 856.6370\n",
      "Epoch 75/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.6091 - mae: 879.6091 - val_loss: 853.8858 - val_mae: 853.8858\n",
      "Epoch 76/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.8788 - mae: 880.8788 - val_loss: 857.2279 - val_mae: 857.2279\n",
      "Epoch 77/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.1027 - mae: 882.1027 - val_loss: 857.7626 - val_mae: 857.7626\n",
      "Epoch 78/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.7380 - mae: 880.7380 - val_loss: 854.7590 - val_mae: 854.7590\n",
      "Epoch 79/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.4349 - mae: 882.4349 - val_loss: 854.9644 - val_mae: 854.9644\n",
      "Epoch 80/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.8140 - mae: 880.8140 - val_loss: 856.5941 - val_mae: 856.5941\n",
      "Epoch 81/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.5665 - mae: 880.5665 - val_loss: 860.1779 - val_mae: 860.1779\n",
      "Epoch 82/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.8028 - mae: 879.8028 - val_loss: 855.3988 - val_mae: 855.3988\n",
      "Epoch 83/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 880.7036 - mae: 880.7036 - val_loss: 853.7216 - val_mae: 853.7216\n",
      "Epoch 84/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.7124 - mae: 880.7124 - val_loss: 856.8890 - val_mae: 856.8890\n",
      "Epoch 85/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.6932 - mae: 881.6932 - val_loss: 856.0471 - val_mae: 856.0471\n",
      "Epoch 86/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.1473 - mae: 880.1473 - val_loss: 857.9536 - val_mae: 857.9536\n",
      "Epoch 87/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.8744 - mae: 880.8744 - val_loss: 854.9885 - val_mae: 854.9885\n",
      "Epoch 88/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.9039 - mae: 879.9039 - val_loss: 852.9871 - val_mae: 852.9871\n",
      "Epoch 89/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.2554 - mae: 879.2554 - val_loss: 855.3012 - val_mae: 855.3012\n",
      "Epoch 90/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 879.7919 - mae: 879.7919 - val_loss: 853.9403 - val_mae: 853.9403\n",
      "Epoch 91/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 879.8392 - mae: 879.8392 - val_loss: 858.1904 - val_mae: 858.1904\n",
      "Epoch 92/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 881.0900 - mae: 881.0900 - val_loss: 853.8655 - val_mae: 853.8655\n",
      "Epoch 93/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 880.4351 - mae: 880.4351 - val_loss: 853.2963 - val_mae: 853.2963\n",
      "Epoch 94/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 879.8643 - mae: 879.8643 - val_loss: 853.5639 - val_mae: 853.5639\n",
      "Epoch 95/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.2437 - mae: 880.2437 - val_loss: 854.3282 - val_mae: 854.3282\n",
      "Epoch 96/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.1982 - mae: 879.1982 - val_loss: 854.1235 - val_mae: 854.1235\n",
      "Epoch 97/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.5231 - mae: 878.5231 - val_loss: 852.3142 - val_mae: 852.3142\n",
      "Epoch 98/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.4532 - mae: 877.4532 - val_loss: 856.0964 - val_mae: 856.0964\n",
      "Epoch 99/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.0081 - mae: 877.0081 - val_loss: 851.9301 - val_mae: 851.9301\n",
      "Epoch 100/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.7379 - mae: 877.7379 - val_loss: 855.5980 - val_mae: 855.5980\n",
      "Fold 2 - Loss: 855.5978, MAE: 855.5978\n",
      "Fold 3 / 5\n",
      "Epoch 1/100\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 2049.8169 - mae: 2049.8169 - val_loss: 1089.2832 - val_mae: 1089.2832\n",
      "Epoch 2/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 970.5664 - mae: 970.5664 - val_loss: 872.8082 - val_mae: 872.8082\n",
      "Epoch 3/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 887.3270 - mae: 887.3270 - val_loss: 866.4218 - val_mae: 866.4218\n",
      "Epoch 4/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 886.4881 - mae: 886.4881 - val_loss: 862.3160 - val_mae: 862.3160\n",
      "Epoch 5/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 886.7667 - mae: 886.7667 - val_loss: 862.7942 - val_mae: 862.7942\n",
      "Epoch 6/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.5618 - mae: 883.5618 - val_loss: 867.0345 - val_mae: 867.0345\n",
      "Epoch 7/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.7987 - mae: 884.7987 - val_loss: 860.2793 - val_mae: 860.2793\n",
      "Epoch 8/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.9719 - mae: 878.9719 - val_loss: 865.1796 - val_mae: 865.1796\n",
      "Epoch 9/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.0517 - mae: 883.0517 - val_loss: 861.4274 - val_mae: 861.4274\n",
      "Epoch 10/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.8943 - mae: 884.8943 - val_loss: 862.8966 - val_mae: 862.8966\n",
      "Epoch 11/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.8691 - mae: 882.8691 - val_loss: 864.1626 - val_mae: 864.1626\n",
      "Epoch 12/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.1944 - mae: 880.1944 - val_loss: 863.4227 - val_mae: 863.4227\n",
      "Epoch 13/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.0639 - mae: 884.0639 - val_loss: 859.2028 - val_mae: 859.2028\n",
      "Epoch 14/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.2707 - mae: 882.2707 - val_loss: 866.1733 - val_mae: 866.1733\n",
      "Epoch 15/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.1101 - mae: 883.1101 - val_loss: 865.7343 - val_mae: 865.7343\n",
      "Epoch 16/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.9926 - mae: 881.9926 - val_loss: 861.4859 - val_mae: 861.4859\n",
      "Epoch 17/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.6959 - mae: 883.6959 - val_loss: 862.3629 - val_mae: 862.3629\n",
      "Epoch 18/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.4683 - mae: 881.4683 - val_loss: 867.5425 - val_mae: 867.5425\n",
      "Epoch 19/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 879.3132 - mae: 879.3132 - val_loss: 861.4652 - val_mae: 861.4652\n",
      "Epoch 20/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 882.7800 - mae: 882.7800 - val_loss: 867.1143 - val_mae: 867.1143\n",
      "Epoch 21/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.7598 - mae: 880.7598 - val_loss: 858.7779 - val_mae: 858.7779\n",
      "Epoch 22/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 883.4258 - mae: 883.4258 - val_loss: 861.3022 - val_mae: 861.3022\n",
      "Epoch 23/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.3622 - mae: 881.3622 - val_loss: 861.7702 - val_mae: 861.7702\n",
      "Epoch 24/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.0598 - mae: 880.0598 - val_loss: 860.1121 - val_mae: 860.1121\n",
      "Epoch 25/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.8923 - mae: 880.8923 - val_loss: 861.6033 - val_mae: 861.6033\n",
      "Epoch 26/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.5392 - mae: 879.5392 - val_loss: 861.3685 - val_mae: 861.3685\n",
      "Epoch 27/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.6998 - mae: 883.6998 - val_loss: 862.9487 - val_mae: 862.9487\n",
      "Epoch 28/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.8782 - mae: 881.8782 - val_loss: 859.6880 - val_mae: 859.6880\n",
      "Epoch 29/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.0397 - mae: 883.0397 - val_loss: 864.1394 - val_mae: 864.1394\n",
      "Epoch 30/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.2321 - mae: 883.2321 - val_loss: 860.7092 - val_mae: 860.7092\n",
      "Epoch 31/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 881.2168 - mae: 881.2168 - val_loss: 858.6382 - val_mae: 858.6382\n",
      "Epoch 32/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.8383 - mae: 883.8383 - val_loss: 859.9804 - val_mae: 859.9804\n",
      "Epoch 33/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.6570 - mae: 879.6570 - val_loss: 864.4740 - val_mae: 864.4740\n",
      "Epoch 34/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.5362 - mae: 880.5362 - val_loss: 862.8812 - val_mae: 862.8812\n",
      "Epoch 35/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.6461 - mae: 882.6461 - val_loss: 860.4817 - val_mae: 860.4817\n",
      "Epoch 36/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.4568 - mae: 880.4568 - val_loss: 861.5804 - val_mae: 861.5804\n",
      "Epoch 37/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.8089 - mae: 879.8089 - val_loss: 861.7837 - val_mae: 861.7837\n",
      "Epoch 38/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.0446 - mae: 881.0446 - val_loss: 863.3849 - val_mae: 863.3849\n",
      "Epoch 39/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.4102 - mae: 880.4102 - val_loss: 862.2538 - val_mae: 862.2538\n",
      "Epoch 40/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.1008 - mae: 881.1008 - val_loss: 865.3614 - val_mae: 865.3614\n",
      "Epoch 41/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.9786 - mae: 881.9786 - val_loss: 863.5114 - val_mae: 863.5114\n",
      "Epoch 42/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.7647 - mae: 883.7647 - val_loss: 858.4887 - val_mae: 858.4887\n",
      "Epoch 43/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.1583 - mae: 882.1583 - val_loss: 863.9530 - val_mae: 863.9530\n",
      "Epoch 44/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.6973 - mae: 880.6973 - val_loss: 861.6577 - val_mae: 861.6577\n",
      "Epoch 45/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.6806 - mae: 880.6806 - val_loss: 860.2745 - val_mae: 860.2745\n",
      "Epoch 46/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.0906 - mae: 881.0906 - val_loss: 863.2720 - val_mae: 863.2720\n",
      "Epoch 47/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.3104 - mae: 880.3104 - val_loss: 858.9907 - val_mae: 858.9907\n",
      "Epoch 48/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.6499 - mae: 881.6499 - val_loss: 859.3209 - val_mae: 859.3209\n",
      "Epoch 49/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.9889 - mae: 880.9889 - val_loss: 867.6612 - val_mae: 867.6612\n",
      "Epoch 50/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.0187 - mae: 883.0187 - val_loss: 862.1887 - val_mae: 862.1887\n",
      "Epoch 51/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.4545 - mae: 878.4545 - val_loss: 862.2016 - val_mae: 862.2016\n",
      "Epoch 52/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.1995 - mae: 881.1995 - val_loss: 858.2300 - val_mae: 858.2300\n",
      "Epoch 53/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.6523 - mae: 880.6523 - val_loss: 862.5651 - val_mae: 862.5651\n",
      "Epoch 54/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.6088 - mae: 881.6088 - val_loss: 858.6270 - val_mae: 858.6270\n",
      "Epoch 55/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.6762 - mae: 882.6762 - val_loss: 860.7768 - val_mae: 860.7768\n",
      "Epoch 56/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.8995 - mae: 879.8995 - val_loss: 858.4797 - val_mae: 858.4797\n",
      "Epoch 57/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.9055 - mae: 879.9055 - val_loss: 861.0880 - val_mae: 861.0880\n",
      "Epoch 58/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.6663 - mae: 881.6663 - val_loss: 860.6910 - val_mae: 860.6910\n",
      "Epoch 59/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.3396 - mae: 882.3396 - val_loss: 863.2200 - val_mae: 863.2200\n",
      "Epoch 60/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.6826 - mae: 877.6826 - val_loss: 860.1207 - val_mae: 860.1207\n",
      "Epoch 61/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.3011 - mae: 879.3011 - val_loss: 858.5788 - val_mae: 858.5788\n",
      "Epoch 62/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.3392 - mae: 880.3392 - val_loss: 859.6105 - val_mae: 859.6105\n",
      "Epoch 63/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.7859 - mae: 880.7859 - val_loss: 861.3445 - val_mae: 861.3445\n",
      "Epoch 64/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.3771 - mae: 880.3771 - val_loss: 857.9414 - val_mae: 857.9414\n",
      "Epoch 65/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.2393 - mae: 880.2393 - val_loss: 860.6259 - val_mae: 860.6259\n",
      "Epoch 66/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.3262 - mae: 877.3262 - val_loss: 858.6302 - val_mae: 858.6302\n",
      "Epoch 67/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.2820 - mae: 880.2820 - val_loss: 860.1577 - val_mae: 860.1577\n",
      "Epoch 68/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.7072 - mae: 877.7072 - val_loss: 862.1625 - val_mae: 862.1625\n",
      "Epoch 69/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.7965 - mae: 877.7965 - val_loss: 857.1123 - val_mae: 857.1123\n",
      "Epoch 70/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.6742 - mae: 878.6742 - val_loss: 860.6649 - val_mae: 860.6649\n",
      "Epoch 71/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.6786 - mae: 879.6786 - val_loss: 857.7802 - val_mae: 857.7802\n",
      "Epoch 72/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.1119 - mae: 882.1119 - val_loss: 856.7903 - val_mae: 856.7903\n",
      "Epoch 73/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.4819 - mae: 878.4819 - val_loss: 860.4393 - val_mae: 860.4393\n",
      "Epoch 74/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.3887 - mae: 881.3887 - val_loss: 861.6195 - val_mae: 861.6195\n",
      "Epoch 75/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 875.7549 - mae: 875.7549 - val_loss: 858.7869 - val_mae: 858.7869\n",
      "Epoch 76/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.4162 - mae: 877.4162 - val_loss: 861.6840 - val_mae: 861.6840\n",
      "Epoch 77/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.5965 - mae: 880.5965 - val_loss: 857.5017 - val_mae: 857.5017\n",
      "Epoch 78/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.9539 - mae: 877.9539 - val_loss: 859.8174 - val_mae: 859.8174\n",
      "Epoch 79/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 875.2631 - mae: 875.2631 - val_loss: 860.3661 - val_mae: 860.3661\n",
      "Epoch 80/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.4948 - mae: 876.4948 - val_loss: 860.5939 - val_mae: 860.5939\n",
      "Epoch 81/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.7150 - mae: 878.7150 - val_loss: 856.9312 - val_mae: 856.9312\n",
      "Epoch 82/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 875.5149 - mae: 875.5149 - val_loss: 861.9094 - val_mae: 861.9094\n",
      "Epoch 83/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.0573 - mae: 878.0573 - val_loss: 859.2795 - val_mae: 859.2795\n",
      "Epoch 84/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.5508 - mae: 878.5508 - val_loss: 863.3564 - val_mae: 863.3564\n",
      "Epoch 85/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 875.9087 - mae: 875.9087 - val_loss: 856.1384 - val_mae: 856.1384\n",
      "Epoch 86/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 875.3206 - mae: 875.3206 - val_loss: 858.0435 - val_mae: 858.0435\n",
      "Epoch 87/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.5593 - mae: 876.5593 - val_loss: 858.2481 - val_mae: 858.2481\n",
      "Epoch 88/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.4456 - mae: 878.4456 - val_loss: 858.4326 - val_mae: 858.4326\n",
      "Epoch 89/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.3071 - mae: 877.3071 - val_loss: 856.3132 - val_mae: 856.3132\n",
      "Epoch 90/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.3164 - mae: 876.3164 - val_loss: 855.0532 - val_mae: 855.0532\n",
      "Epoch 91/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 877.3233 - mae: 877.3233 - val_loss: 856.4462 - val_mae: 856.4462\n",
      "Epoch 92/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 875.0772 - mae: 875.0772 - val_loss: 857.2642 - val_mae: 857.2642\n",
      "Epoch 93/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.0141 - mae: 879.0141 - val_loss: 864.8354 - val_mae: 864.8354\n",
      "Epoch 94/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 874.9832 - mae: 874.9832 - val_loss: 854.6396 - val_mae: 854.6396\n",
      "Epoch 95/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 874.3546 - mae: 874.3546 - val_loss: 855.8001 - val_mae: 855.8001\n",
      "Epoch 96/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 875.4701 - mae: 875.4701 - val_loss: 855.8936 - val_mae: 855.8936\n",
      "Epoch 97/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.6998 - mae: 876.6998 - val_loss: 855.6050 - val_mae: 855.6050\n",
      "Epoch 98/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 874.7231 - mae: 874.7231 - val_loss: 854.2498 - val_mae: 854.2498\n",
      "Epoch 99/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.4757 - mae: 877.4757 - val_loss: 860.2068 - val_mae: 860.2068\n",
      "Epoch 100/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 874.5393 - mae: 874.5393 - val_loss: 855.4614 - val_mae: 855.4614\n",
      "Fold 3 - Loss: 855.4616, MAE: 855.4616\n",
      "Fold 4 / 5\n",
      "Epoch 1/100\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 2028.4626 - mae: 2028.4626 - val_loss: 1104.5242 - val_mae: 1104.5242\n",
      "Epoch 2/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 974.5633 - mae: 974.5633 - val_loss: 889.8689 - val_mae: 889.8689\n",
      "Epoch 3/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 887.3264 - mae: 887.3264 - val_loss: 874.5682 - val_mae: 874.5682\n",
      "Epoch 4/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.3446 - mae: 881.3446 - val_loss: 874.8174 - val_mae: 874.8174\n",
      "Epoch 5/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 880.8524 - mae: 880.8524 - val_loss: 870.8204 - val_mae: 870.8204\n",
      "Epoch 6/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.0818 - mae: 884.0818 - val_loss: 872.8633 - val_mae: 872.8633\n",
      "Epoch 7/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.4093 - mae: 880.4093 - val_loss: 871.5547 - val_mae: 871.5547\n",
      "Epoch 8/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 881.7667 - mae: 881.7667 - val_loss: 870.2745 - val_mae: 870.2745\n",
      "Epoch 9/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.6151 - mae: 882.6151 - val_loss: 871.1102 - val_mae: 871.1102\n",
      "Epoch 10/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.5009 - mae: 883.5009 - val_loss: 870.3538 - val_mae: 870.3538\n",
      "Epoch 11/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.4171 - mae: 880.4171 - val_loss: 869.0900 - val_mae: 869.0900\n",
      "Epoch 12/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.3369 - mae: 882.3369 - val_loss: 874.4222 - val_mae: 874.4222\n",
      "Epoch 13/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.1397 - mae: 880.1397 - val_loss: 872.0176 - val_mae: 872.0176\n",
      "Epoch 14/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.5529 - mae: 879.5529 - val_loss: 870.5627 - val_mae: 870.5627\n",
      "Epoch 15/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.7950 - mae: 878.7950 - val_loss: 869.7274 - val_mae: 869.7274\n",
      "Epoch 16/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 879.7504 - mae: 879.7504 - val_loss: 872.4734 - val_mae: 872.4734\n",
      "Epoch 17/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.3004 - mae: 878.3004 - val_loss: 870.2571 - val_mae: 870.2571\n",
      "Epoch 18/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.4686 - mae: 879.4686 - val_loss: 869.3102 - val_mae: 869.3102\n",
      "Epoch 19/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.6829 - mae: 878.6829 - val_loss: 871.9622 - val_mae: 871.9622\n",
      "Epoch 20/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.6486 - mae: 880.6486 - val_loss: 873.3524 - val_mae: 873.3524\n",
      "Epoch 21/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.7605 - mae: 879.7605 - val_loss: 876.7730 - val_mae: 876.7730\n",
      "Epoch 22/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.5675 - mae: 879.5675 - val_loss: 875.5101 - val_mae: 875.5101\n",
      "Epoch 23/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.7906 - mae: 879.7906 - val_loss: 871.2331 - val_mae: 871.2331\n",
      "Epoch 24/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.1391 - mae: 879.1391 - val_loss: 869.3335 - val_mae: 869.3335\n",
      "Epoch 25/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.6401 - mae: 879.6401 - val_loss: 873.8380 - val_mae: 873.8380\n",
      "Epoch 26/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.3351 - mae: 878.3351 - val_loss: 869.2936 - val_mae: 869.2936\n",
      "Epoch 27/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 878.4851 - mae: 878.4851 - val_loss: 870.6228 - val_mae: 870.6228\n",
      "Epoch 28/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 875.6819 - mae: 875.6819 - val_loss: 872.5817 - val_mae: 872.5817\n",
      "Epoch 29/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 880.0272 - mae: 880.0272 - val_loss: 871.5280 - val_mae: 871.5280\n",
      "Epoch 30/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.5593 - mae: 878.5593 - val_loss: 870.1000 - val_mae: 870.1000\n",
      "Epoch 31/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.9629 - mae: 877.9629 - val_loss: 869.3732 - val_mae: 869.3732\n",
      "Epoch 32/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.3714 - mae: 876.3714 - val_loss: 871.6268 - val_mae: 871.6268\n",
      "Epoch 33/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.6566 - mae: 879.6566 - val_loss: 869.9247 - val_mae: 869.9247\n",
      "Epoch 34/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.5957 - mae: 876.5957 - val_loss: 870.3530 - val_mae: 870.3530\n",
      "Epoch 35/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.5522 - mae: 879.5522 - val_loss: 869.7798 - val_mae: 869.7798\n",
      "Epoch 36/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.5443 - mae: 877.5443 - val_loss: 872.7502 - val_mae: 872.7502\n",
      "Epoch 37/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.7088 - mae: 878.7088 - val_loss: 869.1456 - val_mae: 869.1456\n",
      "Epoch 38/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.2943 - mae: 878.2943 - val_loss: 869.7089 - val_mae: 869.7089\n",
      "Epoch 39/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.5128 - mae: 877.5128 - val_loss: 869.0978 - val_mae: 869.0978\n",
      "Epoch 40/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.0840 - mae: 880.0840 - val_loss: 869.4142 - val_mae: 869.4142\n",
      "Epoch 41/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 875.4417 - mae: 875.4417 - val_loss: 869.2004 - val_mae: 869.2004\n",
      "Epoch 42/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.4683 - mae: 878.4683 - val_loss: 870.9162 - val_mae: 870.9162\n",
      "Epoch 43/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.8816 - mae: 876.8816 - val_loss: 868.4941 - val_mae: 868.4941\n",
      "Epoch 44/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.3076 - mae: 877.3076 - val_loss: 871.9850 - val_mae: 871.9850\n",
      "Epoch 45/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.6320 - mae: 879.6320 - val_loss: 872.2900 - val_mae: 872.2900\n",
      "Epoch 46/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 873.8912 - mae: 873.8912 - val_loss: 872.9891 - val_mae: 872.9891\n",
      "Epoch 47/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.3859 - mae: 876.3859 - val_loss: 874.1544 - val_mae: 874.1544\n",
      "Epoch 48/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.0768 - mae: 876.0768 - val_loss: 874.7014 - val_mae: 874.7014\n",
      "Epoch 49/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.4366 - mae: 878.4366 - val_loss: 871.0988 - val_mae: 871.0988\n",
      "Epoch 50/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.1136 - mae: 876.1136 - val_loss: 870.8016 - val_mae: 870.8016\n",
      "Epoch 51/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.0952 - mae: 877.0952 - val_loss: 868.3325 - val_mae: 868.3325\n",
      "Epoch 52/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.2592 - mae: 876.2592 - val_loss: 869.4728 - val_mae: 869.4728\n",
      "Epoch 53/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.5296 - mae: 876.5296 - val_loss: 867.3979 - val_mae: 867.3979\n",
      "Epoch 54/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 875.0704 - mae: 875.0704 - val_loss: 868.8581 - val_mae: 868.8581\n",
      "Epoch 55/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.7284 - mae: 876.7284 - val_loss: 867.8170 - val_mae: 867.8170\n",
      "Epoch 56/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.4750 - mae: 876.4750 - val_loss: 866.7433 - val_mae: 866.7433\n",
      "Epoch 57/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 875.2110 - mae: 875.2110 - val_loss: 867.3687 - val_mae: 867.3687\n",
      "Epoch 58/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 875.1033 - mae: 875.1033 - val_loss: 869.9500 - val_mae: 869.9500\n",
      "Epoch 59/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 875.8878 - mae: 875.8878 - val_loss: 871.0766 - val_mae: 871.0766\n",
      "Epoch 60/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.7510 - mae: 876.7510 - val_loss: 866.0677 - val_mae: 866.0677\n",
      "Epoch 61/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 875.6705 - mae: 875.6705 - val_loss: 869.5615 - val_mae: 869.5615\n",
      "Epoch 62/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.9070 - mae: 876.9070 - val_loss: 867.7775 - val_mae: 867.7775\n",
      "Epoch 63/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.2688 - mae: 877.2688 - val_loss: 871.8749 - val_mae: 871.8749\n",
      "Epoch 64/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.0700 - mae: 877.0700 - val_loss: 869.2325 - val_mae: 869.2325\n",
      "Epoch 65/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.0618 - mae: 876.0618 - val_loss: 867.1419 - val_mae: 867.1419\n",
      "Epoch 66/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 875.6081 - mae: 875.6081 - val_loss: 866.5106 - val_mae: 866.5106\n",
      "Epoch 67/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 873.1603 - mae: 873.1603 - val_loss: 870.0164 - val_mae: 870.0164\n",
      "Epoch 68/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 874.0422 - mae: 874.0422 - val_loss: 869.6805 - val_mae: 869.6805\n",
      "Epoch 69/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.7981 - mae: 877.7981 - val_loss: 866.6973 - val_mae: 866.6973\n",
      "Epoch 70/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.5490 - mae: 876.5490 - val_loss: 867.4454 - val_mae: 867.4454\n",
      "Epoch 71/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.9188 - mae: 876.9188 - val_loss: 868.9058 - val_mae: 868.9058\n",
      "Epoch 72/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 874.9460 - mae: 874.9460 - val_loss: 868.7829 - val_mae: 868.7829\n",
      "Epoch 73/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 873.3640 - mae: 873.3640 - val_loss: 866.4653 - val_mae: 866.4653\n",
      "Epoch 74/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 873.5109 - mae: 873.5109 - val_loss: 868.2009 - val_mae: 868.2009\n",
      "Epoch 75/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 871.7714 - mae: 871.7714 - val_loss: 866.0491 - val_mae: 866.0491\n",
      "Epoch 76/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 873.1431 - mae: 873.1431 - val_loss: 865.2899 - val_mae: 865.2899\n",
      "Epoch 77/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 874.2290 - mae: 874.2290 - val_loss: 873.7323 - val_mae: 873.7323\n",
      "Epoch 78/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 873.5143 - mae: 873.5143 - val_loss: 866.6057 - val_mae: 866.6057\n",
      "Epoch 79/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 874.1404 - mae: 874.1404 - val_loss: 864.2623 - val_mae: 864.2623\n",
      "Epoch 80/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 875.7059 - mae: 875.7059 - val_loss: 868.3517 - val_mae: 868.3517\n",
      "Epoch 81/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 875.5260 - mae: 875.5260 - val_loss: 867.7172 - val_mae: 867.7172\n",
      "Epoch 82/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 875.3907 - mae: 875.3907 - val_loss: 868.9155 - val_mae: 868.9155\n",
      "Epoch 83/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 872.0411 - mae: 872.0411 - val_loss: 869.3333 - val_mae: 869.3333\n",
      "Epoch 84/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 875.7607 - mae: 875.7607 - val_loss: 866.5179 - val_mae: 866.5179\n",
      "Epoch 85/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 874.9742 - mae: 874.9742 - val_loss: 871.2236 - val_mae: 871.2236\n",
      "Epoch 86/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 871.8326 - mae: 871.8326 - val_loss: 864.1810 - val_mae: 864.1810\n",
      "Epoch 87/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 875.0327 - mae: 875.0327 - val_loss: 873.4002 - val_mae: 873.4002\n",
      "Epoch 88/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 872.6007 - mae: 872.6007 - val_loss: 864.2277 - val_mae: 864.2277\n",
      "Epoch 89/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 874.8026 - mae: 874.8026 - val_loss: 864.4600 - val_mae: 864.4600\n",
      "Epoch 90/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 870.3564 - mae: 870.3564 - val_loss: 869.2949 - val_mae: 869.2949\n",
      "Epoch 91/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 872.1069 - mae: 872.1069 - val_loss: 865.2877 - val_mae: 865.2877\n",
      "Epoch 92/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 873.2988 - mae: 873.2988 - val_loss: 865.1121 - val_mae: 865.1121\n",
      "Epoch 93/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 873.1419 - mae: 873.1419 - val_loss: 864.1458 - val_mae: 864.1458\n",
      "Epoch 94/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 873.4902 - mae: 873.4902 - val_loss: 864.7365 - val_mae: 864.7365\n",
      "Epoch 95/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 872.7907 - mae: 872.7907 - val_loss: 867.0613 - val_mae: 867.0613\n",
      "Epoch 96/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 871.9569 - mae: 871.9569 - val_loss: 865.5777 - val_mae: 865.5777\n",
      "Epoch 97/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 872.9589 - mae: 872.9589 - val_loss: 865.7909 - val_mae: 865.7909\n",
      "Epoch 98/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 873.1425 - mae: 873.1425 - val_loss: 865.5461 - val_mae: 865.5461\n",
      "Epoch 99/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 873.2057 - mae: 873.2057 - val_loss: 862.7961 - val_mae: 862.7961\n",
      "Epoch 100/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 873.0196 - mae: 873.0196 - val_loss: 866.0425 - val_mae: 866.0425\n",
      "Fold 4 - Loss: 866.0425, MAE: 866.0425\n",
      "Fold 5 / 5\n",
      "Epoch 1/100\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 2123.0896 - mae: 2123.0896 - val_loss: 1094.4419 - val_mae: 1094.4419\n",
      "Epoch 2/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 990.3653 - mae: 990.3653 - val_loss: 865.3053 - val_mae: 865.3053\n",
      "Epoch 3/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 894.4374 - mae: 894.4374 - val_loss: 848.0511 - val_mae: 848.0511\n",
      "Epoch 4/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 891.0125 - mae: 891.0125 - val_loss: 848.0674 - val_mae: 848.0674\n",
      "Epoch 5/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 889.3084 - mae: 889.3084 - val_loss: 843.4136 - val_mae: 843.4136\n",
      "Epoch 6/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 886.4496 - mae: 886.4496 - val_loss: 844.1095 - val_mae: 844.1095\n",
      "Epoch 7/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 889.1030 - mae: 889.1030 - val_loss: 844.6895 - val_mae: 844.6895\n",
      "Epoch 8/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 889.1714 - mae: 889.1714 - val_loss: 846.0936 - val_mae: 846.0936\n",
      "Epoch 9/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 890.5181 - mae: 890.5181 - val_loss: 843.9568 - val_mae: 843.9568\n",
      "Epoch 10/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 886.2321 - mae: 886.2321 - val_loss: 843.3146 - val_mae: 843.3146\n",
      "Epoch 11/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 886.9884 - mae: 886.9884 - val_loss: 846.3915 - val_mae: 846.3915\n",
      "Epoch 12/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 886.6465 - mae: 886.6465 - val_loss: 848.0894 - val_mae: 848.0894\n",
      "Epoch 13/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 888.8364 - mae: 888.8364 - val_loss: 849.3698 - val_mae: 849.3698\n",
      "Epoch 14/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 886.6226 - mae: 886.6226 - val_loss: 849.3613 - val_mae: 849.3613\n",
      "Epoch 15/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 886.5975 - mae: 886.5975 - val_loss: 846.0904 - val_mae: 846.0904\n",
      "Epoch 16/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 888.0441 - mae: 888.0441 - val_loss: 843.7577 - val_mae: 843.7577\n",
      "Epoch 17/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 887.3306 - mae: 887.3306 - val_loss: 844.1644 - val_mae: 844.1644\n",
      "Epoch 18/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 887.3041 - mae: 887.3041 - val_loss: 844.2065 - val_mae: 844.2065\n",
      "Epoch 19/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.2435 - mae: 885.2435 - val_loss: 845.1058 - val_mae: 845.1058\n",
      "Epoch 20/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 887.9554 - mae: 887.9554 - val_loss: 841.9059 - val_mae: 841.9059\n",
      "Epoch 21/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 884.1544 - mae: 884.1544 - val_loss: 844.1050 - val_mae: 844.1050\n",
      "Epoch 22/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 887.2216 - mae: 887.2216 - val_loss: 848.5030 - val_mae: 848.5030\n",
      "Epoch 23/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 885.5088 - mae: 885.5088 - val_loss: 844.2168 - val_mae: 844.2168\n",
      "Epoch 24/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 883.7619 - mae: 883.7619 - val_loss: 844.4319 - val_mae: 844.4319\n",
      "Epoch 25/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 885.9781 - mae: 885.9781 - val_loss: 843.4928 - val_mae: 843.4928\n",
      "Epoch 26/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.6798 - mae: 885.6798 - val_loss: 842.3287 - val_mae: 842.3287\n",
      "Epoch 27/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 887.6537 - mae: 887.6537 - val_loss: 842.2780 - val_mae: 842.2780\n",
      "Epoch 28/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 888.0849 - mae: 888.0849 - val_loss: 843.5417 - val_mae: 843.5417\n",
      "Epoch 29/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.9461 - mae: 884.9461 - val_loss: 842.5743 - val_mae: 842.5743\n",
      "Epoch 30/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 887.2798 - mae: 887.2798 - val_loss: 843.9981 - val_mae: 843.9981\n",
      "Epoch 31/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 887.4435 - mae: 887.4435 - val_loss: 844.3128 - val_mae: 844.3128\n",
      "Epoch 32/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.2775 - mae: 885.2775 - val_loss: 849.5304 - val_mae: 849.5304\n",
      "Epoch 33/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 886.6099 - mae: 886.6099 - val_loss: 845.2846 - val_mae: 845.2846\n",
      "Epoch 34/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 886.4216 - mae: 886.4216 - val_loss: 842.2691 - val_mae: 842.2691\n",
      "Epoch 35/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.8201 - mae: 885.8201 - val_loss: 843.5270 - val_mae: 843.5270\n",
      "Epoch 36/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.9965 - mae: 884.9965 - val_loss: 844.1241 - val_mae: 844.1241\n",
      "Epoch 37/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 887.8177 - mae: 887.8177 - val_loss: 843.9224 - val_mae: 843.9224\n",
      "Epoch 38/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.2125 - mae: 884.2125 - val_loss: 844.9241 - val_mae: 844.9241\n",
      "Epoch 39/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.0919 - mae: 882.0919 - val_loss: 845.9023 - val_mae: 845.9023\n",
      "Epoch 40/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.1691 - mae: 883.1691 - val_loss: 847.8110 - val_mae: 847.8110\n",
      "Epoch 41/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.1765 - mae: 883.1765 - val_loss: 843.0386 - val_mae: 843.0386\n",
      "Epoch 42/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.3577 - mae: 885.3577 - val_loss: 845.3000 - val_mae: 845.3000\n",
      "Epoch 43/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.3624 - mae: 884.3624 - val_loss: 841.1364 - val_mae: 841.1364\n",
      "Epoch 44/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.4511 - mae: 884.4511 - val_loss: 843.0807 - val_mae: 843.0807\n",
      "Epoch 45/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.1436 - mae: 885.1436 - val_loss: 840.3731 - val_mae: 840.3731\n",
      "Epoch 46/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.2206 - mae: 883.2206 - val_loss: 840.9899 - val_mae: 840.9899\n",
      "Epoch 47/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.3474 - mae: 884.3474 - val_loss: 841.5692 - val_mae: 841.5692\n",
      "Epoch 48/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.8069 - mae: 882.8069 - val_loss: 840.1973 - val_mae: 840.1973\n",
      "Epoch 49/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.7622 - mae: 883.7622 - val_loss: 847.2915 - val_mae: 847.2915\n",
      "Epoch 50/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.9183 - mae: 885.9183 - val_loss: 842.3557 - val_mae: 842.3557\n",
      "Epoch 51/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.4531 - mae: 883.4531 - val_loss: 841.0583 - val_mae: 841.0583\n",
      "Epoch 52/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 882.5547 - mae: 882.5547 - val_loss: 842.0600 - val_mae: 842.0600\n",
      "Epoch 53/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.6581 - mae: 883.6581 - val_loss: 845.5264 - val_mae: 845.5264\n",
      "Epoch 54/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.5147 - mae: 882.5147 - val_loss: 843.2070 - val_mae: 843.2070\n",
      "Epoch 55/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.7189 - mae: 883.7189 - val_loss: 845.0869 - val_mae: 845.0869\n",
      "Epoch 56/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.7607 - mae: 881.7607 - val_loss: 839.6004 - val_mae: 839.6004\n",
      "Epoch 57/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.9797 - mae: 883.9797 - val_loss: 838.7327 - val_mae: 838.7327\n",
      "Epoch 58/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.6899 - mae: 880.6899 - val_loss: 838.1149 - val_mae: 838.1149\n",
      "Epoch 59/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.4725 - mae: 884.4725 - val_loss: 839.1120 - val_mae: 839.1120\n",
      "Epoch 60/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.5668 - mae: 883.5668 - val_loss: 837.7305 - val_mae: 837.7305\n",
      "Epoch 61/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.6860 - mae: 880.6860 - val_loss: 839.4130 - val_mae: 839.4130\n",
      "Epoch 62/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.0965 - mae: 880.0965 - val_loss: 837.7471 - val_mae: 837.7471\n",
      "Epoch 63/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.5952 - mae: 880.5952 - val_loss: 839.9582 - val_mae: 839.9582\n",
      "Epoch 64/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.4810 - mae: 880.4810 - val_loss: 844.7946 - val_mae: 844.7946\n",
      "Epoch 65/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.7041 - mae: 882.7041 - val_loss: 839.3674 - val_mae: 839.3674\n",
      "Epoch 66/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.3611 - mae: 885.3611 - val_loss: 837.5620 - val_mae: 837.5620\n",
      "Epoch 67/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.6359 - mae: 881.6359 - val_loss: 838.9366 - val_mae: 838.9366\n",
      "Epoch 68/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.5893 - mae: 882.5893 - val_loss: 844.7451 - val_mae: 844.7451\n",
      "Epoch 69/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.5433 - mae: 883.5433 - val_loss: 837.1982 - val_mae: 837.1982\n",
      "Epoch 70/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.9813 - mae: 882.9813 - val_loss: 837.3923 - val_mae: 837.3923\n",
      "Epoch 71/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.5587 - mae: 882.5587 - val_loss: 839.9435 - val_mae: 839.9435\n",
      "Epoch 72/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.5775 - mae: 882.5775 - val_loss: 837.9237 - val_mae: 837.9237\n",
      "Epoch 73/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.1747 - mae: 882.1747 - val_loss: 837.2933 - val_mae: 837.2933\n",
      "Epoch 74/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.3440 - mae: 881.3440 - val_loss: 840.6646 - val_mae: 840.6646\n",
      "Epoch 75/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.9454 - mae: 881.9454 - val_loss: 839.8153 - val_mae: 839.8153\n",
      "Epoch 76/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.4752 - mae: 881.4752 - val_loss: 836.7750 - val_mae: 836.7750\n",
      "Epoch 77/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.9263 - mae: 881.9263 - val_loss: 838.1062 - val_mae: 838.1062\n",
      "Epoch 78/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 880.2656 - mae: 880.2656 - val_loss: 838.5880 - val_mae: 838.5880\n",
      "Epoch 79/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.6699 - mae: 880.6699 - val_loss: 841.9652 - val_mae: 841.9652\n",
      "Epoch 80/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 884.1306 - mae: 884.1306 - val_loss: 841.4620 - val_mae: 841.4620\n",
      "Epoch 81/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 882.4528 - mae: 882.4528 - val_loss: 842.3133 - val_mae: 842.3133\n",
      "Epoch 82/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.7244 - mae: 882.7244 - val_loss: 838.3478 - val_mae: 838.3478\n",
      "Epoch 83/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 883.3394 - mae: 883.3394 - val_loss: 839.4411 - val_mae: 839.4411\n",
      "Epoch 84/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 881.4976 - mae: 881.4976 - val_loss: 842.4625 - val_mae: 842.4625\n",
      "Epoch 85/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.4677 - mae: 879.4677 - val_loss: 845.1695 - val_mae: 845.1695\n",
      "Epoch 86/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 879.9585 - mae: 879.9585 - val_loss: 839.8814 - val_mae: 839.8814\n",
      "Epoch 87/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 880.2636 - mae: 880.2636 - val_loss: 836.9963 - val_mae: 836.9963\n",
      "Epoch 88/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 881.0618 - mae: 881.0618 - val_loss: 842.5406 - val_mae: 842.5406\n",
      "Epoch 89/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 880.9093 - mae: 880.9093 - val_loss: 840.9368 - val_mae: 840.9368\n",
      "Epoch 90/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 881.8687 - mae: 881.8687 - val_loss: 837.9057 - val_mae: 837.9057\n",
      "Epoch 91/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 880.9831 - mae: 880.9831 - val_loss: 839.0450 - val_mae: 839.0450\n",
      "Epoch 92/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 880.2721 - mae: 880.2721 - val_loss: 838.0326 - val_mae: 838.0326\n",
      "Epoch 93/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 881.2356 - mae: 881.2356 - val_loss: 836.9706 - val_mae: 836.9706\n",
      "Epoch 94/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.5216 - mae: 881.5216 - val_loss: 837.2473 - val_mae: 837.2473\n",
      "Epoch 95/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.1058 - mae: 881.1058 - val_loss: 840.5430 - val_mae: 840.5430\n",
      "Epoch 96/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.3120 - mae: 879.3120 - val_loss: 838.4487 - val_mae: 838.4487\n",
      "Epoch 97/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.9277 - mae: 880.9277 - val_loss: 837.8162 - val_mae: 837.8162\n",
      "Epoch 98/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.2443 - mae: 879.2443 - val_loss: 836.9453 - val_mae: 836.9453\n",
      "Epoch 99/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.3370 - mae: 878.3370 - val_loss: 838.2014 - val_mae: 838.2014\n",
      "Epoch 100/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.5249 - mae: 880.5249 - val_loss: 836.9844 - val_mae: 836.9844\n",
      "Fold 5 - Loss: 836.9841, MAE: 836.9841\n",
      "\n",
      "Cross Validation 5-Fold 결과:\n",
      "MAE 평균: 853.9284, 표준편차: 9.3984\n",
      "\n",
      "\n",
      "--- Cross Validation: 7-Fold 시작 ---\n",
      "\n",
      "Fold 1 / 7\n",
      "Epoch 1/100\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 2073.7246 - mae: 2073.7246 - val_loss: 1111.0226 - val_mae: 1111.0226\n",
      "Epoch 2/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 985.6450 - mae: 985.6450 - val_loss: 872.7318 - val_mae: 872.7318\n",
      "Epoch 3/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 894.7029 - mae: 894.7029 - val_loss: 852.9791 - val_mae: 852.9791\n",
      "Epoch 4/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 889.7448 - mae: 889.7448 - val_loss: 853.3597 - val_mae: 853.3597\n",
      "Epoch 5/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 889.3232 - mae: 889.3232 - val_loss: 850.0295 - val_mae: 850.0295\n",
      "Epoch 6/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 886.3077 - mae: 886.3077 - val_loss: 849.6585 - val_mae: 849.6585\n",
      "Epoch 7/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.6742 - mae: 882.6742 - val_loss: 849.8803 - val_mae: 849.8803\n",
      "Epoch 8/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 884.9746 - mae: 884.9746 - val_loss: 854.8444 - val_mae: 854.8444\n",
      "Epoch 9/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 884.7587 - mae: 884.7587 - val_loss: 854.1201 - val_mae: 854.1201\n",
      "Epoch 10/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 886.9451 - mae: 886.9451 - val_loss: 849.6183 - val_mae: 849.6183\n",
      "Epoch 11/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 885.6934 - mae: 885.6934 - val_loss: 853.1861 - val_mae: 853.1861\n",
      "Epoch 12/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.8629 - mae: 882.8629 - val_loss: 851.6069 - val_mae: 851.6069\n",
      "Epoch 13/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 884.1548 - mae: 884.1548 - val_loss: 851.2530 - val_mae: 851.2530\n",
      "Epoch 14/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 885.2036 - mae: 885.2036 - val_loss: 847.8746 - val_mae: 847.8746\n",
      "Epoch 15/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.3055 - mae: 883.3055 - val_loss: 848.3824 - val_mae: 848.3824\n",
      "Epoch 16/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 885.0519 - mae: 885.0519 - val_loss: 853.4520 - val_mae: 853.4520\n",
      "Epoch 17/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.2473 - mae: 882.2473 - val_loss: 850.0916 - val_mae: 850.0916\n",
      "Epoch 18/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.3053 - mae: 883.3053 - val_loss: 848.7661 - val_mae: 848.7661\n",
      "Epoch 19/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.3441 - mae: 882.3441 - val_loss: 849.7831 - val_mae: 849.7831\n",
      "Epoch 20/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.3518 - mae: 882.3518 - val_loss: 851.1772 - val_mae: 851.1772\n",
      "Epoch 21/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 885.0571 - mae: 885.0571 - val_loss: 849.9753 - val_mae: 849.9753\n",
      "Epoch 22/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 884.0113 - mae: 884.0113 - val_loss: 850.6670 - val_mae: 850.6670\n",
      "Epoch 23/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 884.6425 - mae: 884.6425 - val_loss: 852.8287 - val_mae: 852.8287\n",
      "Epoch 24/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.3350 - mae: 882.3350 - val_loss: 847.7972 - val_mae: 847.7972\n",
      "Epoch 25/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 885.0235 - mae: 885.0235 - val_loss: 850.5748 - val_mae: 850.5748\n",
      "Epoch 26/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 885.4497 - mae: 885.4497 - val_loss: 850.9637 - val_mae: 850.9637\n",
      "Epoch 27/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 888.5641 - mae: 888.5641 - val_loss: 850.9518 - val_mae: 850.9518\n",
      "Epoch 28/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 884.7335 - mae: 884.7335 - val_loss: 854.3162 - val_mae: 854.3162\n",
      "Epoch 29/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.3466 - mae: 881.3466 - val_loss: 855.3104 - val_mae: 855.3104\n",
      "Epoch 30/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 884.5588 - mae: 884.5588 - val_loss: 848.0762 - val_mae: 848.0762\n",
      "Epoch 31/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 884.1541 - mae: 884.1541 - val_loss: 850.2531 - val_mae: 850.2531\n",
      "Epoch 32/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.6619 - mae: 882.6619 - val_loss: 848.0054 - val_mae: 848.0054\n",
      "Epoch 33/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.9022 - mae: 882.9022 - val_loss: 849.8953 - val_mae: 849.8953\n",
      "Epoch 34/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.8937 - mae: 882.8937 - val_loss: 854.5967 - val_mae: 854.5967\n",
      "Epoch 35/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.6575 - mae: 881.6575 - val_loss: 850.1323 - val_mae: 850.1323\n",
      "Epoch 36/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.4454 - mae: 883.4454 - val_loss: 849.2638 - val_mae: 849.2638\n",
      "Epoch 37/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 883.6184 - mae: 883.6184 - val_loss: 849.3127 - val_mae: 849.3127\n",
      "Epoch 38/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 883.2939 - mae: 883.2939 - val_loss: 851.2941 - val_mae: 851.2941\n",
      "Epoch 39/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.7758 - mae: 882.7758 - val_loss: 849.0707 - val_mae: 849.0707\n",
      "Epoch 40/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.9158 - mae: 882.9158 - val_loss: 850.6841 - val_mae: 850.6841\n",
      "Epoch 41/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.3679 - mae: 882.3679 - val_loss: 849.9043 - val_mae: 849.9043\n",
      "Epoch 42/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.0861 - mae: 881.0861 - val_loss: 852.3071 - val_mae: 852.3071\n",
      "Epoch 43/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.2264 - mae: 882.2264 - val_loss: 854.2151 - val_mae: 854.2151\n",
      "Epoch 44/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 883.3627 - mae: 883.3627 - val_loss: 851.6307 - val_mae: 851.6307\n",
      "Epoch 45/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.5150 - mae: 881.5150 - val_loss: 848.8954 - val_mae: 848.8954\n",
      "Epoch 46/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 884.5953 - mae: 884.5953 - val_loss: 849.4281 - val_mae: 849.4281\n",
      "Epoch 47/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.6102 - mae: 881.6102 - val_loss: 848.5809 - val_mae: 848.5809\n",
      "Epoch 48/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.9395 - mae: 880.9395 - val_loss: 848.9987 - val_mae: 848.9987\n",
      "Epoch 49/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.3773 - mae: 882.3773 - val_loss: 847.3441 - val_mae: 847.3441\n",
      "Epoch 50/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.7043 - mae: 882.7043 - val_loss: 851.1938 - val_mae: 851.1938\n",
      "Epoch 51/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.3657 - mae: 882.3657 - val_loss: 847.8713 - val_mae: 847.8713\n",
      "Epoch 52/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.7673 - mae: 881.7673 - val_loss: 848.8636 - val_mae: 848.8636\n",
      "Epoch 53/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.6563 - mae: 882.6563 - val_loss: 851.4760 - val_mae: 851.4760\n",
      "Epoch 54/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.2480 - mae: 883.2480 - val_loss: 852.5579 - val_mae: 852.5579\n",
      "Epoch 55/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 883.1938 - mae: 883.1938 - val_loss: 851.5956 - val_mae: 851.5956\n",
      "Epoch 56/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.8870 - mae: 878.8870 - val_loss: 846.6368 - val_mae: 846.6368\n",
      "Epoch 57/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.7815 - mae: 881.7815 - val_loss: 848.7140 - val_mae: 848.7140\n",
      "Epoch 58/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.4590 - mae: 880.4590 - val_loss: 850.6630 - val_mae: 850.6630\n",
      "Epoch 59/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.5035 - mae: 879.5035 - val_loss: 845.5909 - val_mae: 845.5909\n",
      "Epoch 60/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.8765 - mae: 880.8765 - val_loss: 845.6750 - val_mae: 845.6750\n",
      "Epoch 61/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.4888 - mae: 881.4888 - val_loss: 846.6619 - val_mae: 846.6619\n",
      "Epoch 62/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 878.9049 - mae: 878.9049 - val_loss: 849.8317 - val_mae: 849.8317\n",
      "Epoch 63/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 879.8740 - mae: 879.8740 - val_loss: 848.1318 - val_mae: 848.1318\n",
      "Epoch 64/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.5610 - mae: 881.5610 - val_loss: 847.3234 - val_mae: 847.3234\n",
      "Epoch 65/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.2457 - mae: 880.2457 - val_loss: 845.6528 - val_mae: 845.6528\n",
      "Epoch 66/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.7170 - mae: 880.7170 - val_loss: 844.5825 - val_mae: 844.5825\n",
      "Epoch 67/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.7369 - mae: 879.7369 - val_loss: 845.4465 - val_mae: 845.4465\n",
      "Epoch 68/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.7375 - mae: 878.7375 - val_loss: 846.9147 - val_mae: 846.9147\n",
      "Epoch 69/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 878.5505 - mae: 878.5505 - val_loss: 843.8046 - val_mae: 843.8046\n",
      "Epoch 70/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 879.4704 - mae: 879.4704 - val_loss: 848.6348 - val_mae: 848.6348\n",
      "Epoch 71/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.0355 - mae: 881.0355 - val_loss: 844.7164 - val_mae: 844.7164\n",
      "Epoch 72/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 879.9211 - mae: 879.9211 - val_loss: 845.7278 - val_mae: 845.7278\n",
      "Epoch 73/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.6450 - mae: 882.6450 - val_loss: 846.4911 - val_mae: 846.4911\n",
      "Epoch 74/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.4622 - mae: 880.4622 - val_loss: 845.1654 - val_mae: 845.1654\n",
      "Epoch 75/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.7460 - mae: 878.7460 - val_loss: 845.9158 - val_mae: 845.9158\n",
      "Epoch 76/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.0616 - mae: 878.0616 - val_loss: 843.6413 - val_mae: 843.6413\n",
      "Epoch 77/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.5015 - mae: 880.5015 - val_loss: 848.5110 - val_mae: 848.5110\n",
      "Epoch 78/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 878.8897 - mae: 878.8897 - val_loss: 844.9879 - val_mae: 844.9879\n",
      "Epoch 79/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 878.1686 - mae: 878.1686 - val_loss: 844.1056 - val_mae: 844.1056\n",
      "Epoch 80/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 878.2325 - mae: 878.2325 - val_loss: 844.5279 - val_mae: 844.5279\n",
      "Epoch 81/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 879.5345 - mae: 879.5345 - val_loss: 844.2255 - val_mae: 844.2255\n",
      "Epoch 82/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 876.8465 - mae: 876.8465 - val_loss: 843.2182 - val_mae: 843.2182\n",
      "Epoch 83/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.1099 - mae: 879.1099 - val_loss: 843.8303 - val_mae: 843.8303\n",
      "Epoch 84/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 876.9427 - mae: 876.9427 - val_loss: 843.1810 - val_mae: 843.1810\n",
      "Epoch 85/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 876.8530 - mae: 876.8530 - val_loss: 846.5767 - val_mae: 846.5767\n",
      "Epoch 86/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 878.3209 - mae: 878.3209 - val_loss: 843.2486 - val_mae: 843.2486\n",
      "Epoch 87/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 878.5406 - mae: 878.5406 - val_loss: 843.0787 - val_mae: 843.0787\n",
      "Epoch 88/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.3900 - mae: 880.3900 - val_loss: 843.5218 - val_mae: 843.5218\n",
      "Epoch 89/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 876.8470 - mae: 876.8470 - val_loss: 842.5926 - val_mae: 842.5926\n",
      "Epoch 90/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 878.3002 - mae: 878.3002 - val_loss: 845.1149 - val_mae: 845.1149\n",
      "Epoch 91/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.1348 - mae: 878.1348 - val_loss: 845.6610 - val_mae: 845.6610\n",
      "Epoch 92/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.5446 - mae: 879.5446 - val_loss: 848.3897 - val_mae: 848.3897\n",
      "Epoch 93/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.3054 - mae: 879.3054 - val_loss: 844.9255 - val_mae: 844.9255\n",
      "Epoch 94/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.6691 - mae: 878.6691 - val_loss: 847.0262 - val_mae: 847.0262\n",
      "Epoch 95/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 876.8190 - mae: 876.8190 - val_loss: 844.9586 - val_mae: 844.9586\n",
      "Epoch 96/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 877.5610 - mae: 877.5610 - val_loss: 845.5651 - val_mae: 845.5651\n",
      "Epoch 97/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.3311 - mae: 880.3311 - val_loss: 847.5269 - val_mae: 847.5269\n",
      "Epoch 98/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.1245 - mae: 878.1245 - val_loss: 843.7807 - val_mae: 843.7807\n",
      "Epoch 99/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 874.5847 - mae: 874.5847 - val_loss: 846.1719 - val_mae: 846.1719\n",
      "Epoch 100/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.0621 - mae: 878.0621 - val_loss: 844.1437 - val_mae: 844.1437\n",
      "Fold 1 - Loss: 844.1437, MAE: 844.1437\n",
      "Fold 2 / 7\n",
      "Epoch 1/100\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 2205.8892 - mae: 2205.8892 - val_loss: 1181.2300 - val_mae: 1181.2300\n",
      "Epoch 2/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 1015.5294 - mae: 1015.5294 - val_loss: 899.4583 - val_mae: 899.4583\n",
      "Epoch 3/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 891.9257 - mae: 891.9257 - val_loss: 869.0235 - val_mae: 869.0235\n",
      "Epoch 4/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 884.1156 - mae: 884.1156 - val_loss: 868.5004 - val_mae: 868.5004\n",
      "Epoch 5/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 884.0377 - mae: 884.0377 - val_loss: 863.1030 - val_mae: 863.1030\n",
      "Epoch 6/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.6485 - mae: 883.6485 - val_loss: 864.1816 - val_mae: 864.1816\n",
      "Epoch 7/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 883.3619 - mae: 883.3619 - val_loss: 864.8389 - val_mae: 864.8389\n",
      "Epoch 8/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.7719 - mae: 882.7719 - val_loss: 864.9232 - val_mae: 864.9232\n",
      "Epoch 9/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 885.3785 - mae: 885.3785 - val_loss: 864.4237 - val_mae: 864.4237\n",
      "Epoch 10/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.9190 - mae: 881.9190 - val_loss: 868.3428 - val_mae: 868.3428\n",
      "Epoch 11/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.4205 - mae: 882.4205 - val_loss: 867.1823 - val_mae: 867.1823\n",
      "Epoch 12/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 884.9896 - mae: 884.9896 - val_loss: 862.1035 - val_mae: 862.1035\n",
      "Epoch 13/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.1962 - mae: 882.1962 - val_loss: 864.7037 - val_mae: 864.7037\n",
      "Epoch 14/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.3000 - mae: 883.3000 - val_loss: 863.3035 - val_mae: 863.3035\n",
      "Epoch 15/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.0587 - mae: 880.0587 - val_loss: 870.0842 - val_mae: 870.0842\n",
      "Epoch 16/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.9293 - mae: 881.9293 - val_loss: 862.8954 - val_mae: 862.8954\n",
      "Epoch 17/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.4753 - mae: 880.4753 - val_loss: 866.0157 - val_mae: 866.0157\n",
      "Epoch 18/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.1769 - mae: 880.1769 - val_loss: 868.9554 - val_mae: 868.9554\n",
      "Epoch 19/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.7105 - mae: 881.7105 - val_loss: 862.1903 - val_mae: 862.1903\n",
      "Epoch 20/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.3018 - mae: 878.3018 - val_loss: 870.3035 - val_mae: 870.3035\n",
      "Epoch 21/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.7855 - mae: 879.7855 - val_loss: 864.3657 - val_mae: 864.3657\n",
      "Epoch 22/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.9467 - mae: 881.9467 - val_loss: 863.7044 - val_mae: 863.7044\n",
      "Epoch 23/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.6004 - mae: 880.6004 - val_loss: 863.2708 - val_mae: 863.2708\n",
      "Epoch 24/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.2870 - mae: 881.2870 - val_loss: 864.9283 - val_mae: 864.9283\n",
      "Epoch 25/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.2322 - mae: 881.2322 - val_loss: 867.1952 - val_mae: 867.1952\n",
      "Epoch 26/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 879.4673 - mae: 879.4673 - val_loss: 863.8206 - val_mae: 863.8206\n",
      "Epoch 27/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.7378 - mae: 881.7378 - val_loss: 863.7845 - val_mae: 863.7845\n",
      "Epoch 28/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.2162 - mae: 879.2162 - val_loss: 866.8125 - val_mae: 866.8125\n",
      "Epoch 29/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.7551 - mae: 882.7551 - val_loss: 862.2283 - val_mae: 862.2283\n",
      "Epoch 30/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.4709 - mae: 880.4709 - val_loss: 865.3853 - val_mae: 865.3853\n",
      "Epoch 31/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.4857 - mae: 879.4857 - val_loss: 867.3503 - val_mae: 867.3503\n",
      "Epoch 32/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.4352 - mae: 882.4352 - val_loss: 867.5980 - val_mae: 867.5980\n",
      "Epoch 33/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.6730 - mae: 881.6730 - val_loss: 861.6220 - val_mae: 861.6220\n",
      "Epoch 34/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.1552 - mae: 879.1552 - val_loss: 863.3260 - val_mae: 863.3260\n",
      "Epoch 35/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.7607 - mae: 879.7607 - val_loss: 867.7374 - val_mae: 867.7374\n",
      "Epoch 36/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.1706 - mae: 882.1706 - val_loss: 864.8480 - val_mae: 864.8480\n",
      "Epoch 37/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.6769 - mae: 881.6769 - val_loss: 864.6924 - val_mae: 864.6924\n",
      "Epoch 38/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.0149 - mae: 880.0149 - val_loss: 862.9379 - val_mae: 862.9379\n",
      "Epoch 39/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.6257 - mae: 880.6257 - val_loss: 864.8235 - val_mae: 864.8235\n",
      "Epoch 40/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.1677 - mae: 879.1677 - val_loss: 866.9520 - val_mae: 866.9520\n",
      "Epoch 41/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.8196 - mae: 880.8196 - val_loss: 866.9581 - val_mae: 866.9581\n",
      "Epoch 42/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.4660 - mae: 880.4660 - val_loss: 863.1807 - val_mae: 863.1807\n",
      "Epoch 43/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 878.1498 - mae: 878.1498 - val_loss: 867.3924 - val_mae: 867.3924\n",
      "Epoch 44/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 879.4357 - mae: 879.4357 - val_loss: 863.5240 - val_mae: 863.5240\n",
      "Epoch 45/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 878.7619 - mae: 878.7619 - val_loss: 868.2667 - val_mae: 868.2667\n",
      "Epoch 46/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.1989 - mae: 880.1989 - val_loss: 864.5751 - val_mae: 864.5751\n",
      "Epoch 47/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 879.0201 - mae: 879.0201 - val_loss: 862.6960 - val_mae: 862.6960\n",
      "Epoch 48/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.3451 - mae: 881.3451 - val_loss: 862.0934 - val_mae: 862.0934\n",
      "Epoch 49/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.5193 - mae: 881.5193 - val_loss: 862.1669 - val_mae: 862.1669\n",
      "Epoch 50/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.7104 - mae: 879.7104 - val_loss: 863.4975 - val_mae: 863.4975\n",
      "Epoch 51/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.0688 - mae: 880.0688 - val_loss: 861.8821 - val_mae: 861.8821\n",
      "Epoch 52/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.2322 - mae: 879.2322 - val_loss: 861.6180 - val_mae: 861.6180\n",
      "Epoch 53/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.5585 - mae: 881.5585 - val_loss: 861.9911 - val_mae: 861.9911\n",
      "Epoch 54/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.4877 - mae: 880.4877 - val_loss: 867.2827 - val_mae: 867.2827\n",
      "Epoch 55/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.1318 - mae: 880.1318 - val_loss: 865.9697 - val_mae: 865.9697\n",
      "Epoch 56/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.2592 - mae: 880.2592 - val_loss: 867.1909 - val_mae: 867.1909\n",
      "Epoch 57/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.6837 - mae: 878.6837 - val_loss: 861.9703 - val_mae: 861.9703\n",
      "Epoch 58/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.2966 - mae: 881.2966 - val_loss: 866.1785 - val_mae: 866.1785\n",
      "Epoch 59/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.7225 - mae: 879.7225 - val_loss: 861.5927 - val_mae: 861.5927\n",
      "Epoch 60/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.9604 - mae: 880.9604 - val_loss: 862.7410 - val_mae: 862.7410\n",
      "Epoch 61/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 877.6898 - mae: 877.6898 - val_loss: 863.3011 - val_mae: 863.3011\n",
      "Epoch 62/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 877.3744 - mae: 877.3744 - val_loss: 862.8951 - val_mae: 862.8951\n",
      "Epoch 63/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.5947 - mae: 878.5947 - val_loss: 864.9047 - val_mae: 864.9047\n",
      "Epoch 64/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.2700 - mae: 880.2700 - val_loss: 863.7184 - val_mae: 863.7184\n",
      "Epoch 65/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.4344 - mae: 878.4344 - val_loss: 866.6716 - val_mae: 866.6716\n",
      "Epoch 66/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.4172 - mae: 881.4172 - val_loss: 868.1693 - val_mae: 868.1693\n",
      "Epoch 67/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.9180 - mae: 879.9180 - val_loss: 873.5731 - val_mae: 873.5731\n",
      "Epoch 68/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.6135 - mae: 880.6135 - val_loss: 863.8455 - val_mae: 863.8455\n",
      "Epoch 69/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 879.2406 - mae: 879.2406 - val_loss: 864.3005 - val_mae: 864.3005\n",
      "Epoch 70/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.1808 - mae: 878.1808 - val_loss: 863.4402 - val_mae: 863.4402\n",
      "Epoch 71/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.7202 - mae: 881.7202 - val_loss: 865.2097 - val_mae: 865.2097\n",
      "Epoch 72/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.8849 - mae: 878.8849 - val_loss: 865.3900 - val_mae: 865.3900\n",
      "Epoch 73/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.0236 - mae: 880.0236 - val_loss: 866.8108 - val_mae: 866.8108\n",
      "Epoch 74/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.3416 - mae: 878.3416 - val_loss: 862.3069 - val_mae: 862.3069\n",
      "Epoch 75/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.3783 - mae: 881.3783 - val_loss: 864.7440 - val_mae: 864.7440\n",
      "Epoch 76/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 877.6934 - mae: 877.6934 - val_loss: 868.8942 - val_mae: 868.8942\n",
      "Epoch 77/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.9232 - mae: 880.9232 - val_loss: 862.6602 - val_mae: 862.6602\n",
      "Epoch 78/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.5903 - mae: 879.5903 - val_loss: 865.8327 - val_mae: 865.8327\n",
      "Epoch 79/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 877.9636 - mae: 877.9636 - val_loss: 861.4846 - val_mae: 861.4846\n",
      "Epoch 80/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 879.5974 - mae: 879.5974 - val_loss: 861.0838 - val_mae: 861.0838\n",
      "Epoch 81/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 879.8466 - mae: 879.8466 - val_loss: 866.1138 - val_mae: 866.1138\n",
      "Epoch 82/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.2722 - mae: 880.2722 - val_loss: 865.3102 - val_mae: 865.3102\n",
      "Epoch 83/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 878.1061 - mae: 878.1061 - val_loss: 863.1536 - val_mae: 863.1536\n",
      "Epoch 84/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 877.7558 - mae: 877.7558 - val_loss: 869.9180 - val_mae: 869.9180\n",
      "Epoch 85/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.7717 - mae: 880.7717 - val_loss: 862.5015 - val_mae: 862.5015\n",
      "Epoch 86/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 879.4630 - mae: 879.4630 - val_loss: 865.4131 - val_mae: 865.4131\n",
      "Epoch 87/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 879.8429 - mae: 879.8429 - val_loss: 869.1074 - val_mae: 869.1074\n",
      "Epoch 88/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.2759 - mae: 881.2759 - val_loss: 863.5126 - val_mae: 863.5126\n",
      "Epoch 89/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 879.6701 - mae: 879.6701 - val_loss: 863.2940 - val_mae: 863.2940\n",
      "Epoch 90/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.1139 - mae: 880.1139 - val_loss: 865.7075 - val_mae: 865.7075\n",
      "Epoch 91/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 879.4385 - mae: 879.4385 - val_loss: 862.9354 - val_mae: 862.9354\n",
      "Epoch 92/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 879.8100 - mae: 879.8100 - val_loss: 860.9559 - val_mae: 860.9559\n",
      "Epoch 93/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.8875 - mae: 880.8875 - val_loss: 866.3874 - val_mae: 866.3874\n",
      "Epoch 94/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 879.2619 - mae: 879.2619 - val_loss: 862.9474 - val_mae: 862.9474\n",
      "Epoch 95/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 879.5349 - mae: 879.5349 - val_loss: 861.7501 - val_mae: 861.7501\n",
      "Epoch 96/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.5732 - mae: 880.5732 - val_loss: 862.1880 - val_mae: 862.1880\n",
      "Epoch 97/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 879.2044 - mae: 879.2044 - val_loss: 861.7109 - val_mae: 861.7109\n",
      "Epoch 98/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 878.2986 - mae: 878.2986 - val_loss: 863.6654 - val_mae: 863.6654\n",
      "Epoch 99/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 879.3115 - mae: 879.3115 - val_loss: 863.2156 - val_mae: 863.2156\n",
      "Epoch 100/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 876.5794 - mae: 876.5794 - val_loss: 867.2833 - val_mae: 867.2833\n",
      "Fold 2 - Loss: 867.2833, MAE: 867.2833\n",
      "Fold 3 / 7\n",
      "Epoch 1/100\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 2045.9296 - mae: 2045.9296 - val_loss: 1119.0010 - val_mae: 1119.0010\n",
      "Epoch 2/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 979.3644 - mae: 979.3644 - val_loss: 878.7449 - val_mae: 878.7449\n",
      "Epoch 3/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 892.0297 - mae: 892.0297 - val_loss: 861.1696 - val_mae: 861.1696\n",
      "Epoch 4/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 888.2084 - mae: 888.2084 - val_loss: 863.6368 - val_mae: 863.6368\n",
      "Epoch 5/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 884.4789 - mae: 884.4789 - val_loss: 861.4193 - val_mae: 861.4193\n",
      "Epoch 6/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 884.7401 - mae: 884.7401 - val_loss: 855.5699 - val_mae: 855.5699\n",
      "Epoch 7/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 886.4137 - mae: 886.4137 - val_loss: 860.4634 - val_mae: 860.4634\n",
      "Epoch 8/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 884.8875 - mae: 884.8875 - val_loss: 858.5549 - val_mae: 858.5549\n",
      "Epoch 9/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 886.2374 - mae: 886.2374 - val_loss: 861.0662 - val_mae: 861.0662\n",
      "Epoch 10/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 886.3015 - mae: 886.3015 - val_loss: 857.2451 - val_mae: 857.2451\n",
      "Epoch 11/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 887.0880 - mae: 887.0880 - val_loss: 858.7483 - val_mae: 858.7483\n",
      "Epoch 12/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 885.0583 - mae: 885.0583 - val_loss: 858.4391 - val_mae: 858.4391\n",
      "Epoch 13/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 884.2011 - mae: 884.2011 - val_loss: 859.1985 - val_mae: 859.1985\n",
      "Epoch 14/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 884.0928 - mae: 884.0928 - val_loss: 855.0942 - val_mae: 855.0942\n",
      "Epoch 15/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.3907 - mae: 882.3907 - val_loss: 855.6559 - val_mae: 855.6559\n",
      "Epoch 16/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 885.1086 - mae: 885.1086 - val_loss: 855.5424 - val_mae: 855.5424\n",
      "Epoch 17/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 885.2084 - mae: 885.2084 - val_loss: 858.8598 - val_mae: 858.8598\n",
      "Epoch 18/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 884.8881 - mae: 884.8881 - val_loss: 858.2679 - val_mae: 858.2679\n",
      "Epoch 19/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.9194 - mae: 883.9194 - val_loss: 856.7219 - val_mae: 856.7219\n",
      "Epoch 20/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 886.4510 - mae: 886.4510 - val_loss: 855.2456 - val_mae: 855.2456\n",
      "Epoch 21/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.3925 - mae: 882.3925 - val_loss: 857.1639 - val_mae: 857.1639\n",
      "Epoch 22/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 883.7682 - mae: 883.7682 - val_loss: 860.4714 - val_mae: 860.4714\n",
      "Epoch 23/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 885.7998 - mae: 885.7998 - val_loss: 857.2662 - val_mae: 857.2662\n",
      "Epoch 24/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.8651 - mae: 882.8651 - val_loss: 855.8116 - val_mae: 855.8116\n",
      "Epoch 25/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 884.9249 - mae: 884.9249 - val_loss: 861.9616 - val_mae: 861.9616\n",
      "Epoch 26/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 884.0274 - mae: 884.0274 - val_loss: 858.2477 - val_mae: 858.2477\n",
      "Epoch 27/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.2110 - mae: 882.2110 - val_loss: 865.1818 - val_mae: 865.1818\n",
      "Epoch 28/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.5737 - mae: 882.5737 - val_loss: 859.4323 - val_mae: 859.4323\n",
      "Epoch 29/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.5735 - mae: 883.5735 - val_loss: 858.5272 - val_mae: 858.5272\n",
      "Epoch 30/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.8716 - mae: 881.8716 - val_loss: 861.1339 - val_mae: 861.1339\n",
      "Epoch 31/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 884.8364 - mae: 884.8364 - val_loss: 858.3516 - val_mae: 858.3516\n",
      "Epoch 32/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.5081 - mae: 882.5081 - val_loss: 856.6290 - val_mae: 856.6290\n",
      "Epoch 33/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.0434 - mae: 881.0434 - val_loss: 857.7905 - val_mae: 857.7905\n",
      "Epoch 34/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.8559 - mae: 883.8559 - val_loss: 855.7822 - val_mae: 855.7822\n",
      "Epoch 35/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 883.8829 - mae: 883.8829 - val_loss: 854.8643 - val_mae: 854.8643\n",
      "Epoch 36/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 883.9705 - mae: 883.9705 - val_loss: 854.6711 - val_mae: 854.6711\n",
      "Epoch 37/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 884.6404 - mae: 884.6404 - val_loss: 859.5040 - val_mae: 859.5040\n",
      "Epoch 38/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.6362 - mae: 882.6362 - val_loss: 855.1000 - val_mae: 855.1000\n",
      "Epoch 39/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.6818 - mae: 882.6818 - val_loss: 856.6778 - val_mae: 856.6778\n",
      "Epoch 40/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.6123 - mae: 882.6123 - val_loss: 855.5424 - val_mae: 855.5424\n",
      "Epoch 41/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 884.7217 - mae: 884.7217 - val_loss: 860.7715 - val_mae: 860.7715\n",
      "Epoch 42/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 884.0855 - mae: 884.0855 - val_loss: 855.4570 - val_mae: 855.4570\n",
      "Epoch 43/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.9749 - mae: 883.9749 - val_loss: 856.0917 - val_mae: 856.0917\n",
      "Epoch 44/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 884.7203 - mae: 884.7203 - val_loss: 855.1315 - val_mae: 855.1315\n",
      "Epoch 45/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.3450 - mae: 883.3450 - val_loss: 860.9367 - val_mae: 860.9367\n",
      "Epoch 46/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.4139 - mae: 882.4139 - val_loss: 859.6829 - val_mae: 859.6829\n",
      "Epoch 47/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 884.3889 - mae: 884.3889 - val_loss: 854.9294 - val_mae: 854.9294\n",
      "Epoch 48/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.7095 - mae: 881.7095 - val_loss: 857.8666 - val_mae: 857.8666\n",
      "Epoch 49/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.1613 - mae: 882.1613 - val_loss: 857.3020 - val_mae: 857.3020\n",
      "Epoch 50/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.9528 - mae: 883.9528 - val_loss: 859.8174 - val_mae: 859.8174\n",
      "Epoch 51/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.9451 - mae: 883.9451 - val_loss: 854.1983 - val_mae: 854.1983\n",
      "Epoch 52/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.5695 - mae: 883.5695 - val_loss: 855.1989 - val_mae: 855.1989\n",
      "Epoch 53/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.7877 - mae: 881.7877 - val_loss: 856.2779 - val_mae: 856.2779\n",
      "Epoch 54/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.3730 - mae: 882.3730 - val_loss: 858.9156 - val_mae: 858.9156\n",
      "Epoch 55/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 883.4399 - mae: 883.4399 - val_loss: 856.6010 - val_mae: 856.6010\n",
      "Epoch 56/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.7643 - mae: 881.7643 - val_loss: 856.5844 - val_mae: 856.5844\n",
      "Epoch 57/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.5323 - mae: 882.5323 - val_loss: 859.2715 - val_mae: 859.2715\n",
      "Epoch 58/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.6908 - mae: 880.6908 - val_loss: 853.6600 - val_mae: 853.6600\n",
      "Epoch 59/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.2145 - mae: 882.2145 - val_loss: 853.8507 - val_mae: 853.8507\n",
      "Epoch 60/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 885.7539 - mae: 885.7539 - val_loss: 856.5205 - val_mae: 856.5205\n",
      "Epoch 61/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 883.8981 - mae: 883.8981 - val_loss: 859.0185 - val_mae: 859.0185\n",
      "Epoch 62/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.7621 - mae: 882.7621 - val_loss: 859.1995 - val_mae: 859.1995\n",
      "Epoch 63/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 884.2246 - mae: 884.2246 - val_loss: 859.2186 - val_mae: 859.2186\n",
      "Epoch 64/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.5391 - mae: 881.5391 - val_loss: 857.2044 - val_mae: 857.2044\n",
      "Epoch 65/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 886.1527 - mae: 886.1527 - val_loss: 856.0851 - val_mae: 856.0851\n",
      "Epoch 66/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.4660 - mae: 881.4660 - val_loss: 856.0523 - val_mae: 856.0523\n",
      "Epoch 67/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.5261 - mae: 879.5261 - val_loss: 855.6212 - val_mae: 855.6212\n",
      "Epoch 68/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.1772 - mae: 881.1772 - val_loss: 853.6975 - val_mae: 853.6975\n",
      "Epoch 69/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 883.8939 - mae: 883.8939 - val_loss: 855.5869 - val_mae: 855.5869\n",
      "Epoch 70/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.8129 - mae: 880.8129 - val_loss: 860.7031 - val_mae: 860.7031\n",
      "Epoch 71/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.7177 - mae: 881.7177 - val_loss: 859.8083 - val_mae: 859.8083\n",
      "Epoch 72/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.4731 - mae: 879.4731 - val_loss: 854.0751 - val_mae: 854.0751\n",
      "Epoch 73/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.1359 - mae: 881.1359 - val_loss: 855.6334 - val_mae: 855.6334\n",
      "Epoch 74/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.8041 - mae: 880.8041 - val_loss: 854.8527 - val_mae: 854.8527\n",
      "Epoch 75/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.1234 - mae: 880.1234 - val_loss: 855.4161 - val_mae: 855.4161\n",
      "Epoch 76/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.0465 - mae: 881.0465 - val_loss: 854.5060 - val_mae: 854.5060\n",
      "Epoch 77/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.6449 - mae: 881.6449 - val_loss: 854.2665 - val_mae: 854.2665\n",
      "Epoch 78/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 878.9053 - mae: 878.9053 - val_loss: 855.2312 - val_mae: 855.2312\n",
      "Epoch 79/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.7186 - mae: 881.7186 - val_loss: 859.5440 - val_mae: 859.5440\n",
      "Epoch 80/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.5903 - mae: 881.5903 - val_loss: 854.4955 - val_mae: 854.4955\n",
      "Epoch 81/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.6041 - mae: 880.6041 - val_loss: 853.7054 - val_mae: 853.7054\n",
      "Epoch 82/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.7388 - mae: 881.7388 - val_loss: 853.9861 - val_mae: 853.9861\n",
      "Epoch 83/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.3885 - mae: 881.3885 - val_loss: 853.9131 - val_mae: 853.9131\n",
      "Epoch 84/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.9815 - mae: 881.9815 - val_loss: 855.6215 - val_mae: 855.6215\n",
      "Epoch 85/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.8672 - mae: 880.8672 - val_loss: 854.6291 - val_mae: 854.6291\n",
      "Epoch 86/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.9942 - mae: 878.9942 - val_loss: 857.0360 - val_mae: 857.0360\n",
      "Epoch 87/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.7263 - mae: 881.7263 - val_loss: 854.1973 - val_mae: 854.1973\n",
      "Epoch 88/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.7983 - mae: 880.7983 - val_loss: 854.5748 - val_mae: 854.5748\n",
      "Epoch 89/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.1927 - mae: 878.1927 - val_loss: 854.6249 - val_mae: 854.6249\n",
      "Epoch 90/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.1678 - mae: 880.1678 - val_loss: 853.6503 - val_mae: 853.6503\n",
      "Epoch 91/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.5909 - mae: 878.5909 - val_loss: 854.2326 - val_mae: 854.2326\n",
      "Epoch 92/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 877.0228 - mae: 877.0228 - val_loss: 854.6368 - val_mae: 854.6368\n",
      "Epoch 93/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.8035 - mae: 878.8035 - val_loss: 857.0496 - val_mae: 857.0496\n",
      "Epoch 94/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.7859 - mae: 879.7859 - val_loss: 854.7542 - val_mae: 854.7542\n",
      "Epoch 95/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.3845 - mae: 881.3845 - val_loss: 856.6761 - val_mae: 856.6761\n",
      "Epoch 96/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.5176 - mae: 880.5176 - val_loss: 854.4513 - val_mae: 854.4513\n",
      "Epoch 97/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.2493 - mae: 879.2493 - val_loss: 855.4026 - val_mae: 855.4026\n",
      "Epoch 98/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.0229 - mae: 879.0229 - val_loss: 855.6295 - val_mae: 855.6295\n",
      "Epoch 99/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 879.0986 - mae: 879.0986 - val_loss: 855.1145 - val_mae: 855.1145\n",
      "Epoch 100/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 878.8401 - mae: 878.8401 - val_loss: 856.2015 - val_mae: 856.2015\n",
      "Fold 3 - Loss: 856.2014, MAE: 856.2014\n",
      "Fold 4 / 7\n",
      "Epoch 1/100\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 1935.0283 - mae: 1935.0283 - val_loss: 1045.4232 - val_mae: 1045.4232\n",
      "Epoch 2/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 947.0364 - mae: 947.0364 - val_loss: 870.2704 - val_mae: 870.2704\n",
      "Epoch 3/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 886.2661 - mae: 886.2661 - val_loss: 860.7916 - val_mae: 860.7916\n",
      "Epoch 4/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 883.9948 - mae: 883.9948 - val_loss: 866.3061 - val_mae: 866.3061\n",
      "Epoch 5/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.5925 - mae: 881.5925 - val_loss: 861.6116 - val_mae: 861.6116\n",
      "Epoch 6/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 883.2483 - mae: 883.2483 - val_loss: 862.3491 - val_mae: 862.3491\n",
      "Epoch 7/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 885.4914 - mae: 885.4914 - val_loss: 859.7563 - val_mae: 859.7563\n",
      "Epoch 8/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 883.4149 - mae: 883.4149 - val_loss: 859.9932 - val_mae: 859.9932\n",
      "Epoch 9/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.6054 - mae: 880.6054 - val_loss: 861.2371 - val_mae: 861.2371\n",
      "Epoch 10/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.7030 - mae: 882.7030 - val_loss: 861.0772 - val_mae: 861.0772\n",
      "Epoch 11/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 883.7960 - mae: 883.7960 - val_loss: 861.9629 - val_mae: 861.9629\n",
      "Epoch 12/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.2280 - mae: 881.2280 - val_loss: 861.9806 - val_mae: 861.9806\n",
      "Epoch 13/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.9586 - mae: 878.9586 - val_loss: 861.9044 - val_mae: 861.9044\n",
      "Epoch 14/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.6851 - mae: 879.6851 - val_loss: 859.5369 - val_mae: 859.5369\n",
      "Epoch 15/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.9033 - mae: 880.9033 - val_loss: 862.8900 - val_mae: 862.8900\n",
      "Epoch 16/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.7515 - mae: 881.7515 - val_loss: 858.6779 - val_mae: 858.6779\n",
      "Epoch 17/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.3171 - mae: 881.3171 - val_loss: 859.5391 - val_mae: 859.5391\n",
      "Epoch 18/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.8570 - mae: 882.8570 - val_loss: 863.1784 - val_mae: 863.1784\n",
      "Epoch 19/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.6088 - mae: 881.6088 - val_loss: 858.7089 - val_mae: 858.7089\n",
      "Epoch 20/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.6860 - mae: 878.6860 - val_loss: 859.7544 - val_mae: 859.7544\n",
      "Epoch 21/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.0425 - mae: 882.0425 - val_loss: 858.1900 - val_mae: 858.1900\n",
      "Epoch 22/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.9641 - mae: 880.9641 - val_loss: 865.9887 - val_mae: 865.9887\n",
      "Epoch 23/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.5719 - mae: 881.5719 - val_loss: 863.5469 - val_mae: 863.5469\n",
      "Epoch 24/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.2231 - mae: 882.2231 - val_loss: 860.3505 - val_mae: 860.3505\n",
      "Epoch 25/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 884.0388 - mae: 884.0388 - val_loss: 858.6773 - val_mae: 858.6773\n",
      "Epoch 26/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.9104 - mae: 879.9104 - val_loss: 859.2119 - val_mae: 859.2119\n",
      "Epoch 27/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 879.3505 - mae: 879.3505 - val_loss: 860.9260 - val_mae: 860.9260\n",
      "Epoch 28/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.5167 - mae: 882.5167 - val_loss: 860.2047 - val_mae: 860.2047\n",
      "Epoch 29/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.0073 - mae: 882.0073 - val_loss: 861.5508 - val_mae: 861.5508\n",
      "Epoch 30/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.7072 - mae: 879.7072 - val_loss: 860.8571 - val_mae: 860.8571\n",
      "Epoch 31/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.8536 - mae: 880.8536 - val_loss: 860.5853 - val_mae: 860.5853\n",
      "Epoch 32/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 878.6508 - mae: 878.6508 - val_loss: 859.5335 - val_mae: 859.5335\n",
      "Epoch 33/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 883.3146 - mae: 883.3146 - val_loss: 859.7640 - val_mae: 859.7640\n",
      "Epoch 34/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.9520 - mae: 880.9520 - val_loss: 860.3416 - val_mae: 860.3416\n",
      "Epoch 35/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.7471 - mae: 880.7471 - val_loss: 858.9553 - val_mae: 858.9553\n",
      "Epoch 36/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.6714 - mae: 880.6714 - val_loss: 858.5116 - val_mae: 858.5116\n",
      "Epoch 37/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 877.7593 - mae: 877.7593 - val_loss: 862.4135 - val_mae: 862.4135\n",
      "Epoch 38/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.5255 - mae: 880.5255 - val_loss: 860.9925 - val_mae: 860.9925\n",
      "Epoch 39/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.5681 - mae: 880.5681 - val_loss: 863.0978 - val_mae: 863.0978\n",
      "Epoch 40/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 877.8857 - mae: 877.8857 - val_loss: 860.3815 - val_mae: 860.3815\n",
      "Epoch 41/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.0753 - mae: 879.0753 - val_loss: 859.6487 - val_mae: 859.6487\n",
      "Epoch 42/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.1171 - mae: 880.1171 - val_loss: 858.8154 - val_mae: 858.8154\n",
      "Epoch 43/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.7726 - mae: 881.7726 - val_loss: 859.1916 - val_mae: 859.1916\n",
      "Epoch 44/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.1544 - mae: 878.1544 - val_loss: 858.9037 - val_mae: 858.9037\n",
      "Epoch 45/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.2191 - mae: 881.2191 - val_loss: 860.1775 - val_mae: 860.1775\n",
      "Epoch 46/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 879.1852 - mae: 879.1852 - val_loss: 857.8691 - val_mae: 857.8691\n",
      "Epoch 47/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.3546 - mae: 880.3546 - val_loss: 862.1324 - val_mae: 862.1324\n",
      "Epoch 48/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.8485 - mae: 880.8485 - val_loss: 859.2426 - val_mae: 859.2426\n",
      "Epoch 49/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.3452 - mae: 881.3452 - val_loss: 861.6279 - val_mae: 861.6279\n",
      "Epoch 50/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.3600 - mae: 878.3600 - val_loss: 858.8992 - val_mae: 858.8992\n",
      "Epoch 51/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.5638 - mae: 879.5638 - val_loss: 863.1525 - val_mae: 863.1525\n",
      "Epoch 52/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.0580 - mae: 881.0580 - val_loss: 861.9443 - val_mae: 861.9443\n",
      "Epoch 53/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.3116 - mae: 880.3116 - val_loss: 859.8652 - val_mae: 859.8652\n",
      "Epoch 54/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 878.2680 - mae: 878.2680 - val_loss: 858.1463 - val_mae: 858.1463\n",
      "Epoch 55/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 879.4490 - mae: 879.4490 - val_loss: 859.5270 - val_mae: 859.5270\n",
      "Epoch 56/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 879.9506 - mae: 879.9506 - val_loss: 860.1679 - val_mae: 860.1679\n",
      "Epoch 57/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.1780 - mae: 878.1780 - val_loss: 860.3521 - val_mae: 860.3521\n",
      "Epoch 58/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.1409 - mae: 880.1409 - val_loss: 861.3535 - val_mae: 861.3535\n",
      "Epoch 59/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 877.9604 - mae: 877.9604 - val_loss: 859.2823 - val_mae: 859.2823\n",
      "Epoch 60/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.3240 - mae: 880.3240 - val_loss: 858.2640 - val_mae: 858.2640\n",
      "Epoch 61/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.5414 - mae: 878.5414 - val_loss: 864.1685 - val_mae: 864.1685\n",
      "Epoch 62/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.7802 - mae: 879.7802 - val_loss: 860.2825 - val_mae: 860.2825\n",
      "Epoch 63/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 878.4429 - mae: 878.4429 - val_loss: 857.5202 - val_mae: 857.5202\n",
      "Epoch 64/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.5169 - mae: 878.5169 - val_loss: 860.9129 - val_mae: 860.9129\n",
      "Epoch 65/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 879.4146 - mae: 879.4146 - val_loss: 861.7856 - val_mae: 861.7856\n",
      "Epoch 66/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 879.0391 - mae: 879.0391 - val_loss: 858.0667 - val_mae: 858.0667\n",
      "Epoch 67/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.3647 - mae: 880.3647 - val_loss: 864.4467 - val_mae: 864.4467\n",
      "Epoch 68/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 879.9742 - mae: 879.9742 - val_loss: 859.5840 - val_mae: 859.5840\n",
      "Epoch 69/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 877.5093 - mae: 877.5093 - val_loss: 859.7899 - val_mae: 859.7899\n",
      "Epoch 70/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 878.8093 - mae: 878.8093 - val_loss: 861.2172 - val_mae: 861.2172\n",
      "Epoch 71/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 877.9277 - mae: 877.9277 - val_loss: 862.6302 - val_mae: 862.6302\n",
      "Epoch 72/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 878.2369 - mae: 878.2369 - val_loss: 858.5260 - val_mae: 858.5260\n",
      "Epoch 73/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.2545 - mae: 880.2545 - val_loss: 865.4340 - val_mae: 865.4340\n",
      "Epoch 74/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.4547 - mae: 880.4547 - val_loss: 861.3441 - val_mae: 861.3441\n",
      "Epoch 75/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.0847 - mae: 878.0847 - val_loss: 865.6611 - val_mae: 865.6611\n",
      "Epoch 76/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 879.7394 - mae: 879.7394 - val_loss: 861.3038 - val_mae: 861.3038\n",
      "Epoch 77/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 878.7648 - mae: 878.7648 - val_loss: 858.8530 - val_mae: 858.8530\n",
      "Epoch 78/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 877.4100 - mae: 877.4100 - val_loss: 864.5723 - val_mae: 864.5723\n",
      "Epoch 79/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 877.8882 - mae: 877.8882 - val_loss: 857.7061 - val_mae: 857.7061\n",
      "Epoch 80/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 877.1716 - mae: 877.1716 - val_loss: 858.2825 - val_mae: 858.2825\n",
      "Epoch 81/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 877.8494 - mae: 877.8494 - val_loss: 861.7631 - val_mae: 861.7631\n",
      "Epoch 82/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 876.8520 - mae: 876.8520 - val_loss: 860.2037 - val_mae: 860.2037\n",
      "Epoch 83/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.1849 - mae: 881.1849 - val_loss: 862.9636 - val_mae: 862.9636\n",
      "Epoch 84/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 879.6638 - mae: 879.6638 - val_loss: 859.1970 - val_mae: 859.1970\n",
      "Epoch 85/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.3284 - mae: 879.3284 - val_loss: 858.3524 - val_mae: 858.3524\n",
      "Epoch 86/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 875.8842 - mae: 875.8842 - val_loss: 859.0507 - val_mae: 859.0507\n",
      "Epoch 87/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.0072 - mae: 880.0072 - val_loss: 859.0177 - val_mae: 859.0177\n",
      "Epoch 88/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.3773 - mae: 881.3773 - val_loss: 860.8403 - val_mae: 860.8403\n",
      "Epoch 89/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 879.3951 - mae: 879.3951 - val_loss: 860.1949 - val_mae: 860.1949\n",
      "Epoch 90/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 879.1792 - mae: 879.1792 - val_loss: 860.9679 - val_mae: 860.9679\n",
      "Epoch 91/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.0057 - mae: 880.0057 - val_loss: 859.6823 - val_mae: 859.6823\n",
      "Epoch 92/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.1262 - mae: 880.1262 - val_loss: 857.5308 - val_mae: 857.5308\n",
      "Epoch 93/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.0255 - mae: 880.0255 - val_loss: 858.4283 - val_mae: 858.4283\n",
      "Epoch 94/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 876.0623 - mae: 876.0623 - val_loss: 859.8346 - val_mae: 859.8346\n",
      "Epoch 95/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 877.4439 - mae: 877.4439 - val_loss: 862.7544 - val_mae: 862.7544\n",
      "Epoch 96/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 876.8674 - mae: 876.8674 - val_loss: 857.3715 - val_mae: 857.3715\n",
      "Epoch 97/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 877.6993 - mae: 877.6993 - val_loss: 858.2350 - val_mae: 858.2350\n",
      "Epoch 98/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.0211 - mae: 878.0211 - val_loss: 858.2385 - val_mae: 858.2385\n",
      "Epoch 99/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 877.7388 - mae: 877.7388 - val_loss: 862.8573 - val_mae: 862.8573\n",
      "Epoch 100/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.7271 - mae: 878.7271 - val_loss: 861.1461 - val_mae: 861.1461\n",
      "Fold 4 - Loss: 861.1459, MAE: 861.1459\n",
      "Fold 5 / 7\n",
      "Epoch 1/100\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 2087.8677 - mae: 2087.8677 - val_loss: 1110.7527 - val_mae: 1110.7527\n",
      "Epoch 2/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 988.5353 - mae: 988.5353 - val_loss: 884.2665 - val_mae: 884.2665\n",
      "Epoch 3/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 887.3401 - mae: 887.3401 - val_loss: 869.4693 - val_mae: 869.4693\n",
      "Epoch 4/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 883.4454 - mae: 883.4454 - val_loss: 864.1019 - val_mae: 864.1019\n",
      "Epoch 5/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.6102 - mae: 882.6102 - val_loss: 870.3184 - val_mae: 870.3184\n",
      "Epoch 6/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 884.8124 - mae: 884.8124 - val_loss: 865.4060 - val_mae: 865.4060\n",
      "Epoch 7/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 883.0063 - mae: 883.0063 - val_loss: 864.0132 - val_mae: 864.0132\n",
      "Epoch 8/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 883.6518 - mae: 883.6518 - val_loss: 869.4987 - val_mae: 869.4987\n",
      "Epoch 9/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.9619 - mae: 882.9619 - val_loss: 864.9034 - val_mae: 864.9034\n",
      "Epoch 10/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 884.2015 - mae: 884.2015 - val_loss: 866.4155 - val_mae: 866.4155\n",
      "Epoch 11/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.2515 - mae: 883.2515 - val_loss: 865.3530 - val_mae: 865.3530\n",
      "Epoch 12/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 884.6683 - mae: 884.6683 - val_loss: 864.0449 - val_mae: 864.0449\n",
      "Epoch 13/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.9706 - mae: 882.9706 - val_loss: 865.9379 - val_mae: 865.9379\n",
      "Epoch 14/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.3361 - mae: 882.3361 - val_loss: 864.0566 - val_mae: 864.0566\n",
      "Epoch 15/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.4708 - mae: 881.4708 - val_loss: 865.9669 - val_mae: 865.9669\n",
      "Epoch 16/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.4833 - mae: 882.4833 - val_loss: 873.7624 - val_mae: 873.7624\n",
      "Epoch 17/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.7341 - mae: 881.7341 - val_loss: 866.1734 - val_mae: 866.1734\n",
      "Epoch 18/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.7350 - mae: 882.7350 - val_loss: 864.4484 - val_mae: 864.4484\n",
      "Epoch 19/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.4998 - mae: 883.4998 - val_loss: 867.6863 - val_mae: 867.6863\n",
      "Epoch 20/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 883.2758 - mae: 883.2758 - val_loss: 863.5533 - val_mae: 863.5533\n",
      "Epoch 21/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.6555 - mae: 882.6555 - val_loss: 868.2999 - val_mae: 868.2999\n",
      "Epoch 22/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.6914 - mae: 882.6914 - val_loss: 864.9959 - val_mae: 864.9959\n",
      "Epoch 23/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 885.0886 - mae: 885.0886 - val_loss: 866.2144 - val_mae: 866.2144\n",
      "Epoch 24/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 878.9292 - mae: 878.9292 - val_loss: 864.7141 - val_mae: 864.7141\n",
      "Epoch 25/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.7699 - mae: 881.7699 - val_loss: 867.8887 - val_mae: 867.8887\n",
      "Epoch 26/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.9500 - mae: 880.9500 - val_loss: 864.4930 - val_mae: 864.4930\n",
      "Epoch 27/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.5951 - mae: 881.5951 - val_loss: 862.3099 - val_mae: 862.3099\n",
      "Epoch 28/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.4223 - mae: 881.4223 - val_loss: 864.8728 - val_mae: 864.8728\n",
      "Epoch 29/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.9324 - mae: 882.9324 - val_loss: 865.0980 - val_mae: 865.0980\n",
      "Epoch 30/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.8041 - mae: 881.8041 - val_loss: 864.4105 - val_mae: 864.4105\n",
      "Epoch 31/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.5593 - mae: 881.5593 - val_loss: 864.6987 - val_mae: 864.6987\n",
      "Epoch 32/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.1556 - mae: 882.1556 - val_loss: 864.3723 - val_mae: 864.3723\n",
      "Epoch 33/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.4485 - mae: 882.4485 - val_loss: 866.2111 - val_mae: 866.2111\n",
      "Epoch 34/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.5749 - mae: 882.5749 - val_loss: 862.0482 - val_mae: 862.0482\n",
      "Epoch 35/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.9765 - mae: 880.9765 - val_loss: 864.3423 - val_mae: 864.3423\n",
      "Epoch 36/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.8342 - mae: 880.8342 - val_loss: 864.8756 - val_mae: 864.8756\n",
      "Epoch 37/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.1475 - mae: 880.1475 - val_loss: 861.7418 - val_mae: 861.7418\n",
      "Epoch 38/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.6822 - mae: 881.6822 - val_loss: 863.1447 - val_mae: 863.1447\n",
      "Epoch 39/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.5184 - mae: 881.5184 - val_loss: 861.5237 - val_mae: 861.5237\n",
      "Epoch 40/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.5071 - mae: 883.5071 - val_loss: 864.1707 - val_mae: 864.1707\n",
      "Epoch 41/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.2852 - mae: 882.2852 - val_loss: 861.6351 - val_mae: 861.6351\n",
      "Epoch 42/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.8581 - mae: 880.8581 - val_loss: 871.3334 - val_mae: 871.3334\n",
      "Epoch 43/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.7922 - mae: 882.7922 - val_loss: 863.4156 - val_mae: 863.4156\n",
      "Epoch 44/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.5395 - mae: 880.5395 - val_loss: 865.4811 - val_mae: 865.4811\n",
      "Epoch 45/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 878.8387 - mae: 878.8387 - val_loss: 865.4810 - val_mae: 865.4810\n",
      "Epoch 46/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.4088 - mae: 880.4088 - val_loss: 866.1097 - val_mae: 866.1097\n",
      "Epoch 47/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.8297 - mae: 880.8297 - val_loss: 864.6973 - val_mae: 864.6973\n",
      "Epoch 48/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.0023 - mae: 881.0023 - val_loss: 865.0799 - val_mae: 865.0799\n",
      "Epoch 49/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.1691 - mae: 878.1691 - val_loss: 866.4724 - val_mae: 866.4724\n",
      "Epoch 50/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.8232 - mae: 881.8232 - val_loss: 862.6896 - val_mae: 862.6896\n",
      "Epoch 51/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.3312 - mae: 881.3312 - val_loss: 865.7112 - val_mae: 865.7112\n",
      "Epoch 52/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.3521 - mae: 880.3521 - val_loss: 863.4226 - val_mae: 863.4226\n",
      "Epoch 53/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.0382 - mae: 879.0382 - val_loss: 863.9304 - val_mae: 863.9304\n",
      "Epoch 54/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.4858 - mae: 880.4858 - val_loss: 866.5178 - val_mae: 866.5178\n",
      "Epoch 55/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.5601 - mae: 881.5601 - val_loss: 872.7940 - val_mae: 872.7940\n",
      "Epoch 56/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.1726 - mae: 880.1726 - val_loss: 865.6683 - val_mae: 865.6683\n",
      "Epoch 57/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.5341 - mae: 881.5341 - val_loss: 865.6960 - val_mae: 865.6960\n",
      "Epoch 58/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.4432 - mae: 881.4432 - val_loss: 864.7649 - val_mae: 864.7649\n",
      "Epoch 59/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 878.8367 - mae: 878.8367 - val_loss: 861.5902 - val_mae: 861.5902\n",
      "Epoch 60/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.8475 - mae: 879.8475 - val_loss: 864.3894 - val_mae: 864.3894\n",
      "Epoch 61/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.4543 - mae: 879.4543 - val_loss: 866.5193 - val_mae: 866.5193\n",
      "Epoch 62/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.5093 - mae: 882.5093 - val_loss: 863.7800 - val_mae: 863.7800\n",
      "Epoch 63/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.4446 - mae: 879.4446 - val_loss: 864.7157 - val_mae: 864.7157\n",
      "Epoch 64/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.7479 - mae: 881.7479 - val_loss: 864.6810 - val_mae: 864.6810\n",
      "Epoch 65/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 879.9340 - mae: 879.9340 - val_loss: 872.3306 - val_mae: 872.3306\n",
      "Epoch 66/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.2875 - mae: 881.2875 - val_loss: 862.6809 - val_mae: 862.6809\n",
      "Epoch 67/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 879.8547 - mae: 879.8547 - val_loss: 862.2119 - val_mae: 862.2119\n",
      "Epoch 68/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 879.5263 - mae: 879.5263 - val_loss: 866.1914 - val_mae: 866.1914\n",
      "Epoch 69/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.7678 - mae: 880.7678 - val_loss: 861.0563 - val_mae: 861.0563\n",
      "Epoch 70/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 883.6516 - mae: 883.6516 - val_loss: 862.0368 - val_mae: 862.0368\n",
      "Epoch 71/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.4307 - mae: 879.4307 - val_loss: 864.9944 - val_mae: 864.9944\n",
      "Epoch 72/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.9148 - mae: 879.9148 - val_loss: 863.4316 - val_mae: 863.4316\n",
      "Epoch 73/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 879.5282 - mae: 879.5282 - val_loss: 860.5036 - val_mae: 860.5036\n",
      "Epoch 74/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.9824 - mae: 878.9824 - val_loss: 862.0924 - val_mae: 862.0924\n",
      "Epoch 75/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.3159 - mae: 881.3159 - val_loss: 861.9570 - val_mae: 861.9570\n",
      "Epoch 76/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.3686 - mae: 879.3686 - val_loss: 862.6684 - val_mae: 862.6684\n",
      "Epoch 77/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 879.5706 - mae: 879.5706 - val_loss: 861.2454 - val_mae: 861.2454\n",
      "Epoch 78/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.0734 - mae: 879.0734 - val_loss: 861.9517 - val_mae: 861.9517\n",
      "Epoch 79/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.9243 - mae: 878.9243 - val_loss: 862.2473 - val_mae: 862.2473\n",
      "Epoch 80/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.1339 - mae: 879.1339 - val_loss: 859.9709 - val_mae: 859.9709\n",
      "Epoch 81/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.9445 - mae: 878.9445 - val_loss: 860.1951 - val_mae: 860.1951\n",
      "Epoch 82/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.2107 - mae: 881.2107 - val_loss: 860.9939 - val_mae: 860.9939\n",
      "Epoch 83/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.5044 - mae: 880.5044 - val_loss: 861.4642 - val_mae: 861.4642\n",
      "Epoch 84/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.1665 - mae: 880.1665 - val_loss: 862.1520 - val_mae: 862.1520\n",
      "Epoch 85/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.3856 - mae: 879.3856 - val_loss: 860.5567 - val_mae: 860.5567\n",
      "Epoch 86/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.6404 - mae: 880.6404 - val_loss: 859.9563 - val_mae: 859.9563\n",
      "Epoch 87/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.6965 - mae: 878.6965 - val_loss: 861.2021 - val_mae: 861.2021\n",
      "Epoch 88/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.2265 - mae: 879.2265 - val_loss: 861.1084 - val_mae: 861.1084\n",
      "Epoch 89/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.3792 - mae: 879.3792 - val_loss: 861.1099 - val_mae: 861.1099\n",
      "Epoch 90/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 877.8049 - mae: 877.8049 - val_loss: 863.5598 - val_mae: 863.5598\n",
      "Epoch 91/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.1829 - mae: 880.1829 - val_loss: 861.2878 - val_mae: 861.2878\n",
      "Epoch 92/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.1129 - mae: 880.1129 - val_loss: 859.0134 - val_mae: 859.0134\n",
      "Epoch 93/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 878.0094 - mae: 878.0094 - val_loss: 861.5255 - val_mae: 861.5255\n",
      "Epoch 94/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 876.8177 - mae: 876.8177 - val_loss: 864.9612 - val_mae: 864.9612\n",
      "Epoch 95/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 879.5750 - mae: 879.5750 - val_loss: 858.7194 - val_mae: 858.7194\n",
      "Epoch 96/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 877.3229 - mae: 877.3229 - val_loss: 859.9839 - val_mae: 859.9839\n",
      "Epoch 97/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 877.1157 - mae: 877.1157 - val_loss: 860.7230 - val_mae: 860.7230\n",
      "Epoch 98/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 876.8666 - mae: 876.8666 - val_loss: 863.7717 - val_mae: 863.7717\n",
      "Epoch 99/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 876.5616 - mae: 876.5616 - val_loss: 862.4402 - val_mae: 862.4402\n",
      "Epoch 100/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 878.7804 - mae: 878.7804 - val_loss: 860.3421 - val_mae: 860.3421\n",
      "Fold 5 - Loss: 860.3421, MAE: 860.3421\n",
      "Fold 6 / 7\n",
      "Epoch 1/100\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 2054.9097 - mae: 2054.9097 - val_loss: 1108.4615 - val_mae: 1108.4615\n",
      "Epoch 2/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 982.6470 - mae: 982.6470 - val_loss: 875.5101 - val_mae: 875.5101\n",
      "Epoch 3/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 889.9888 - mae: 889.9888 - val_loss: 860.3912 - val_mae: 860.3912\n",
      "Epoch 4/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 888.2007 - mae: 888.2007 - val_loss: 859.9124 - val_mae: 859.9124\n",
      "Epoch 5/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 885.2469 - mae: 885.2469 - val_loss: 856.8539 - val_mae: 856.8539\n",
      "Epoch 6/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 884.5477 - mae: 884.5477 - val_loss: 857.5953 - val_mae: 857.5953\n",
      "Epoch 7/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 884.0039 - mae: 884.0039 - val_loss: 856.2244 - val_mae: 856.2244\n",
      "Epoch 8/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 884.2426 - mae: 884.2426 - val_loss: 860.9861 - val_mae: 860.9861\n",
      "Epoch 9/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 885.9379 - mae: 885.9379 - val_loss: 855.5562 - val_mae: 855.5562\n",
      "Epoch 10/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 884.0619 - mae: 884.0619 - val_loss: 854.4178 - val_mae: 854.4178\n",
      "Epoch 11/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 885.5460 - mae: 885.5460 - val_loss: 855.0196 - val_mae: 855.0196\n",
      "Epoch 12/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.5131 - mae: 882.5131 - val_loss: 858.6276 - val_mae: 858.6276\n",
      "Epoch 13/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 887.2676 - mae: 887.2676 - val_loss: 858.3182 - val_mae: 858.3182\n",
      "Epoch 14/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 886.3675 - mae: 886.3675 - val_loss: 865.2145 - val_mae: 865.2145\n",
      "Epoch 15/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.6694 - mae: 882.6694 - val_loss: 855.7576 - val_mae: 855.7576\n",
      "Epoch 16/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.7642 - mae: 881.7642 - val_loss: 858.5167 - val_mae: 858.5167\n",
      "Epoch 17/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 885.2422 - mae: 885.2422 - val_loss: 854.2854 - val_mae: 854.2854\n",
      "Epoch 18/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.5710 - mae: 882.5710 - val_loss: 854.9748 - val_mae: 854.9748\n",
      "Epoch 19/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 885.2283 - mae: 885.2283 - val_loss: 858.9866 - val_mae: 858.9866\n",
      "Epoch 20/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.0005 - mae: 883.0005 - val_loss: 854.0087 - val_mae: 854.0087\n",
      "Epoch 21/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.9828 - mae: 883.9828 - val_loss: 854.2462 - val_mae: 854.2462\n",
      "Epoch 22/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.1808 - mae: 883.1808 - val_loss: 856.9998 - val_mae: 856.9998\n",
      "Epoch 23/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.8818 - mae: 883.8818 - val_loss: 856.9211 - val_mae: 856.9211\n",
      "Epoch 24/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.2938 - mae: 882.2938 - val_loss: 856.6517 - val_mae: 856.6517\n",
      "Epoch 25/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.9811 - mae: 881.9811 - val_loss: 856.5107 - val_mae: 856.5107\n",
      "Epoch 26/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 883.8159 - mae: 883.8159 - val_loss: 856.7748 - val_mae: 856.7748\n",
      "Epoch 27/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 884.5652 - mae: 884.5652 - val_loss: 854.5220 - val_mae: 854.5220\n",
      "Epoch 28/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.8396 - mae: 882.8396 - val_loss: 858.9299 - val_mae: 858.9299\n",
      "Epoch 29/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.1853 - mae: 881.1853 - val_loss: 857.1882 - val_mae: 857.1882\n",
      "Epoch 30/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.4640 - mae: 883.4640 - val_loss: 857.2484 - val_mae: 857.2484\n",
      "Epoch 31/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.7593 - mae: 882.7593 - val_loss: 857.4147 - val_mae: 857.4147\n",
      "Epoch 32/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.6309 - mae: 882.6309 - val_loss: 855.1967 - val_mae: 855.1967\n",
      "Epoch 33/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.8569 - mae: 883.8569 - val_loss: 853.6147 - val_mae: 853.6147\n",
      "Epoch 34/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.6837 - mae: 882.6837 - val_loss: 857.6896 - val_mae: 857.6896\n",
      "Epoch 35/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 879.7395 - mae: 879.7395 - val_loss: 854.9661 - val_mae: 854.9661\n",
      "Epoch 36/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.4972 - mae: 880.4972 - val_loss: 854.0870 - val_mae: 854.0870\n",
      "Epoch 37/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.3498 - mae: 882.3498 - val_loss: 857.2349 - val_mae: 857.2349\n",
      "Epoch 38/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.6543 - mae: 881.6543 - val_loss: 852.6714 - val_mae: 852.6714\n",
      "Epoch 39/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.2556 - mae: 882.2556 - val_loss: 853.6732 - val_mae: 853.6732\n",
      "Epoch 40/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 878.9353 - mae: 878.9353 - val_loss: 857.4363 - val_mae: 857.4363\n",
      "Epoch 41/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.0381 - mae: 881.0381 - val_loss: 852.9183 - val_mae: 852.9183\n",
      "Epoch 42/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.4386 - mae: 880.4386 - val_loss: 855.4222 - val_mae: 855.4222\n",
      "Epoch 43/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.4031 - mae: 881.4031 - val_loss: 853.3095 - val_mae: 853.3095\n",
      "Epoch 44/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.6345 - mae: 882.6345 - val_loss: 855.1493 - val_mae: 855.1493\n",
      "Epoch 45/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 879.9595 - mae: 879.9595 - val_loss: 855.8639 - val_mae: 855.8639\n",
      "Epoch 46/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.6815 - mae: 880.6815 - val_loss: 854.1045 - val_mae: 854.1045\n",
      "Epoch 47/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.6047 - mae: 880.6047 - val_loss: 853.4301 - val_mae: 853.4301\n",
      "Epoch 48/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 878.8942 - mae: 878.8942 - val_loss: 853.8120 - val_mae: 853.8120\n",
      "Epoch 49/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.2741 - mae: 883.2741 - val_loss: 852.4353 - val_mae: 852.4353\n",
      "Epoch 50/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 877.6464 - mae: 877.6464 - val_loss: 853.8705 - val_mae: 853.8705\n",
      "Epoch 51/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.4344 - mae: 881.4344 - val_loss: 854.7784 - val_mae: 854.7784\n",
      "Epoch 52/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.4307 - mae: 879.4307 - val_loss: 852.2971 - val_mae: 852.2971\n",
      "Epoch 53/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 878.9506 - mae: 878.9506 - val_loss: 859.0958 - val_mae: 859.0958\n",
      "Epoch 54/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.6443 - mae: 879.6443 - val_loss: 855.1270 - val_mae: 855.1270\n",
      "Epoch 55/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.8525 - mae: 878.8525 - val_loss: 856.2856 - val_mae: 856.2856\n",
      "Epoch 56/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.2919 - mae: 880.2919 - val_loss: 852.4017 - val_mae: 852.4017\n",
      "Epoch 57/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.3182 - mae: 878.3182 - val_loss: 856.6320 - val_mae: 856.6320\n",
      "Epoch 58/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.7324 - mae: 878.7324 - val_loss: 851.2219 - val_mae: 851.2219\n",
      "Epoch 59/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.8248 - mae: 879.8248 - val_loss: 853.3477 - val_mae: 853.3477\n",
      "Epoch 60/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.0408 - mae: 878.0408 - val_loss: 853.6468 - val_mae: 853.6468\n",
      "Epoch 61/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.7770 - mae: 880.7770 - val_loss: 851.3224 - val_mae: 851.3224\n",
      "Epoch 62/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.1135 - mae: 879.1135 - val_loss: 855.3819 - val_mae: 855.3819\n",
      "Epoch 63/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.2228 - mae: 879.2228 - val_loss: 852.5846 - val_mae: 852.5846\n",
      "Epoch 64/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 875.7603 - mae: 875.7603 - val_loss: 852.7781 - val_mae: 852.7781\n",
      "Epoch 65/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.6202 - mae: 879.6202 - val_loss: 852.8633 - val_mae: 852.8633\n",
      "Epoch 66/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 878.1979 - mae: 878.1979 - val_loss: 852.7283 - val_mae: 852.7283\n",
      "Epoch 67/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 879.1602 - mae: 879.1602 - val_loss: 856.2679 - val_mae: 856.2679\n",
      "Epoch 68/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 877.6166 - mae: 877.6166 - val_loss: 853.9412 - val_mae: 853.9412\n",
      "Epoch 69/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.9348 - mae: 879.9348 - val_loss: 857.4579 - val_mae: 857.4579\n",
      "Epoch 70/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.4049 - mae: 879.4049 - val_loss: 854.8326 - val_mae: 854.8326\n",
      "Epoch 71/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.7606 - mae: 879.7606 - val_loss: 851.4562 - val_mae: 851.4562\n",
      "Epoch 72/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 877.6446 - mae: 877.6446 - val_loss: 851.2535 - val_mae: 851.2535\n",
      "Epoch 73/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 876.9796 - mae: 876.9796 - val_loss: 854.7114 - val_mae: 854.7114\n",
      "Epoch 74/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.6267 - mae: 879.6267 - val_loss: 852.8088 - val_mae: 852.8088\n",
      "Epoch 75/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.0303 - mae: 879.0303 - val_loss: 851.2057 - val_mae: 851.2057\n",
      "Epoch 76/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 879.0469 - mae: 879.0469 - val_loss: 856.8972 - val_mae: 856.8972\n",
      "Epoch 77/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.1556 - mae: 879.1556 - val_loss: 852.9267 - val_mae: 852.9267\n",
      "Epoch 78/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.6804 - mae: 878.6804 - val_loss: 851.5523 - val_mae: 851.5523\n",
      "Epoch 79/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.5447 - mae: 879.5447 - val_loss: 855.9689 - val_mae: 855.9689\n",
      "Epoch 80/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 877.7656 - mae: 877.7656 - val_loss: 856.6879 - val_mae: 856.6879\n",
      "Epoch 81/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.7805 - mae: 878.7805 - val_loss: 853.3063 - val_mae: 853.3063\n",
      "Epoch 82/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.8777 - mae: 878.8777 - val_loss: 858.4905 - val_mae: 858.4905\n",
      "Epoch 83/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 877.5909 - mae: 877.5909 - val_loss: 852.4233 - val_mae: 852.4233\n",
      "Epoch 84/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 877.3085 - mae: 877.3085 - val_loss: 850.7278 - val_mae: 850.7278\n",
      "Epoch 85/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 877.4365 - mae: 877.4365 - val_loss: 854.3020 - val_mae: 854.3020\n",
      "Epoch 86/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.4759 - mae: 879.4759 - val_loss: 852.1458 - val_mae: 852.1458\n",
      "Epoch 87/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 878.1238 - mae: 878.1238 - val_loss: 852.1080 - val_mae: 852.1080\n",
      "Epoch 88/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 877.4901 - mae: 877.4901 - val_loss: 853.5273 - val_mae: 853.5273\n",
      "Epoch 89/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.4300 - mae: 880.4300 - val_loss: 852.8004 - val_mae: 852.8004\n",
      "Epoch 90/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.1285 - mae: 880.1285 - val_loss: 854.9102 - val_mae: 854.9102\n",
      "Epoch 91/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.3033 - mae: 878.3033 - val_loss: 851.5831 - val_mae: 851.5831\n",
      "Epoch 92/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.0641 - mae: 878.0641 - val_loss: 855.8862 - val_mae: 855.8862\n",
      "Epoch 93/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 878.3193 - mae: 878.3193 - val_loss: 853.3059 - val_mae: 853.3059\n",
      "Epoch 94/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 877.4919 - mae: 877.4919 - val_loss: 859.3304 - val_mae: 859.3304\n",
      "Epoch 95/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 877.0549 - mae: 877.0549 - val_loss: 855.7745 - val_mae: 855.7745\n",
      "Epoch 96/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 877.9119 - mae: 877.9119 - val_loss: 853.7853 - val_mae: 853.7853\n",
      "Epoch 97/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.5786 - mae: 878.5786 - val_loss: 851.1143 - val_mae: 851.1143\n",
      "Epoch 98/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 877.8259 - mae: 877.8259 - val_loss: 852.8764 - val_mae: 852.8764\n",
      "Epoch 99/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.3940 - mae: 879.3940 - val_loss: 859.2745 - val_mae: 859.2745\n",
      "Epoch 100/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 877.8011 - mae: 877.8011 - val_loss: 851.3919 - val_mae: 851.3919\n",
      "Fold 6 - Loss: 851.3918, MAE: 851.3918\n",
      "Fold 7 / 7\n",
      "Epoch 1/100\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 1970.6051 - mae: 1970.6051 - val_loss: 1059.7538 - val_mae: 1059.7538\n",
      "Epoch 2/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 957.6292 - mae: 957.6292 - val_loss: 868.9127 - val_mae: 868.9127\n",
      "Epoch 3/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 890.6719 - mae: 890.6719 - val_loss: 854.7930 - val_mae: 854.7930\n",
      "Epoch 4/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 888.6416 - mae: 888.6416 - val_loss: 854.5219 - val_mae: 854.5219\n",
      "Epoch 5/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 886.7277 - mae: 886.7277 - val_loss: 853.4197 - val_mae: 853.4197\n",
      "Epoch 6/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.9342 - mae: 883.9342 - val_loss: 855.5111 - val_mae: 855.5111\n",
      "Epoch 7/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 885.2626 - mae: 885.2626 - val_loss: 855.8468 - val_mae: 855.8468\n",
      "Epoch 8/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 887.8787 - mae: 887.8787 - val_loss: 853.6923 - val_mae: 853.6923\n",
      "Epoch 9/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 883.8967 - mae: 883.8967 - val_loss: 853.2924 - val_mae: 853.2924\n",
      "Epoch 10/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.7358 - mae: 883.7358 - val_loss: 851.4097 - val_mae: 851.4097\n",
      "Epoch 11/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 885.2049 - mae: 885.2049 - val_loss: 853.0603 - val_mae: 853.0603\n",
      "Epoch 12/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 884.4387 - mae: 884.4387 - val_loss: 858.1583 - val_mae: 858.1583\n",
      "Epoch 13/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 883.1761 - mae: 883.1761 - val_loss: 857.6523 - val_mae: 857.6523\n",
      "Epoch 14/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 885.4233 - mae: 885.4233 - val_loss: 850.9709 - val_mae: 850.9709\n",
      "Epoch 15/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 884.2975 - mae: 884.2975 - val_loss: 851.4825 - val_mae: 851.4825\n",
      "Epoch 16/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 884.0879 - mae: 884.0879 - val_loss: 850.9675 - val_mae: 850.9675\n",
      "Epoch 17/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 884.9548 - mae: 884.9548 - val_loss: 851.3611 - val_mae: 851.3611\n",
      "Epoch 18/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 883.8183 - mae: 883.8183 - val_loss: 852.7294 - val_mae: 852.7294\n",
      "Epoch 19/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 883.2617 - mae: 883.2617 - val_loss: 851.9036 - val_mae: 851.9036\n",
      "Epoch 20/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.4484 - mae: 882.4484 - val_loss: 851.8319 - val_mae: 851.8319\n",
      "Epoch 21/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.0563 - mae: 883.0563 - val_loss: 852.9606 - val_mae: 852.9606\n",
      "Epoch 22/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.8478 - mae: 881.8478 - val_loss: 854.9038 - val_mae: 854.9038\n",
      "Epoch 23/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.1877 - mae: 883.1877 - val_loss: 851.5105 - val_mae: 851.5105\n",
      "Epoch 24/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.3283 - mae: 882.3283 - val_loss: 851.4388 - val_mae: 851.4388\n",
      "Epoch 25/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.3163 - mae: 883.3163 - val_loss: 854.0812 - val_mae: 854.0812\n",
      "Epoch 26/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.2079 - mae: 882.2079 - val_loss: 851.7819 - val_mae: 851.7819\n",
      "Epoch 27/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.1320 - mae: 883.1320 - val_loss: 851.1407 - val_mae: 851.1407\n",
      "Epoch 28/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.5681 - mae: 881.5681 - val_loss: 849.7961 - val_mae: 849.7961\n",
      "Epoch 29/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.7039 - mae: 882.7039 - val_loss: 860.3917 - val_mae: 860.3917\n",
      "Epoch 30/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 884.0334 - mae: 884.0334 - val_loss: 850.9003 - val_mae: 850.9003\n",
      "Epoch 31/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.3073 - mae: 879.3073 - val_loss: 852.8126 - val_mae: 852.8126\n",
      "Epoch 32/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.8909 - mae: 880.8909 - val_loss: 849.3726 - val_mae: 849.3726\n",
      "Epoch 33/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.7780 - mae: 882.7780 - val_loss: 851.3370 - val_mae: 851.3370\n",
      "Epoch 34/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.9640 - mae: 879.9640 - val_loss: 847.9383 - val_mae: 847.9383\n",
      "Epoch 35/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.6017 - mae: 882.6017 - val_loss: 849.8491 - val_mae: 849.8491\n",
      "Epoch 36/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.2676 - mae: 880.2676 - val_loss: 850.5082 - val_mae: 850.5082\n",
      "Epoch 37/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 884.0258 - mae: 884.0258 - val_loss: 847.5508 - val_mae: 847.5508\n",
      "Epoch 38/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 884.2798 - mae: 884.2798 - val_loss: 849.5992 - val_mae: 849.5992\n",
      "Epoch 39/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.3691 - mae: 881.3691 - val_loss: 853.9183 - val_mae: 853.9183\n",
      "Epoch 40/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.9576 - mae: 881.9576 - val_loss: 854.6193 - val_mae: 854.6193\n",
      "Epoch 41/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.1074 - mae: 881.1074 - val_loss: 849.1718 - val_mae: 849.1718\n",
      "Epoch 42/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.4484 - mae: 882.4484 - val_loss: 849.3815 - val_mae: 849.3815\n",
      "Epoch 43/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.9413 - mae: 882.9413 - val_loss: 849.7180 - val_mae: 849.7180\n",
      "Epoch 44/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.3223 - mae: 882.3223 - val_loss: 849.9152 - val_mae: 849.9152\n",
      "Epoch 45/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.6622 - mae: 881.6622 - val_loss: 847.7901 - val_mae: 847.7901\n",
      "Epoch 46/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.8856 - mae: 880.8856 - val_loss: 850.2963 - val_mae: 850.2963\n",
      "Epoch 47/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.8481 - mae: 880.8481 - val_loss: 857.4353 - val_mae: 857.4353\n",
      "Epoch 48/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.5339 - mae: 882.5339 - val_loss: 851.3048 - val_mae: 851.3048\n",
      "Epoch 49/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.6192 - mae: 882.6192 - val_loss: 849.2012 - val_mae: 849.2012\n",
      "Epoch 50/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.9059 - mae: 881.9059 - val_loss: 852.7855 - val_mae: 852.7855\n",
      "Epoch 51/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.1790 - mae: 882.1790 - val_loss: 848.1900 - val_mae: 848.1900\n",
      "Epoch 52/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.7413 - mae: 882.7413 - val_loss: 851.9634 - val_mae: 851.9634\n",
      "Epoch 53/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.9623 - mae: 880.9623 - val_loss: 849.8754 - val_mae: 849.8754\n",
      "Epoch 54/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 879.6768 - mae: 879.6768 - val_loss: 849.0960 - val_mae: 849.0960\n",
      "Epoch 55/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.5981 - mae: 882.5981 - val_loss: 850.1569 - val_mae: 850.1569\n",
      "Epoch 56/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.7349 - mae: 880.7349 - val_loss: 851.3046 - val_mae: 851.3046\n",
      "Epoch 57/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.0904 - mae: 881.0904 - val_loss: 848.6489 - val_mae: 848.6489\n",
      "Epoch 58/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.4363 - mae: 881.4363 - val_loss: 857.1568 - val_mae: 857.1568\n",
      "Epoch 59/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.9445 - mae: 880.9445 - val_loss: 850.9023 - val_mae: 850.9023\n",
      "Epoch 60/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.0250 - mae: 880.0250 - val_loss: 851.3195 - val_mae: 851.3195\n",
      "Epoch 61/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.0833 - mae: 880.0833 - val_loss: 850.8105 - val_mae: 850.8105\n",
      "Epoch 62/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 879.5135 - mae: 879.5135 - val_loss: 849.7808 - val_mae: 849.7808\n",
      "Epoch 63/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 879.3372 - mae: 879.3372 - val_loss: 852.2374 - val_mae: 852.2374\n",
      "Epoch 64/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 879.7610 - mae: 879.7610 - val_loss: 848.5576 - val_mae: 848.5576\n",
      "Epoch 65/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.3795 - mae: 880.3795 - val_loss: 848.9329 - val_mae: 848.9329\n",
      "Epoch 66/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.4484 - mae: 880.4484 - val_loss: 848.9026 - val_mae: 848.9026\n",
      "Epoch 67/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 879.1194 - mae: 879.1194 - val_loss: 850.9493 - val_mae: 850.9493\n",
      "Epoch 68/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 879.2186 - mae: 879.2186 - val_loss: 849.8574 - val_mae: 849.8574\n",
      "Epoch 69/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.7203 - mae: 880.7203 - val_loss: 852.0607 - val_mae: 852.0607\n",
      "Epoch 70/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.5571 - mae: 881.5571 - val_loss: 851.1202 - val_mae: 851.1202\n",
      "Epoch 71/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.6691 - mae: 881.6691 - val_loss: 851.4697 - val_mae: 851.4697\n",
      "Epoch 72/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.1723 - mae: 880.1723 - val_loss: 851.5730 - val_mae: 851.5730\n",
      "Epoch 73/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.8536 - mae: 880.8536 - val_loss: 850.8036 - val_mae: 850.8036\n",
      "Epoch 74/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.2697 - mae: 880.2697 - val_loss: 849.8223 - val_mae: 849.8223\n",
      "Epoch 75/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 879.2028 - mae: 879.2028 - val_loss: 847.5557 - val_mae: 847.5557\n",
      "Epoch 76/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.0754 - mae: 878.0754 - val_loss: 855.3257 - val_mae: 855.3257\n",
      "Epoch 77/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 877.6925 - mae: 877.6925 - val_loss: 849.8719 - val_mae: 849.8719\n",
      "Epoch 78/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 879.9612 - mae: 879.9612 - val_loss: 850.3085 - val_mae: 850.3085\n",
      "Epoch 79/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 879.2612 - mae: 879.2612 - val_loss: 847.0787 - val_mae: 847.0787\n",
      "Epoch 80/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.4847 - mae: 881.4847 - val_loss: 850.3719 - val_mae: 850.3719\n",
      "Epoch 81/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 879.7811 - mae: 879.7811 - val_loss: 852.8817 - val_mae: 852.8817\n",
      "Epoch 82/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 878.8821 - mae: 878.8821 - val_loss: 847.1593 - val_mae: 847.1593\n",
      "Epoch 83/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 879.5062 - mae: 879.5062 - val_loss: 852.7899 - val_mae: 852.7899\n",
      "Epoch 84/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.1605 - mae: 881.1605 - val_loss: 848.3316 - val_mae: 848.3316\n",
      "Epoch 85/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.7491 - mae: 881.7491 - val_loss: 854.9768 - val_mae: 854.9768\n",
      "Epoch 86/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 879.9216 - mae: 879.9216 - val_loss: 858.2071 - val_mae: 858.2071\n",
      "Epoch 87/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.4941 - mae: 879.4941 - val_loss: 847.5314 - val_mae: 847.5314\n",
      "Epoch 88/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.2971 - mae: 880.2971 - val_loss: 848.8671 - val_mae: 848.8671\n",
      "Epoch 89/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 877.6266 - mae: 877.6266 - val_loss: 850.8787 - val_mae: 850.8787\n",
      "Epoch 90/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 878.2060 - mae: 878.2060 - val_loss: 848.5558 - val_mae: 848.5558\n",
      "Epoch 91/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 877.5614 - mae: 877.5614 - val_loss: 854.5995 - val_mae: 854.5995\n",
      "Epoch 92/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 878.8597 - mae: 878.8597 - val_loss: 848.7108 - val_mae: 848.7108\n",
      "Epoch 93/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 879.6928 - mae: 879.6928 - val_loss: 846.9637 - val_mae: 846.9637\n",
      "Epoch 94/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.2239 - mae: 878.2239 - val_loss: 846.2076 - val_mae: 846.2076\n",
      "Epoch 95/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 878.2317 - mae: 878.2317 - val_loss: 848.6898 - val_mae: 848.6898\n",
      "Epoch 96/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 875.6545 - mae: 875.6545 - val_loss: 850.0161 - val_mae: 850.0161\n",
      "Epoch 97/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.0755 - mae: 880.0755 - val_loss: 847.1914 - val_mae: 847.1914\n",
      "Epoch 98/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 877.6515 - mae: 877.6515 - val_loss: 846.7141 - val_mae: 846.7141\n",
      "Epoch 99/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 878.3536 - mae: 878.3536 - val_loss: 848.2626 - val_mae: 848.2626\n",
      "Epoch 100/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.0107 - mae: 880.0107 - val_loss: 848.8474 - val_mae: 848.8474\n",
      "Fold 7 - Loss: 848.8475, MAE: 848.8475\n",
      "\n",
      "Cross Validation 7-Fold 결과:\n",
      "MAE 평균: 855.6223, 표준편차: 7.4129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "\n",
    "# K-Fold Cross Validation\n",
    "def cross_validate_model(X_train, y_train, n_splits_list):\n",
    "    for n_splits in n_splits_list:\n",
    "        print(f\"\\n--- Cross Validation: {n_splits}-Fold 시작 ---\\n\")\n",
    "        kfold = KFold(n_splits=n_splits, shuffle=True, random_state=7)\n",
    "\n",
    "        fold_no = 1\n",
    "        mae_per_fold = []\n",
    "        \n",
    "        for train_index, val_index in kfold.split(X_train):\n",
    "            print(f\"Fold {fold_no} / {n_splits}\")\n",
    "            \n",
    "            # 데이터 분할\n",
    "            X_fold_train, X_fold_val = X_train[train_index], X_train[val_index]\n",
    "            y_fold_train, y_fold_val = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "            \n",
    "            # DNN 모델 정의\n",
    "            model = Sequential([\n",
    "                Dense(128, activation='relu', input_shape=(X_fold_train.shape[1],)),\n",
    "                Dropout(0.3),  \n",
    "                Dense(64, activation='relu'),\n",
    "                Dropout(0.2),\n",
    "                Dense(32, activation='relu'), \n",
    "                Dense(1)\n",
    "            ])\n",
    "            \n",
    "            # 모델 컴파일\n",
    "            model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                          loss='mae',\n",
    "                          metrics=['mae'])\n",
    "\n",
    "            # 학습 (GPU 사용)\n",
    "            with tf.device(\"/device:GPU:0\"):\n",
    "                history = model.fit(X_fold_train, y_fold_train, \n",
    "                                    epochs=100,  # 폴드마다 학습 횟수를 조정 가능\n",
    "                                    batch_size=128, \n",
    "                                    validation_data=(X_fold_val, y_fold_val), \n",
    "                                    verbose=1)\n",
    "\n",
    "                # 폴드별 평가\n",
    "                loss, mae = model.evaluate(X_fold_val, y_fold_val, verbose=0)\n",
    "                print(f\"Fold {fold_no} - Loss: {loss:.4f}, MAE: {mae:.4f}\")\n",
    "                mae_per_fold.append(mae)\n",
    "\n",
    "            fold_no += 1\n",
    "\n",
    "        # 평균 MAE 출력\n",
    "        print(f\"\\nCross Validation {n_splits}-Fold 결과:\")\n",
    "        print(f\"MAE 평균: {np.mean(mae_per_fold):.4f}, 표준편차: {np.std(mae_per_fold):.4f}\\n\")\n",
    "\n",
    "# Cross Validation 실행 (3, 5, 7-Fold)\n",
    "n_splits_list = [3, 5, 7]\n",
    "cross_validate_model(X_train1, y_train1, n_splits_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 / 3\n",
      "Epoch 1/200\n",
      "197/197 [==============================] - 1s 4ms/step - loss: 2232.7957 - mae: 2232.7957 - val_loss: 1201.2036 - val_mae: 1201.2036\n",
      "Epoch 2/200\n",
      "197/197 [==============================] - 0s 1ms/step - loss: 1044.5273 - mae: 1044.5273 - val_loss: 913.5385 - val_mae: 913.5385\n",
      "Epoch 3/200\n",
      "197/197 [==============================] - 0s 1ms/step - loss: 901.6115 - mae: 901.6115 - val_loss: 864.8330 - val_mae: 864.8330\n",
      "Epoch 4/200\n",
      "197/197 [==============================] - 0s 1ms/step - loss: 890.9505 - mae: 890.9505 - val_loss: 861.4249 - val_mae: 861.4249\n",
      "Epoch 5/200\n",
      "197/197 [==============================] - 0s 1ms/step - loss: 887.9727 - mae: 887.9727 - val_loss: 860.5688 - val_mae: 860.5688\n",
      "Epoch 6/200\n",
      "197/197 [==============================] - 0s 1ms/step - loss: 884.9762 - mae: 884.9762 - val_loss: 859.8094 - val_mae: 859.8094\n",
      "Epoch 7/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.4091 - mae: 884.4091 - val_loss: 857.6708 - val_mae: 857.6708\n",
      "Epoch 8/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 886.2829 - mae: 886.2829 - val_loss: 862.1735 - val_mae: 862.1735\n",
      "Epoch 9/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.3542 - mae: 883.3542 - val_loss: 859.9576 - val_mae: 859.9576\n",
      "Epoch 10/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.4644 - mae: 883.4644 - val_loss: 857.8570 - val_mae: 857.8570\n",
      "Epoch 11/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 886.4464 - mae: 886.4464 - val_loss: 859.3109 - val_mae: 859.3109\n",
      "Epoch 12/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.1215 - mae: 884.1215 - val_loss: 858.5842 - val_mae: 858.5842\n",
      "Epoch 13/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.1590 - mae: 883.1590 - val_loss: 864.4250 - val_mae: 864.4250\n",
      "Epoch 14/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 886.2395 - mae: 886.2395 - val_loss: 855.8377 - val_mae: 855.8377\n",
      "Epoch 15/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.7759 - mae: 882.7759 - val_loss: 855.8763 - val_mae: 855.8763\n",
      "Epoch 16/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.0922 - mae: 881.0922 - val_loss: 859.4702 - val_mae: 859.4702\n",
      "Epoch 17/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 886.6564 - mae: 886.6564 - val_loss: 855.6563 - val_mae: 855.6563\n",
      "Epoch 18/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.3464 - mae: 884.3464 - val_loss: 860.0305 - val_mae: 860.0305\n",
      "Epoch 19/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.3676 - mae: 882.3676 - val_loss: 855.4534 - val_mae: 855.4534\n",
      "Epoch 20/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.9655 - mae: 882.9655 - val_loss: 860.8378 - val_mae: 860.8378\n",
      "Epoch 21/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.9566 - mae: 882.9566 - val_loss: 856.0837 - val_mae: 856.0837\n",
      "Epoch 22/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.8403 - mae: 880.8403 - val_loss: 860.6111 - val_mae: 860.6111\n",
      "Epoch 23/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.0092 - mae: 881.0092 - val_loss: 856.6626 - val_mae: 856.6626\n",
      "Epoch 24/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.1642 - mae: 879.1642 - val_loss: 863.6932 - val_mae: 863.6932\n",
      "Epoch 25/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.2819 - mae: 882.2819 - val_loss: 855.1547 - val_mae: 855.1547\n",
      "Epoch 26/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.2821 - mae: 884.2821 - val_loss: 857.9128 - val_mae: 857.9128\n",
      "Epoch 27/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.7796 - mae: 882.7796 - val_loss: 855.7973 - val_mae: 855.7973\n",
      "Epoch 28/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.1981 - mae: 881.1981 - val_loss: 857.0216 - val_mae: 857.0216\n",
      "Epoch 29/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.7769 - mae: 879.7769 - val_loss: 861.8105 - val_mae: 861.8105\n",
      "Epoch 30/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.8251 - mae: 882.8251 - val_loss: 854.8399 - val_mae: 854.8399\n",
      "Epoch 31/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.4427 - mae: 882.4427 - val_loss: 859.7832 - val_mae: 859.7832\n",
      "Epoch 32/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.7264 - mae: 883.7264 - val_loss: 860.7460 - val_mae: 860.7460\n",
      "Epoch 33/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.5637 - mae: 882.5637 - val_loss: 857.2191 - val_mae: 857.2191\n",
      "Epoch 34/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.3471 - mae: 881.3471 - val_loss: 856.9235 - val_mae: 856.9235\n",
      "Epoch 35/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.7634 - mae: 880.7634 - val_loss: 859.3471 - val_mae: 859.3471\n",
      "Epoch 36/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.5577 - mae: 879.5577 - val_loss: 858.1633 - val_mae: 858.1633\n",
      "Epoch 37/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.3495 - mae: 880.3495 - val_loss: 860.5035 - val_mae: 860.5035\n",
      "Epoch 38/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.3824 - mae: 882.3824 - val_loss: 863.9326 - val_mae: 863.9326\n",
      "Epoch 39/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.4092 - mae: 882.4092 - val_loss: 865.8253 - val_mae: 865.8253\n",
      "Epoch 40/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.1631 - mae: 884.1631 - val_loss: 854.4202 - val_mae: 854.4202\n",
      "Epoch 41/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.5195 - mae: 882.5195 - val_loss: 864.7506 - val_mae: 864.7506\n",
      "Epoch 42/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.1287 - mae: 881.1287 - val_loss: 854.0806 - val_mae: 854.0806\n",
      "Epoch 43/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.8574 - mae: 882.8574 - val_loss: 855.7275 - val_mae: 855.7275\n",
      "Epoch 44/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.3226 - mae: 884.3226 - val_loss: 855.8918 - val_mae: 855.8918\n",
      "Epoch 45/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.6985 - mae: 881.6985 - val_loss: 855.2169 - val_mae: 855.2169\n",
      "Epoch 46/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.9439 - mae: 882.9439 - val_loss: 860.1588 - val_mae: 860.1588\n",
      "Epoch 47/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.4487 - mae: 881.4487 - val_loss: 854.6215 - val_mae: 854.6215\n",
      "Epoch 48/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.3198 - mae: 879.3198 - val_loss: 854.3777 - val_mae: 854.3777\n",
      "Epoch 49/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.4585 - mae: 884.4585 - val_loss: 855.7766 - val_mae: 855.7766\n",
      "Epoch 50/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.9741 - mae: 882.9741 - val_loss: 863.7874 - val_mae: 863.7874\n",
      "Epoch 51/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.3178 - mae: 879.3178 - val_loss: 856.0070 - val_mae: 856.0070\n",
      "Epoch 52/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.6060 - mae: 884.6060 - val_loss: 857.7477 - val_mae: 857.7477\n",
      "Epoch 53/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.4580 - mae: 879.4580 - val_loss: 861.1744 - val_mae: 861.1744\n",
      "Epoch 54/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.9047 - mae: 879.9047 - val_loss: 855.8291 - val_mae: 855.8291\n",
      "Epoch 55/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.6693 - mae: 881.6693 - val_loss: 860.9260 - val_mae: 860.9260\n",
      "Epoch 56/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.8430 - mae: 881.8430 - val_loss: 857.7506 - val_mae: 857.7506\n",
      "Epoch 57/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.0872 - mae: 884.0872 - val_loss: 858.0031 - val_mae: 858.0031\n",
      "Epoch 58/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.6750 - mae: 883.6750 - val_loss: 858.7273 - val_mae: 858.7273\n",
      "Epoch 59/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.1259 - mae: 882.1259 - val_loss: 858.3799 - val_mae: 858.3799\n",
      "Epoch 60/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.3922 - mae: 882.3922 - val_loss: 856.1527 - val_mae: 856.1527\n",
      "Epoch 61/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.1935 - mae: 880.1935 - val_loss: 857.6829 - val_mae: 857.6829\n",
      "Epoch 62/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.9842 - mae: 879.9842 - val_loss: 854.8184 - val_mae: 854.8184\n",
      "Epoch 63/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.8593 - mae: 882.8593 - val_loss: 858.6425 - val_mae: 858.6425\n",
      "Epoch 64/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.0721 - mae: 881.0721 - val_loss: 853.9976 - val_mae: 853.9976\n",
      "Epoch 65/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.3416 - mae: 880.3416 - val_loss: 860.8519 - val_mae: 860.8519\n",
      "Epoch 66/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.4350 - mae: 880.4350 - val_loss: 856.9460 - val_mae: 856.9460\n",
      "Epoch 67/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.4725 - mae: 879.4725 - val_loss: 856.0930 - val_mae: 856.0930\n",
      "Epoch 68/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.2468 - mae: 879.2468 - val_loss: 858.7156 - val_mae: 858.7156\n",
      "Epoch 69/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.6053 - mae: 880.6053 - val_loss: 859.3767 - val_mae: 859.3767\n",
      "Epoch 70/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.1263 - mae: 882.1263 - val_loss: 858.7775 - val_mae: 858.7775\n",
      "Epoch 71/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.5259 - mae: 879.5259 - val_loss: 854.3760 - val_mae: 854.3760\n",
      "Epoch 72/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.8784 - mae: 880.8784 - val_loss: 859.4594 - val_mae: 859.4594\n",
      "Epoch 73/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.9055 - mae: 879.9055 - val_loss: 855.9171 - val_mae: 855.9171\n",
      "Epoch 74/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.3422 - mae: 881.3422 - val_loss: 858.3751 - val_mae: 858.3751\n",
      "Epoch 75/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.5613 - mae: 879.5613 - val_loss: 856.3480 - val_mae: 856.3480\n",
      "Epoch 76/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.6736 - mae: 878.6736 - val_loss: 854.8348 - val_mae: 854.8348\n",
      "Epoch 77/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.3698 - mae: 881.3698 - val_loss: 859.2711 - val_mae: 859.2711\n",
      "Epoch 78/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.7106 - mae: 880.7106 - val_loss: 856.9283 - val_mae: 856.9283\n",
      "Epoch 79/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.6849 - mae: 884.6849 - val_loss: 859.1754 - val_mae: 859.1754\n",
      "Epoch 80/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.5032 - mae: 884.5032 - val_loss: 854.6860 - val_mae: 854.6860\n",
      "Epoch 81/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.4409 - mae: 881.4409 - val_loss: 854.4558 - val_mae: 854.4558\n",
      "Epoch 82/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 876.5074 - mae: 876.5074 - val_loss: 853.9388 - val_mae: 853.9388\n",
      "Epoch 83/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.8203 - mae: 879.8203 - val_loss: 859.7319 - val_mae: 859.7319\n",
      "Epoch 84/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.1517 - mae: 879.1517 - val_loss: 856.4366 - val_mae: 856.4366\n",
      "Epoch 85/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.9111 - mae: 881.9111 - val_loss: 855.9551 - val_mae: 855.9551\n",
      "Epoch 86/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.7127 - mae: 880.7127 - val_loss: 855.5826 - val_mae: 855.5826\n",
      "Epoch 87/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.7258 - mae: 880.7258 - val_loss: 856.9054 - val_mae: 856.9054\n",
      "Epoch 88/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.4041 - mae: 880.4041 - val_loss: 853.7908 - val_mae: 853.7908\n",
      "Epoch 89/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.0343 - mae: 879.0343 - val_loss: 856.6378 - val_mae: 856.6378\n",
      "Epoch 90/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.2446 - mae: 880.2446 - val_loss: 854.6253 - val_mae: 854.6253\n",
      "Epoch 91/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.1520 - mae: 880.1520 - val_loss: 856.1346 - val_mae: 856.1346\n",
      "Epoch 92/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.1135 - mae: 881.1135 - val_loss: 856.0995 - val_mae: 856.0995\n",
      "Epoch 93/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.6944 - mae: 882.6944 - val_loss: 856.1651 - val_mae: 856.1651\n",
      "Epoch 94/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.3184 - mae: 882.3184 - val_loss: 857.8405 - val_mae: 857.8405\n",
      "Epoch 95/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.2065 - mae: 878.2065 - val_loss: 855.9344 - val_mae: 855.9344\n",
      "Epoch 96/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.0570 - mae: 880.0570 - val_loss: 856.2481 - val_mae: 856.2481\n",
      "Epoch 97/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.4783 - mae: 882.4783 - val_loss: 859.2040 - val_mae: 859.2040\n",
      "Epoch 98/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.7834 - mae: 878.7834 - val_loss: 855.4321 - val_mae: 855.4321\n",
      "Epoch 99/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.9569 - mae: 878.9569 - val_loss: 861.4406 - val_mae: 861.4406\n",
      "Epoch 100/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.5248 - mae: 881.5248 - val_loss: 857.7775 - val_mae: 857.7775\n",
      "Epoch 101/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.7809 - mae: 882.7809 - val_loss: 855.4464 - val_mae: 855.4464\n",
      "Epoch 102/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.3702 - mae: 878.3702 - val_loss: 857.7941 - val_mae: 857.7941\n",
      "Epoch 103/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.9799 - mae: 881.9799 - val_loss: 860.8852 - val_mae: 860.8852\n",
      "Epoch 104/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.7930 - mae: 877.7930 - val_loss: 855.1652 - val_mae: 855.1652\n",
      "Epoch 105/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.4942 - mae: 879.4942 - val_loss: 858.6204 - val_mae: 858.6204\n",
      "Epoch 106/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.7596 - mae: 882.7596 - val_loss: 855.5813 - val_mae: 855.5813\n",
      "Epoch 107/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.6152 - mae: 881.6152 - val_loss: 857.9874 - val_mae: 857.9874\n",
      "Epoch 108/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.0901 - mae: 882.0901 - val_loss: 856.2927 - val_mae: 856.2927\n",
      "Epoch 109/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 876.4261 - mae: 876.4261 - val_loss: 857.5989 - val_mae: 857.5989\n",
      "Epoch 110/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.5853 - mae: 879.5853 - val_loss: 859.4758 - val_mae: 859.4758\n",
      "Epoch 111/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.9111 - mae: 878.9111 - val_loss: 855.8185 - val_mae: 855.8185\n",
      "Epoch 112/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.5593 - mae: 879.5593 - val_loss: 856.4294 - val_mae: 856.4294\n",
      "Epoch 113/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.1376 - mae: 880.1376 - val_loss: 854.6335 - val_mae: 854.6335\n",
      "Epoch 114/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.7234 - mae: 878.7234 - val_loss: 856.8133 - val_mae: 856.8133\n",
      "Epoch 115/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.0784 - mae: 881.0784 - val_loss: 854.9332 - val_mae: 854.9332\n",
      "Epoch 116/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.0867 - mae: 879.0867 - val_loss: 854.2657 - val_mae: 854.2657\n",
      "Epoch 117/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.0216 - mae: 881.0216 - val_loss: 853.4713 - val_mae: 853.4713\n",
      "Epoch 118/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.8897 - mae: 879.8897 - val_loss: 856.2741 - val_mae: 856.2741\n",
      "Epoch 119/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.3654 - mae: 878.3654 - val_loss: 856.3250 - val_mae: 856.3250\n",
      "Epoch 120/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.4465 - mae: 880.4465 - val_loss: 862.9713 - val_mae: 862.9713\n",
      "Epoch 121/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.9645 - mae: 879.9645 - val_loss: 861.1991 - val_mae: 861.1991\n",
      "Epoch 122/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.3040 - mae: 878.3040 - val_loss: 856.0283 - val_mae: 856.0283\n",
      "Epoch 123/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.9276 - mae: 879.9276 - val_loss: 859.3912 - val_mae: 859.3912\n",
      "Epoch 124/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.8994 - mae: 879.8994 - val_loss: 861.8346 - val_mae: 861.8346\n",
      "Epoch 125/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.6581 - mae: 877.6581 - val_loss: 862.5876 - val_mae: 862.5876\n",
      "Epoch 126/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.1993 - mae: 880.1993 - val_loss: 854.1266 - val_mae: 854.1266\n",
      "Epoch 127/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.9538 - mae: 877.9538 - val_loss: 855.2410 - val_mae: 855.2410\n",
      "Epoch 128/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.2316 - mae: 881.2316 - val_loss: 854.9115 - val_mae: 854.9115\n",
      "Epoch 129/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 876.4935 - mae: 876.4935 - val_loss: 856.0522 - val_mae: 856.0522\n",
      "Epoch 130/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.1852 - mae: 879.1852 - val_loss: 857.6367 - val_mae: 857.6367\n",
      "Epoch 131/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.2231 - mae: 881.2231 - val_loss: 857.8615 - val_mae: 857.8615\n",
      "Epoch 132/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.4221 - mae: 878.4221 - val_loss: 854.3883 - val_mae: 854.3883\n",
      "Epoch 133/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.4844 - mae: 877.4844 - val_loss: 861.3234 - val_mae: 861.3234\n",
      "Epoch 134/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.3483 - mae: 878.3483 - val_loss: 853.6448 - val_mae: 853.6448\n",
      "Epoch 135/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.8377 - mae: 878.8377 - val_loss: 854.7975 - val_mae: 854.7975\n",
      "Epoch 136/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.4438 - mae: 877.4438 - val_loss: 856.3257 - val_mae: 856.3257\n",
      "Epoch 137/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.7241 - mae: 877.7241 - val_loss: 855.9194 - val_mae: 855.9194\n",
      "Epoch 138/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.6590 - mae: 877.6590 - val_loss: 857.5411 - val_mae: 857.5411\n",
      "Epoch 139/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.6188 - mae: 877.6188 - val_loss: 856.5508 - val_mae: 856.5508\n",
      "Epoch 140/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.2134 - mae: 878.2134 - val_loss: 857.8998 - val_mae: 857.8998\n",
      "Epoch 141/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.6884 - mae: 880.6884 - val_loss: 855.0764 - val_mae: 855.0764\n",
      "Epoch 142/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.9136 - mae: 877.9136 - val_loss: 854.3242 - val_mae: 854.3242\n",
      "Epoch 143/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.0038 - mae: 879.0038 - val_loss: 856.3925 - val_mae: 856.3925\n",
      "Epoch 144/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.7907 - mae: 877.7907 - val_loss: 854.3652 - val_mae: 854.3652\n",
      "Epoch 145/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 875.8279 - mae: 875.8279 - val_loss: 853.3284 - val_mae: 853.3284\n",
      "Epoch 146/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.6970 - mae: 877.6970 - val_loss: 855.7906 - val_mae: 855.7906\n",
      "Epoch 147/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.2000 - mae: 879.2000 - val_loss: 856.1776 - val_mae: 856.1776\n",
      "Epoch 148/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.0775 - mae: 878.0775 - val_loss: 856.0228 - val_mae: 856.0228\n",
      "Epoch 149/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.8557 - mae: 880.8557 - val_loss: 858.9827 - val_mae: 858.9827\n",
      "Epoch 150/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 876.5806 - mae: 876.5806 - val_loss: 856.6301 - val_mae: 856.6301\n",
      "Epoch 151/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.3843 - mae: 880.3843 - val_loss: 854.9918 - val_mae: 854.9918\n",
      "Epoch 152/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.7074 - mae: 877.7074 - val_loss: 854.9501 - val_mae: 854.9501\n",
      "Epoch 153/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.8723 - mae: 878.8723 - val_loss: 856.4830 - val_mae: 856.4830\n",
      "Epoch 154/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.1918 - mae: 880.1918 - val_loss: 857.8323 - val_mae: 857.8323\n",
      "Epoch 155/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.2632 - mae: 878.2632 - val_loss: 857.8571 - val_mae: 857.8571\n",
      "Epoch 156/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.2986 - mae: 878.2986 - val_loss: 854.8617 - val_mae: 854.8617\n",
      "Epoch 157/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.2294 - mae: 877.2294 - val_loss: 855.4846 - val_mae: 855.4846\n",
      "Epoch 158/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.7754 - mae: 878.7754 - val_loss: 853.6587 - val_mae: 853.6587\n",
      "Epoch 159/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.0858 - mae: 878.0858 - val_loss: 855.4844 - val_mae: 855.4844\n",
      "Epoch 160/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 876.9373 - mae: 876.9373 - val_loss: 854.7533 - val_mae: 854.7533\n",
      "Epoch 161/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 876.6022 - mae: 876.6022 - val_loss: 856.1657 - val_mae: 856.1657\n",
      "Epoch 162/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.3297 - mae: 878.3297 - val_loss: 861.5153 - val_mae: 861.5153\n",
      "Epoch 163/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.6791 - mae: 878.6791 - val_loss: 855.2877 - val_mae: 855.2877\n",
      "Epoch 164/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.3246 - mae: 879.3246 - val_loss: 856.6143 - val_mae: 856.6143\n",
      "Epoch 165/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.4859 - mae: 878.4859 - val_loss: 853.6865 - val_mae: 853.6865\n",
      "Epoch 166/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 876.7539 - mae: 876.7539 - val_loss: 859.1568 - val_mae: 859.1568\n",
      "Epoch 167/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.4610 - mae: 878.4610 - val_loss: 857.1743 - val_mae: 857.1743\n",
      "Epoch 168/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.5161 - mae: 878.5161 - val_loss: 853.9873 - val_mae: 853.9873\n",
      "Epoch 169/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.9650 - mae: 877.9650 - val_loss: 858.0877 - val_mae: 858.0877\n",
      "Epoch 170/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.7834 - mae: 879.7834 - val_loss: 859.1521 - val_mae: 859.1521\n",
      "Epoch 171/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.2616 - mae: 877.2616 - val_loss: 855.3654 - val_mae: 855.3654\n",
      "Epoch 172/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.3598 - mae: 879.3598 - val_loss: 855.6194 - val_mae: 855.6194\n",
      "Epoch 173/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 876.7842 - mae: 876.7842 - val_loss: 855.6144 - val_mae: 855.6144\n",
      "Epoch 174/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.0597 - mae: 879.0597 - val_loss: 854.3262 - val_mae: 854.3262\n",
      "Epoch 175/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.8722 - mae: 877.8722 - val_loss: 855.3315 - val_mae: 855.3315\n",
      "Epoch 176/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 875.8525 - mae: 875.8525 - val_loss: 858.7751 - val_mae: 858.7751\n",
      "Epoch 177/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.9695 - mae: 877.9695 - val_loss: 855.1392 - val_mae: 855.1392\n",
      "Epoch 178/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.6681 - mae: 878.6681 - val_loss: 855.3033 - val_mae: 855.3033\n",
      "Epoch 179/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.1827 - mae: 879.1827 - val_loss: 855.1432 - val_mae: 855.1432\n",
      "Epoch 180/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.3329 - mae: 879.3329 - val_loss: 858.4739 - val_mae: 858.4739\n",
      "Epoch 181/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 876.8038 - mae: 876.8038 - val_loss: 853.5181 - val_mae: 853.5181\n",
      "Epoch 182/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.4456 - mae: 879.4456 - val_loss: 858.7609 - val_mae: 858.7609\n",
      "Epoch 183/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.6705 - mae: 878.6705 - val_loss: 854.6672 - val_mae: 854.6672\n",
      "Epoch 184/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 876.8032 - mae: 876.8032 - val_loss: 856.9517 - val_mae: 856.9517\n",
      "Epoch 185/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 876.5629 - mae: 876.5629 - val_loss: 856.3734 - val_mae: 856.3734\n",
      "Epoch 186/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 876.9506 - mae: 876.9506 - val_loss: 856.5888 - val_mae: 856.5888\n",
      "Epoch 187/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 875.7874 - mae: 875.7874 - val_loss: 856.0681 - val_mae: 856.0681\n",
      "Epoch 188/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.4863 - mae: 879.4863 - val_loss: 859.4863 - val_mae: 859.4863\n",
      "Epoch 189/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 876.3856 - mae: 876.3856 - val_loss: 856.1091 - val_mae: 856.1091\n",
      "Epoch 190/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.3338 - mae: 877.3338 - val_loss: 860.1933 - val_mae: 860.1933\n",
      "Epoch 191/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 876.6146 - mae: 876.6146 - val_loss: 858.1850 - val_mae: 858.1850\n",
      "Epoch 192/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.2852 - mae: 878.2852 - val_loss: 857.4064 - val_mae: 857.4064\n",
      "Epoch 193/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.8639 - mae: 878.8639 - val_loss: 853.6025 - val_mae: 853.6025\n",
      "Epoch 194/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.2180 - mae: 877.2180 - val_loss: 853.4499 - val_mae: 853.4499\n",
      "Epoch 195/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 876.2043 - mae: 876.2043 - val_loss: 856.0145 - val_mae: 856.0145\n",
      "Epoch 196/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 876.8970 - mae: 876.8970 - val_loss: 854.6550 - val_mae: 854.6550\n",
      "Epoch 197/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.8089 - mae: 877.8089 - val_loss: 853.8809 - val_mae: 853.8809\n",
      "Epoch 198/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 876.3307 - mae: 876.3307 - val_loss: 855.3519 - val_mae: 855.3519\n",
      "Epoch 199/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 876.7665 - mae: 876.7665 - val_loss: 855.2089 - val_mae: 855.2089\n",
      "Epoch 200/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 876.8366 - mae: 876.8366 - val_loss: 854.5284 - val_mae: 854.5284\n",
      "Fold 1 - Loss: 854.5283, MAE: 854.5283\n",
      "393/393 [==============================] - 0s 490us/step\n",
      "[Test results]\n",
      "MAPE: 0.3475\n",
      "MAE: 854.5283\n",
      "MSE: 1.2247e+06\n",
      "MSE: 1224678.4685\n",
      "RMSE: 1106.6519\n",
      "\n",
      "Fold 2 / 3\n",
      "Epoch 1/200\n",
      "197/197 [==============================] - 1s 2ms/step - loss: 2291.9016 - mae: 2291.9016 - val_loss: 1194.5352 - val_mae: 1194.5352\n",
      "Epoch 2/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 1060.9886 - mae: 1060.9886 - val_loss: 923.6014 - val_mae: 923.6014\n",
      "Epoch 3/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 903.5446 - mae: 903.5446 - val_loss: 872.5653 - val_mae: 872.5653\n",
      "Epoch 4/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 886.6999 - mae: 886.6999 - val_loss: 868.5213 - val_mae: 868.5213\n",
      "Epoch 5/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.4257 - mae: 883.4257 - val_loss: 865.7190 - val_mae: 865.7190\n",
      "Epoch 6/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.6968 - mae: 884.6968 - val_loss: 870.5862 - val_mae: 870.5862\n",
      "Epoch 7/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 886.0799 - mae: 886.0799 - val_loss: 865.6758 - val_mae: 865.6758\n",
      "Epoch 8/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.3090 - mae: 884.3090 - val_loss: 862.9328 - val_mae: 862.9328\n",
      "Epoch 9/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.3104 - mae: 883.3104 - val_loss: 864.1572 - val_mae: 864.1572\n",
      "Epoch 10/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.9963 - mae: 880.9963 - val_loss: 864.5867 - val_mae: 864.5867\n",
      "Epoch 11/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.0391 - mae: 882.0391 - val_loss: 865.5970 - val_mae: 865.5970\n",
      "Epoch 12/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.3989 - mae: 882.3989 - val_loss: 863.5859 - val_mae: 863.5859\n",
      "Epoch 13/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.2909 - mae: 884.2909 - val_loss: 866.0933 - val_mae: 866.0933\n",
      "Epoch 14/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.8140 - mae: 880.8140 - val_loss: 865.8322 - val_mae: 865.8322\n",
      "Epoch 15/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.5764 - mae: 884.5764 - val_loss: 868.3240 - val_mae: 868.3240\n",
      "Epoch 16/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.8698 - mae: 880.8698 - val_loss: 864.6141 - val_mae: 864.6141\n",
      "Epoch 17/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.0670 - mae: 878.0670 - val_loss: 866.9509 - val_mae: 866.9509\n",
      "Epoch 18/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.9576 - mae: 882.9576 - val_loss: 864.8879 - val_mae: 864.8879\n",
      "Epoch 19/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.7034 - mae: 881.7034 - val_loss: 862.0496 - val_mae: 862.0496\n",
      "Epoch 20/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.1490 - mae: 879.1490 - val_loss: 865.3979 - val_mae: 865.3979\n",
      "Epoch 21/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.0295 - mae: 880.0295 - val_loss: 864.5784 - val_mae: 864.5784\n",
      "Epoch 22/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.9687 - mae: 878.9687 - val_loss: 867.0497 - val_mae: 867.0497\n",
      "Epoch 23/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.6459 - mae: 880.6459 - val_loss: 864.9847 - val_mae: 864.9847\n",
      "Epoch 24/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.9609 - mae: 880.9609 - val_loss: 862.2368 - val_mae: 862.2368\n",
      "Epoch 25/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.2931 - mae: 881.2931 - val_loss: 864.6812 - val_mae: 864.6812\n",
      "Epoch 26/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.6086 - mae: 877.6086 - val_loss: 868.3386 - val_mae: 868.3386\n",
      "Epoch 27/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.0710 - mae: 882.0710 - val_loss: 862.9622 - val_mae: 862.9622\n",
      "Epoch 28/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.6164 - mae: 883.6164 - val_loss: 864.1922 - val_mae: 864.1922\n",
      "Epoch 29/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.0024 - mae: 878.0024 - val_loss: 864.4843 - val_mae: 864.4843\n",
      "Epoch 30/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.4185 - mae: 880.4185 - val_loss: 866.4899 - val_mae: 866.4899\n",
      "Epoch 31/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.6021 - mae: 881.6021 - val_loss: 867.8281 - val_mae: 867.8281\n",
      "Epoch 32/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.7779 - mae: 877.7779 - val_loss: 865.3409 - val_mae: 865.3409\n",
      "Epoch 33/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.4926 - mae: 879.4926 - val_loss: 867.3854 - val_mae: 867.3854\n",
      "Epoch 34/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.7176 - mae: 879.7176 - val_loss: 864.4307 - val_mae: 864.4307\n",
      "Epoch 35/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.8473 - mae: 877.8473 - val_loss: 866.2831 - val_mae: 866.2831\n",
      "Epoch 36/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.0480 - mae: 882.0480 - val_loss: 865.7154 - val_mae: 865.7154\n",
      "Epoch 37/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.6513 - mae: 878.6513 - val_loss: 864.3242 - val_mae: 864.3242\n",
      "Epoch 38/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.2056 - mae: 880.2056 - val_loss: 863.8422 - val_mae: 863.8422\n",
      "Epoch 39/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.4302 - mae: 878.4302 - val_loss: 864.8798 - val_mae: 864.8798\n",
      "Epoch 40/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.9348 - mae: 879.9348 - val_loss: 864.8979 - val_mae: 864.8979\n",
      "Epoch 41/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.7219 - mae: 881.7219 - val_loss: 864.4384 - val_mae: 864.4384\n",
      "Epoch 42/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.8862 - mae: 879.8862 - val_loss: 863.7974 - val_mae: 863.7974\n",
      "Epoch 43/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.8847 - mae: 877.8847 - val_loss: 866.3748 - val_mae: 866.3748\n",
      "Epoch 44/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.2930 - mae: 878.2930 - val_loss: 864.9586 - val_mae: 864.9586\n",
      "Epoch 45/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.9472 - mae: 878.9472 - val_loss: 865.6220 - val_mae: 865.6220\n",
      "Epoch 46/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.7419 - mae: 880.7419 - val_loss: 866.1378 - val_mae: 866.1378\n",
      "Epoch 47/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.1361 - mae: 879.1361 - val_loss: 862.6251 - val_mae: 862.6251\n",
      "Epoch 48/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.2525 - mae: 882.2525 - val_loss: 865.8467 - val_mae: 865.8467\n",
      "Epoch 49/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.1472 - mae: 879.1472 - val_loss: 865.5563 - val_mae: 865.5563\n",
      "Epoch 50/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.8451 - mae: 878.8451 - val_loss: 862.3417 - val_mae: 862.3417\n",
      "Epoch 51/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.7750 - mae: 877.7750 - val_loss: 865.7071 - val_mae: 865.7071\n",
      "Epoch 52/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.9150 - mae: 879.9150 - val_loss: 866.8852 - val_mae: 866.8852\n",
      "Epoch 53/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.7493 - mae: 878.7493 - val_loss: 868.5635 - val_mae: 868.5635\n",
      "Epoch 54/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.3857 - mae: 879.3857 - val_loss: 867.7648 - val_mae: 867.7648\n",
      "Epoch 55/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.1065 - mae: 879.1065 - val_loss: 867.0284 - val_mae: 867.0284\n",
      "Epoch 56/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.3224 - mae: 879.3224 - val_loss: 865.4974 - val_mae: 865.4974\n",
      "Epoch 57/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.3204 - mae: 880.3204 - val_loss: 862.0118 - val_mae: 862.0118\n",
      "Epoch 58/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.5911 - mae: 879.5911 - val_loss: 866.3744 - val_mae: 866.3744\n",
      "Epoch 59/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.9008 - mae: 879.9008 - val_loss: 863.3904 - val_mae: 863.3904\n",
      "Epoch 60/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.7416 - mae: 878.7416 - val_loss: 862.9160 - val_mae: 862.9160\n",
      "Epoch 61/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.7651 - mae: 879.7651 - val_loss: 862.0587 - val_mae: 862.0587\n",
      "Epoch 62/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.6411 - mae: 879.6411 - val_loss: 863.6595 - val_mae: 863.6595\n",
      "Epoch 63/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.1931 - mae: 877.1931 - val_loss: 867.7188 - val_mae: 867.7188\n",
      "Epoch 64/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.9118 - mae: 879.9118 - val_loss: 862.2708 - val_mae: 862.2708\n",
      "Epoch 65/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.4652 - mae: 877.4652 - val_loss: 865.7943 - val_mae: 865.7943\n",
      "Epoch 66/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.1953 - mae: 878.1953 - val_loss: 867.3633 - val_mae: 867.3633\n",
      "Epoch 67/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.7521 - mae: 880.7521 - val_loss: 862.8527 - val_mae: 862.8527\n",
      "Epoch 68/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.4425 - mae: 878.4425 - val_loss: 867.4835 - val_mae: 867.4835\n",
      "Epoch 69/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.0830 - mae: 879.0830 - val_loss: 862.5376 - val_mae: 862.5376\n",
      "Epoch 70/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.5275 - mae: 879.5275 - val_loss: 866.9431 - val_mae: 866.9431\n",
      "Epoch 71/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.5912 - mae: 877.5912 - val_loss: 865.6564 - val_mae: 865.6564\n",
      "Epoch 72/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.8377 - mae: 878.8377 - val_loss: 864.5195 - val_mae: 864.5195\n",
      "Epoch 73/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.4952 - mae: 878.4952 - val_loss: 868.1378 - val_mae: 868.1378\n",
      "Epoch 74/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.5847 - mae: 878.5847 - val_loss: 865.3306 - val_mae: 865.3306\n",
      "Epoch 75/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.5475 - mae: 878.5475 - val_loss: 870.6757 - val_mae: 870.6757\n",
      "Epoch 76/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 875.9092 - mae: 875.9092 - val_loss: 868.6189 - val_mae: 868.6189\n",
      "Epoch 77/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.3456 - mae: 880.3456 - val_loss: 865.5063 - val_mae: 865.5063\n",
      "Epoch 78/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.9473 - mae: 878.9473 - val_loss: 864.4800 - val_mae: 864.4800\n",
      "Epoch 79/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.6095 - mae: 879.6095 - val_loss: 865.6140 - val_mae: 865.6140\n",
      "Epoch 80/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.6105 - mae: 878.6105 - val_loss: 866.9511 - val_mae: 866.9511\n",
      "Epoch 81/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.0430 - mae: 878.0430 - val_loss: 864.0685 - val_mae: 864.0685\n",
      "Epoch 82/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 876.1909 - mae: 876.1909 - val_loss: 863.9621 - val_mae: 863.9621\n",
      "Epoch 83/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.4656 - mae: 877.4656 - val_loss: 862.9973 - val_mae: 862.9973\n",
      "Epoch 84/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.7831 - mae: 877.7831 - val_loss: 865.9677 - val_mae: 865.9677\n",
      "Epoch 85/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.7911 - mae: 879.7911 - val_loss: 862.1481 - val_mae: 862.1481\n",
      "Epoch 86/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.3304 - mae: 878.3304 - val_loss: 862.4537 - val_mae: 862.4537\n",
      "Epoch 87/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 876.4090 - mae: 876.4090 - val_loss: 863.7592 - val_mae: 863.7592\n",
      "Epoch 88/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.6126 - mae: 880.6126 - val_loss: 869.4191 - val_mae: 869.4191\n",
      "Epoch 89/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.3698 - mae: 877.3698 - val_loss: 865.8635 - val_mae: 865.8635\n",
      "Epoch 90/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 876.5720 - mae: 876.5720 - val_loss: 863.8005 - val_mae: 863.8005\n",
      "Epoch 91/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.0424 - mae: 878.0424 - val_loss: 863.0688 - val_mae: 863.0688\n",
      "Epoch 92/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.1577 - mae: 879.1577 - val_loss: 864.1182 - val_mae: 864.1182\n",
      "Epoch 93/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.6860 - mae: 878.6860 - val_loss: 866.6929 - val_mae: 866.6929\n",
      "Epoch 94/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.4854 - mae: 879.4854 - val_loss: 868.2695 - val_mae: 868.2695\n",
      "Epoch 95/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.2739 - mae: 878.2739 - val_loss: 866.5889 - val_mae: 866.5889\n",
      "Epoch 96/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.6329 - mae: 878.6329 - val_loss: 870.7941 - val_mae: 870.7941\n",
      "Epoch 97/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 875.4321 - mae: 875.4321 - val_loss: 868.0773 - val_mae: 868.0773\n",
      "Epoch 98/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.3087 - mae: 878.3087 - val_loss: 865.6571 - val_mae: 865.6571\n",
      "Epoch 99/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 876.2693 - mae: 876.2693 - val_loss: 867.4371 - val_mae: 867.4371\n",
      "Epoch 100/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 875.5504 - mae: 875.5504 - val_loss: 864.0367 - val_mae: 864.0367\n",
      "Epoch 101/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.2430 - mae: 878.2430 - val_loss: 862.3000 - val_mae: 862.3000\n",
      "Epoch 102/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.2697 - mae: 877.2697 - val_loss: 866.7748 - val_mae: 866.7748\n",
      "Epoch 103/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 875.5704 - mae: 875.5704 - val_loss: 864.5560 - val_mae: 864.5560\n",
      "Epoch 104/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 876.2762 - mae: 876.2762 - val_loss: 867.8147 - val_mae: 867.8147\n",
      "Epoch 105/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 876.9894 - mae: 876.9894 - val_loss: 862.9722 - val_mae: 862.9722\n",
      "Epoch 106/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.2827 - mae: 877.2827 - val_loss: 866.0323 - val_mae: 866.0323\n",
      "Epoch 107/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.1385 - mae: 877.1385 - val_loss: 864.3452 - val_mae: 864.3452\n",
      "Epoch 108/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.7816 - mae: 877.7816 - val_loss: 865.3707 - val_mae: 865.3707\n",
      "Epoch 109/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 876.1838 - mae: 876.1838 - val_loss: 865.4333 - val_mae: 865.4333\n",
      "Epoch 110/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.0479 - mae: 878.0479 - val_loss: 865.2294 - val_mae: 865.2294\n",
      "Epoch 111/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 876.7662 - mae: 876.7662 - val_loss: 863.1509 - val_mae: 863.1509\n",
      "Epoch 112/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.2526 - mae: 877.2526 - val_loss: 867.8536 - val_mae: 867.8536\n",
      "Epoch 113/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.0321 - mae: 877.0321 - val_loss: 866.5410 - val_mae: 866.5410\n",
      "Epoch 114/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.8247 - mae: 877.8247 - val_loss: 863.0769 - val_mae: 863.0769\n",
      "Epoch 115/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 875.7875 - mae: 875.7875 - val_loss: 863.8607 - val_mae: 863.8607\n",
      "Epoch 116/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.2385 - mae: 877.2385 - val_loss: 867.3306 - val_mae: 867.3306\n",
      "Epoch 117/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.6272 - mae: 878.6272 - val_loss: 863.2358 - val_mae: 863.2358\n",
      "Epoch 118/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 876.0241 - mae: 876.0241 - val_loss: 865.1210 - val_mae: 865.1210\n",
      "Epoch 119/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 876.3378 - mae: 876.3378 - val_loss: 865.4205 - val_mae: 865.4205\n",
      "Epoch 120/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.1648 - mae: 877.1648 - val_loss: 869.9682 - val_mae: 869.9682\n",
      "Epoch 121/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 875.4299 - mae: 875.4299 - val_loss: 862.2609 - val_mae: 862.2609\n",
      "Epoch 122/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.8577 - mae: 877.8577 - val_loss: 862.9894 - val_mae: 862.9894\n",
      "Epoch 123/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.2861 - mae: 878.2861 - val_loss: 865.7017 - val_mae: 865.7017\n",
      "Epoch 124/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 875.6685 - mae: 875.6685 - val_loss: 863.7026 - val_mae: 863.7026\n",
      "Epoch 125/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 875.3781 - mae: 875.3781 - val_loss: 861.8779 - val_mae: 861.8779\n",
      "Epoch 126/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 876.8292 - mae: 876.8292 - val_loss: 862.7785 - val_mae: 862.7785\n",
      "Epoch 127/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 873.4636 - mae: 873.4636 - val_loss: 861.6337 - val_mae: 861.6337\n",
      "Epoch 128/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 874.0291 - mae: 874.0291 - val_loss: 865.1010 - val_mae: 865.1010\n",
      "Epoch 129/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 875.2783 - mae: 875.2783 - val_loss: 867.6978 - val_mae: 867.6978\n",
      "Epoch 130/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.7808 - mae: 878.7808 - val_loss: 866.2163 - val_mae: 866.2163\n",
      "Epoch 131/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 876.8615 - mae: 876.8615 - val_loss: 862.5334 - val_mae: 862.5334\n",
      "Epoch 132/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 876.8035 - mae: 876.8035 - val_loss: 865.5852 - val_mae: 865.5852\n",
      "Epoch 133/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.6277 - mae: 878.6277 - val_loss: 865.7436 - val_mae: 865.7436\n",
      "Epoch 134/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 875.0394 - mae: 875.0394 - val_loss: 861.3670 - val_mae: 861.3670\n",
      "Epoch 135/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 875.9404 - mae: 875.9404 - val_loss: 863.7312 - val_mae: 863.7312\n",
      "Epoch 136/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 876.4851 - mae: 876.4851 - val_loss: 864.0895 - val_mae: 864.0895\n",
      "Epoch 137/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.0040 - mae: 877.0040 - val_loss: 864.6776 - val_mae: 864.6776\n",
      "Epoch 138/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 874.7957 - mae: 874.7957 - val_loss: 864.7144 - val_mae: 864.7144\n",
      "Epoch 139/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.0699 - mae: 877.0699 - val_loss: 862.9437 - val_mae: 862.9437\n",
      "Epoch 140/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.0204 - mae: 878.0204 - val_loss: 866.3918 - val_mae: 866.3918\n",
      "Epoch 141/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.0280 - mae: 877.0280 - val_loss: 861.7664 - val_mae: 861.7664\n",
      "Epoch 142/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 875.2314 - mae: 875.2314 - val_loss: 864.8948 - val_mae: 864.8948\n",
      "Epoch 143/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 875.7245 - mae: 875.7245 - val_loss: 864.2347 - val_mae: 864.2347\n",
      "Epoch 144/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 876.8795 - mae: 876.8795 - val_loss: 861.8655 - val_mae: 861.8655\n",
      "Epoch 145/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 876.5904 - mae: 876.5904 - val_loss: 862.1190 - val_mae: 862.1190\n",
      "Epoch 146/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.0308 - mae: 877.0308 - val_loss: 861.6611 - val_mae: 861.6611\n",
      "Epoch 147/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 875.4788 - mae: 875.4788 - val_loss: 866.3932 - val_mae: 866.3932\n",
      "Epoch 148/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 873.3959 - mae: 873.3959 - val_loss: 864.5090 - val_mae: 864.5090\n",
      "Epoch 149/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.2725 - mae: 877.2725 - val_loss: 863.2756 - val_mae: 863.2756\n",
      "Epoch 150/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 876.0217 - mae: 876.0217 - val_loss: 861.4025 - val_mae: 861.4025\n",
      "Epoch 151/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 874.8954 - mae: 874.8954 - val_loss: 864.7933 - val_mae: 864.7933\n",
      "Epoch 152/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 876.1381 - mae: 876.1381 - val_loss: 861.3282 - val_mae: 861.3282\n",
      "Epoch 153/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 873.5194 - mae: 873.5194 - val_loss: 862.6561 - val_mae: 862.6561\n",
      "Epoch 154/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.8517 - mae: 877.8517 - val_loss: 861.8927 - val_mae: 861.8927\n",
      "Epoch 155/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.3971 - mae: 878.3971 - val_loss: 864.7789 - val_mae: 864.7789\n",
      "Epoch 156/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 876.1042 - mae: 876.1042 - val_loss: 865.4944 - val_mae: 865.4944\n",
      "Epoch 157/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 875.5045 - mae: 875.5045 - val_loss: 862.9283 - val_mae: 862.9283\n",
      "Epoch 158/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 874.5929 - mae: 874.5929 - val_loss: 861.8997 - val_mae: 861.8997\n",
      "Epoch 159/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.6790 - mae: 877.6790 - val_loss: 865.3458 - val_mae: 865.3458\n",
      "Epoch 160/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 875.7330 - mae: 875.7330 - val_loss: 862.3339 - val_mae: 862.3339\n",
      "Epoch 161/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 875.5211 - mae: 875.5211 - val_loss: 861.8483 - val_mae: 861.8483\n",
      "Epoch 162/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 874.7676 - mae: 874.7676 - val_loss: 864.7278 - val_mae: 864.7278\n",
      "Epoch 163/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 874.8203 - mae: 874.8203 - val_loss: 863.4446 - val_mae: 863.4446\n",
      "Epoch 164/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 873.9882 - mae: 873.9882 - val_loss: 864.3699 - val_mae: 864.3699\n",
      "Epoch 165/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 876.6827 - mae: 876.6827 - val_loss: 863.1863 - val_mae: 863.1863\n",
      "Epoch 166/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 874.0654 - mae: 874.0654 - val_loss: 862.5450 - val_mae: 862.5450\n",
      "Epoch 167/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 873.7591 - mae: 873.7591 - val_loss: 861.1641 - val_mae: 861.1641\n",
      "Epoch 168/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 875.8263 - mae: 875.8263 - val_loss: 862.0240 - val_mae: 862.0240\n",
      "Epoch 169/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 875.0240 - mae: 875.0240 - val_loss: 862.0710 - val_mae: 862.0710\n",
      "Epoch 170/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 875.0133 - mae: 875.0133 - val_loss: 865.2292 - val_mae: 865.2292\n",
      "Epoch 171/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 874.1069 - mae: 874.1069 - val_loss: 865.5135 - val_mae: 865.5135\n",
      "Epoch 172/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 874.2582 - mae: 874.2582 - val_loss: 861.4856 - val_mae: 861.4856\n",
      "Epoch 173/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 875.3307 - mae: 875.3307 - val_loss: 864.0161 - val_mae: 864.0161\n",
      "Epoch 174/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 875.7742 - mae: 875.7742 - val_loss: 863.0992 - val_mae: 863.0992\n",
      "Epoch 175/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 873.8546 - mae: 873.8546 - val_loss: 862.9740 - val_mae: 862.9740\n",
      "Epoch 176/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 874.3207 - mae: 874.3207 - val_loss: 861.5259 - val_mae: 861.5259\n",
      "Epoch 177/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 876.3277 - mae: 876.3277 - val_loss: 863.4856 - val_mae: 863.4856\n",
      "Epoch 178/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.6290 - mae: 877.6290 - val_loss: 862.2469 - val_mae: 862.2469\n",
      "Epoch 179/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 873.6648 - mae: 873.6648 - val_loss: 863.1703 - val_mae: 863.1703\n",
      "Epoch 180/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 871.0586 - mae: 871.0586 - val_loss: 867.5922 - val_mae: 867.5922\n",
      "Epoch 181/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 874.6932 - mae: 874.6932 - val_loss: 862.3555 - val_mae: 862.3555\n",
      "Epoch 182/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 875.3291 - mae: 875.3291 - val_loss: 862.0854 - val_mae: 862.0854\n",
      "Epoch 183/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 873.6381 - mae: 873.6381 - val_loss: 864.6337 - val_mae: 864.6337\n",
      "Epoch 184/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 874.5840 - mae: 874.5840 - val_loss: 862.5443 - val_mae: 862.5443\n",
      "Epoch 185/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 875.0833 - mae: 875.0833 - val_loss: 863.7921 - val_mae: 863.7921\n",
      "Epoch 186/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 873.3414 - mae: 873.3414 - val_loss: 862.2496 - val_mae: 862.2496\n",
      "Epoch 187/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 872.8508 - mae: 872.8508 - val_loss: 862.7490 - val_mae: 862.7490\n",
      "Epoch 188/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 872.9406 - mae: 872.9406 - val_loss: 865.6094 - val_mae: 865.6094\n",
      "Epoch 189/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 875.9794 - mae: 875.9794 - val_loss: 865.2975 - val_mae: 865.2975\n",
      "Epoch 190/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 872.6347 - mae: 872.6347 - val_loss: 861.1459 - val_mae: 861.1459\n",
      "Epoch 191/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 874.7080 - mae: 874.7080 - val_loss: 862.8104 - val_mae: 862.8104\n",
      "Epoch 192/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 872.3873 - mae: 872.3873 - val_loss: 865.1179 - val_mae: 865.1179\n",
      "Epoch 193/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 875.5760 - mae: 875.5760 - val_loss: 865.0822 - val_mae: 865.0822\n",
      "Epoch 194/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 874.1298 - mae: 874.1298 - val_loss: 866.2676 - val_mae: 866.2676\n",
      "Epoch 195/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 873.5910 - mae: 873.5910 - val_loss: 865.0278 - val_mae: 865.0278\n",
      "Epoch 196/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 874.5009 - mae: 874.5009 - val_loss: 862.4689 - val_mae: 862.4689\n",
      "Epoch 197/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 871.8474 - mae: 871.8474 - val_loss: 863.2027 - val_mae: 863.2027\n",
      "Epoch 198/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 873.7524 - mae: 873.7524 - val_loss: 863.7910 - val_mae: 863.7910\n",
      "Epoch 199/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 875.6085 - mae: 875.6085 - val_loss: 865.4045 - val_mae: 865.4045\n",
      "Epoch 200/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 873.8275 - mae: 873.8275 - val_loss: 863.9346 - val_mae: 863.9346\n",
      "Fold 2 - Loss: 863.9344, MAE: 863.9344\n",
      "393/393 [==============================] - 0s 509us/step\n",
      "[Test results]\n",
      "MAPE: 0.348\n",
      "MAE: 863.9346\n",
      "MSE: 1.2278e+06\n",
      "MSE: 1227765.8424\n",
      "RMSE: 1108.046\n",
      "\n",
      "Fold 3 / 3\n",
      "Epoch 1/200\n",
      "197/197 [==============================] - 1s 2ms/step - loss: 2308.5486 - mae: 2308.5486 - val_loss: 1182.1044 - val_mae: 1182.1044\n",
      "Epoch 2/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 1058.5258 - mae: 1058.5258 - val_loss: 910.7042 - val_mae: 910.7042\n",
      "Epoch 3/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 904.1468 - mae: 904.1468 - val_loss: 861.2843 - val_mae: 861.2843\n",
      "Epoch 4/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 891.0081 - mae: 891.0081 - val_loss: 854.1110 - val_mae: 854.1110\n",
      "Epoch 5/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 886.7215 - mae: 886.7215 - val_loss: 853.9431 - val_mae: 853.9431\n",
      "Epoch 6/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 888.0370 - mae: 888.0370 - val_loss: 858.9323 - val_mae: 858.9323\n",
      "Epoch 7/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 886.9420 - mae: 886.9420 - val_loss: 860.3270 - val_mae: 860.3270\n",
      "Epoch 8/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 886.4539 - mae: 886.4539 - val_loss: 857.2658 - val_mae: 857.2658\n",
      "Epoch 9/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.3975 - mae: 885.3975 - val_loss: 855.6581 - val_mae: 855.6581\n",
      "Epoch 10/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 888.4601 - mae: 888.4601 - val_loss: 855.0710 - val_mae: 855.0710\n",
      "Epoch 11/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.9084 - mae: 885.9084 - val_loss: 853.3633 - val_mae: 853.3633\n",
      "Epoch 12/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 886.5122 - mae: 886.5122 - val_loss: 854.1138 - val_mae: 854.1138\n",
      "Epoch 13/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.2819 - mae: 885.2819 - val_loss: 852.5143 - val_mae: 852.5143\n",
      "Epoch 14/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.1509 - mae: 884.1509 - val_loss: 853.4288 - val_mae: 853.4288\n",
      "Epoch 15/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 886.2377 - mae: 886.2377 - val_loss: 858.0989 - val_mae: 858.0989\n",
      "Epoch 16/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 886.1802 - mae: 886.1802 - val_loss: 853.0355 - val_mae: 853.0355\n",
      "Epoch 17/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.7870 - mae: 883.7870 - val_loss: 857.4638 - val_mae: 857.4638\n",
      "Epoch 18/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.7637 - mae: 885.7637 - val_loss: 854.1495 - val_mae: 854.1495\n",
      "Epoch 19/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.1516 - mae: 885.1516 - val_loss: 853.1774 - val_mae: 853.1774\n",
      "Epoch 20/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 887.9866 - mae: 887.9866 - val_loss: 851.4315 - val_mae: 851.4315\n",
      "Epoch 21/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.9373 - mae: 883.9373 - val_loss: 853.0738 - val_mae: 853.0738\n",
      "Epoch 22/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.5510 - mae: 885.5510 - val_loss: 851.6426 - val_mae: 851.6426\n",
      "Epoch 23/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.4022 - mae: 885.4022 - val_loss: 853.4805 - val_mae: 853.4805\n",
      "Epoch 24/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.5279 - mae: 883.5279 - val_loss: 853.3749 - val_mae: 853.3749\n",
      "Epoch 25/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.4178 - mae: 885.4178 - val_loss: 854.4417 - val_mae: 854.4417\n",
      "Epoch 26/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 886.7656 - mae: 886.7656 - val_loss: 862.1128 - val_mae: 862.1128\n",
      "Epoch 27/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.4947 - mae: 884.4947 - val_loss: 857.7758 - val_mae: 857.7758\n",
      "Epoch 28/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 886.3508 - mae: 886.3508 - val_loss: 856.9489 - val_mae: 856.9489\n",
      "Epoch 29/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.5431 - mae: 885.5431 - val_loss: 852.8441 - val_mae: 852.8441\n",
      "Epoch 30/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.9830 - mae: 884.9830 - val_loss: 853.1572 - val_mae: 853.1572\n",
      "Epoch 31/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.4473 - mae: 884.4473 - val_loss: 851.0680 - val_mae: 851.0680\n",
      "Epoch 32/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 887.4142 - mae: 887.4142 - val_loss: 851.2918 - val_mae: 851.2918\n",
      "Epoch 33/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.3737 - mae: 884.3737 - val_loss: 855.6401 - val_mae: 855.6401\n",
      "Epoch 34/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.6307 - mae: 885.6307 - val_loss: 861.0171 - val_mae: 861.0171\n",
      "Epoch 35/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.7531 - mae: 885.7531 - val_loss: 854.1985 - val_mae: 854.1985\n",
      "Epoch 36/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.0869 - mae: 885.0869 - val_loss: 855.2449 - val_mae: 855.2449\n",
      "Epoch 37/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.0430 - mae: 885.0430 - val_loss: 857.2905 - val_mae: 857.2905\n",
      "Epoch 38/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.7803 - mae: 885.7803 - val_loss: 854.2493 - val_mae: 854.2493\n",
      "Epoch 39/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.1677 - mae: 883.1677 - val_loss: 853.1055 - val_mae: 853.1055\n",
      "Epoch 40/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.3231 - mae: 883.3231 - val_loss: 851.8090 - val_mae: 851.8090\n",
      "Epoch 41/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.2969 - mae: 885.2969 - val_loss: 851.3766 - val_mae: 851.3766\n",
      "Epoch 42/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.9214 - mae: 885.9214 - val_loss: 851.0569 - val_mae: 851.0569\n",
      "Epoch 43/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.3713 - mae: 885.3713 - val_loss: 852.7909 - val_mae: 852.7909\n",
      "Epoch 44/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.3690 - mae: 885.3690 - val_loss: 853.6174 - val_mae: 853.6174\n",
      "Epoch 45/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.7360 - mae: 883.7360 - val_loss: 853.4305 - val_mae: 853.4305\n",
      "Epoch 46/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.4054 - mae: 884.4054 - val_loss: 851.8157 - val_mae: 851.8157\n",
      "Epoch 47/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.5340 - mae: 884.5340 - val_loss: 851.2239 - val_mae: 851.2239\n",
      "Epoch 48/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.7913 - mae: 884.7913 - val_loss: 853.2568 - val_mae: 853.2568\n",
      "Epoch 49/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.4476 - mae: 884.4476 - val_loss: 855.3505 - val_mae: 855.3505\n",
      "Epoch 50/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.4238 - mae: 885.4238 - val_loss: 851.2427 - val_mae: 851.2427\n",
      "Epoch 51/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.9260 - mae: 885.9260 - val_loss: 852.7216 - val_mae: 852.7216\n",
      "Epoch 52/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.4196 - mae: 883.4196 - val_loss: 851.1478 - val_mae: 851.1478\n",
      "Epoch 53/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.8511 - mae: 883.8511 - val_loss: 852.3741 - val_mae: 852.3741\n",
      "Epoch 54/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.8753 - mae: 885.8753 - val_loss: 855.4984 - val_mae: 855.4984\n",
      "Epoch 55/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 886.1961 - mae: 886.1961 - val_loss: 853.1548 - val_mae: 853.1548\n",
      "Epoch 56/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 886.4925 - mae: 886.4925 - val_loss: 851.6898 - val_mae: 851.6898\n",
      "Epoch 57/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.2520 - mae: 884.2520 - val_loss: 853.8725 - val_mae: 853.8725\n",
      "Epoch 58/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.8477 - mae: 884.8477 - val_loss: 856.1127 - val_mae: 856.1127\n",
      "Epoch 59/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.2095 - mae: 884.2095 - val_loss: 858.6663 - val_mae: 858.6663\n",
      "Epoch 60/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.3771 - mae: 884.3771 - val_loss: 852.0692 - val_mae: 852.0692\n",
      "Epoch 61/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.3978 - mae: 883.3978 - val_loss: 851.3762 - val_mae: 851.3762\n",
      "Epoch 62/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.0031 - mae: 882.0031 - val_loss: 853.9916 - val_mae: 853.9916\n",
      "Epoch 63/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.8978 - mae: 879.8978 - val_loss: 850.3115 - val_mae: 850.3115\n",
      "Epoch 64/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.6913 - mae: 881.6913 - val_loss: 851.3132 - val_mae: 851.3132\n",
      "Epoch 65/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.9335 - mae: 882.9335 - val_loss: 853.2361 - val_mae: 853.2361\n",
      "Epoch 66/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.7861 - mae: 885.7861 - val_loss: 851.6519 - val_mae: 851.6519\n",
      "Epoch 67/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.4467 - mae: 885.4467 - val_loss: 860.7452 - val_mae: 860.7452\n",
      "Epoch 68/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.9999 - mae: 880.9999 - val_loss: 852.4677 - val_mae: 852.4677\n",
      "Epoch 69/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.3399 - mae: 885.3399 - val_loss: 856.4185 - val_mae: 856.4185\n",
      "Epoch 70/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.4171 - mae: 882.4171 - val_loss: 852.6780 - val_mae: 852.6780\n",
      "Epoch 71/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.5797 - mae: 882.5797 - val_loss: 850.8718 - val_mae: 850.8718\n",
      "Epoch 72/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.2635 - mae: 884.2635 - val_loss: 850.6810 - val_mae: 850.6810\n",
      "Epoch 73/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.7112 - mae: 880.7112 - val_loss: 851.1125 - val_mae: 851.1125\n",
      "Epoch 74/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.3898 - mae: 883.3898 - val_loss: 851.9428 - val_mae: 851.9428\n",
      "Epoch 75/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.2463 - mae: 881.2463 - val_loss: 853.3815 - val_mae: 853.3815\n",
      "Epoch 76/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.1438 - mae: 883.1438 - val_loss: 851.7473 - val_mae: 851.7473\n",
      "Epoch 77/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.9080 - mae: 883.9080 - val_loss: 854.2137 - val_mae: 854.2137\n",
      "Epoch 78/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.8703 - mae: 882.8703 - val_loss: 856.3798 - val_mae: 856.3798\n",
      "Epoch 79/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.8965 - mae: 882.8965 - val_loss: 850.1239 - val_mae: 850.1239\n",
      "Epoch 80/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.1090 - mae: 882.1090 - val_loss: 856.5052 - val_mae: 856.5052\n",
      "Epoch 81/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.3630 - mae: 884.3630 - val_loss: 850.0007 - val_mae: 850.0007\n",
      "Epoch 82/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.1652 - mae: 885.1652 - val_loss: 852.2027 - val_mae: 852.2027\n",
      "Epoch 83/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.8013 - mae: 883.8013 - val_loss: 849.1002 - val_mae: 849.1002\n",
      "Epoch 84/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.9953 - mae: 884.9953 - val_loss: 854.1038 - val_mae: 854.1038\n",
      "Epoch 85/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.9270 - mae: 885.9270 - val_loss: 851.9473 - val_mae: 851.9473\n",
      "Epoch 86/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.8692 - mae: 881.8692 - val_loss: 851.0436 - val_mae: 851.0436\n",
      "Epoch 87/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.9325 - mae: 879.9325 - val_loss: 849.7020 - val_mae: 849.7020\n",
      "Epoch 88/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.2541 - mae: 884.2541 - val_loss: 851.9709 - val_mae: 851.9709\n",
      "Epoch 89/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.9177 - mae: 883.9177 - val_loss: 853.0817 - val_mae: 853.0817\n",
      "Epoch 90/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.4426 - mae: 881.4426 - val_loss: 848.7575 - val_mae: 848.7575\n",
      "Epoch 91/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.9733 - mae: 878.9733 - val_loss: 850.1193 - val_mae: 850.1193\n",
      "Epoch 92/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.7575 - mae: 881.7575 - val_loss: 849.9031 - val_mae: 849.9031\n",
      "Epoch 93/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.6984 - mae: 881.6984 - val_loss: 851.0777 - val_mae: 851.0777\n",
      "Epoch 94/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.5385 - mae: 882.5385 - val_loss: 849.9906 - val_mae: 849.9906\n",
      "Epoch 95/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.2886 - mae: 883.2886 - val_loss: 854.0087 - val_mae: 854.0087\n",
      "Epoch 96/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.2505 - mae: 879.2505 - val_loss: 847.8934 - val_mae: 847.8934\n",
      "Epoch 97/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.2483 - mae: 881.2483 - val_loss: 850.0975 - val_mae: 850.0975\n",
      "Epoch 98/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.8010 - mae: 882.8010 - val_loss: 849.4312 - val_mae: 849.4312\n",
      "Epoch 99/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.9863 - mae: 881.9863 - val_loss: 849.1560 - val_mae: 849.1560\n",
      "Epoch 100/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.5665 - mae: 883.5665 - val_loss: 848.6910 - val_mae: 848.6910\n",
      "Epoch 101/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.8562 - mae: 878.8562 - val_loss: 847.7296 - val_mae: 847.7296\n",
      "Epoch 102/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.4200 - mae: 881.4200 - val_loss: 851.7259 - val_mae: 851.7259\n",
      "Epoch 103/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.6923 - mae: 877.6923 - val_loss: 847.9037 - val_mae: 847.9037\n",
      "Epoch 104/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.4103 - mae: 880.4103 - val_loss: 856.6581 - val_mae: 856.6581\n",
      "Epoch 105/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.1116 - mae: 881.1116 - val_loss: 848.0822 - val_mae: 848.0822\n",
      "Epoch 106/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.7606 - mae: 880.7606 - val_loss: 848.6655 - val_mae: 848.6655\n",
      "Epoch 107/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.2113 - mae: 882.2113 - val_loss: 846.9271 - val_mae: 846.9271\n",
      "Epoch 108/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.2693 - mae: 884.2693 - val_loss: 848.4997 - val_mae: 848.4997\n",
      "Epoch 109/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.8762 - mae: 881.8762 - val_loss: 850.8262 - val_mae: 850.8262\n",
      "Epoch 110/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.0727 - mae: 881.0727 - val_loss: 847.1121 - val_mae: 847.1121\n",
      "Epoch 111/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.0079 - mae: 879.0079 - val_loss: 847.6404 - val_mae: 847.6404\n",
      "Epoch 112/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.5002 - mae: 881.5002 - val_loss: 851.3147 - val_mae: 851.3147\n",
      "Epoch 113/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.8733 - mae: 879.8733 - val_loss: 847.6855 - val_mae: 847.6855\n",
      "Epoch 114/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.8713 - mae: 878.8713 - val_loss: 848.2371 - val_mae: 848.2371\n",
      "Epoch 115/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.4996 - mae: 880.4996 - val_loss: 847.7213 - val_mae: 847.7213\n",
      "Epoch 116/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.7265 - mae: 880.7265 - val_loss: 847.2291 - val_mae: 847.2291\n",
      "Epoch 117/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.7380 - mae: 879.7380 - val_loss: 848.9167 - val_mae: 848.9167\n",
      "Epoch 118/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.5825 - mae: 880.5825 - val_loss: 849.3956 - val_mae: 849.3956\n",
      "Epoch 119/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.8557 - mae: 880.8557 - val_loss: 849.3414 - val_mae: 849.3414\n",
      "Epoch 120/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.1499 - mae: 881.1499 - val_loss: 846.9007 - val_mae: 846.9007\n",
      "Epoch 121/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.2532 - mae: 882.2532 - val_loss: 846.7055 - val_mae: 846.7055\n",
      "Epoch 122/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.5751 - mae: 878.5751 - val_loss: 847.8922 - val_mae: 847.8922\n",
      "Epoch 123/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.4584 - mae: 879.4584 - val_loss: 848.6184 - val_mae: 848.6184\n",
      "Epoch 124/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.9108 - mae: 879.9108 - val_loss: 846.2654 - val_mae: 846.2654\n",
      "Epoch 125/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.2927 - mae: 880.2927 - val_loss: 848.3299 - val_mae: 848.3299\n",
      "Epoch 126/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.6220 - mae: 878.6220 - val_loss: 848.5327 - val_mae: 848.5327\n",
      "Epoch 127/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.5776 - mae: 878.5776 - val_loss: 849.0669 - val_mae: 849.0669\n",
      "Epoch 128/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.3992 - mae: 877.3992 - val_loss: 847.8752 - val_mae: 847.8752\n",
      "Epoch 129/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.8419 - mae: 878.8419 - val_loss: 846.0308 - val_mae: 846.0308\n",
      "Epoch 130/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.0392 - mae: 877.0392 - val_loss: 848.1927 - val_mae: 848.1927\n",
      "Epoch 131/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.7036 - mae: 879.7036 - val_loss: 847.5514 - val_mae: 847.5514\n",
      "Epoch 132/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.1360 - mae: 881.1360 - val_loss: 848.8146 - val_mae: 848.8146\n",
      "Epoch 133/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.8829 - mae: 879.8829 - val_loss: 846.5061 - val_mae: 846.5061\n",
      "Epoch 134/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.6559 - mae: 880.6559 - val_loss: 847.8082 - val_mae: 847.8082\n",
      "Epoch 135/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.5850 - mae: 881.5850 - val_loss: 850.5315 - val_mae: 850.5315\n",
      "Epoch 136/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.0178 - mae: 879.0178 - val_loss: 847.4488 - val_mae: 847.4488\n",
      "Epoch 137/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.3173 - mae: 879.3173 - val_loss: 846.2286 - val_mae: 846.2286\n",
      "Epoch 138/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.3625 - mae: 879.3625 - val_loss: 847.6942 - val_mae: 847.6942\n",
      "Epoch 139/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.5290 - mae: 878.5290 - val_loss: 846.2905 - val_mae: 846.2905\n",
      "Epoch 140/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.4229 - mae: 877.4229 - val_loss: 850.3682 - val_mae: 850.3682\n",
      "Epoch 141/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.4570 - mae: 880.4570 - val_loss: 848.1394 - val_mae: 848.1394\n",
      "Epoch 142/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.5476 - mae: 878.5476 - val_loss: 849.0745 - val_mae: 849.0745\n",
      "Epoch 143/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.2130 - mae: 877.2130 - val_loss: 846.3632 - val_mae: 846.3632\n",
      "Epoch 144/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 876.9683 - mae: 876.9683 - val_loss: 850.0024 - val_mae: 850.0024\n",
      "Epoch 145/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.5485 - mae: 880.5485 - val_loss: 846.6185 - val_mae: 846.6185\n",
      "Epoch 146/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.6218 - mae: 878.6218 - val_loss: 848.6635 - val_mae: 848.6635\n",
      "Epoch 147/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.4119 - mae: 879.4119 - val_loss: 848.8738 - val_mae: 848.8738\n",
      "Epoch 148/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.4971 - mae: 879.4971 - val_loss: 846.1318 - val_mae: 846.1318\n",
      "Epoch 149/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.4305 - mae: 877.4305 - val_loss: 847.8090 - val_mae: 847.8090\n",
      "Epoch 150/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.1547 - mae: 879.1547 - val_loss: 846.6232 - val_mae: 846.6232\n",
      "Epoch 151/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.9872 - mae: 877.9872 - val_loss: 845.8853 - val_mae: 845.8853\n",
      "Epoch 152/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.5245 - mae: 881.5245 - val_loss: 846.4858 - val_mae: 846.4858\n",
      "Epoch 153/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 876.7874 - mae: 876.7874 - val_loss: 846.0646 - val_mae: 846.0646\n",
      "Epoch 154/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.8262 - mae: 879.8262 - val_loss: 846.8268 - val_mae: 846.8268\n",
      "Epoch 155/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.4130 - mae: 879.4130 - val_loss: 849.9838 - val_mae: 849.9838\n",
      "Epoch 156/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.1136 - mae: 877.1136 - val_loss: 847.5765 - val_mae: 847.5765\n",
      "Epoch 157/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 875.5766 - mae: 875.5766 - val_loss: 845.6246 - val_mae: 845.6246\n",
      "Epoch 158/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.7954 - mae: 878.7954 - val_loss: 846.6465 - val_mae: 846.6465\n",
      "Epoch 159/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.8120 - mae: 877.8120 - val_loss: 847.4316 - val_mae: 847.4316\n",
      "Epoch 160/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.3562 - mae: 877.3562 - val_loss: 848.0900 - val_mae: 848.0900\n",
      "Epoch 161/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.0525 - mae: 882.0525 - val_loss: 847.9526 - val_mae: 847.9526\n",
      "Epoch 162/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.8868 - mae: 878.8868 - val_loss: 847.7367 - val_mae: 847.7367\n",
      "Epoch 163/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.2372 - mae: 877.2372 - val_loss: 851.2058 - val_mae: 851.2058\n",
      "Epoch 164/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.7120 - mae: 877.7120 - val_loss: 846.4299 - val_mae: 846.4299\n",
      "Epoch 165/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.8394 - mae: 879.8394 - val_loss: 846.9655 - val_mae: 846.9655\n",
      "Epoch 166/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.5768 - mae: 878.5768 - val_loss: 847.9017 - val_mae: 847.9017\n",
      "Epoch 167/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.3781 - mae: 879.3781 - val_loss: 850.7875 - val_mae: 850.7875\n",
      "Epoch 168/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.5531 - mae: 878.5531 - val_loss: 850.1223 - val_mae: 850.1223\n",
      "Epoch 169/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.2437 - mae: 879.2437 - val_loss: 846.2134 - val_mae: 846.2134\n",
      "Epoch 170/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 876.5834 - mae: 876.5834 - val_loss: 846.1210 - val_mae: 846.1210\n",
      "Epoch 171/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 875.8202 - mae: 875.8202 - val_loss: 847.8384 - val_mae: 847.8384\n",
      "Epoch 172/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 875.7503 - mae: 875.7503 - val_loss: 848.4853 - val_mae: 848.4853\n",
      "Epoch 173/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.0507 - mae: 878.0507 - val_loss: 849.5948 - val_mae: 849.5948\n",
      "Epoch 174/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 876.5894 - mae: 876.5894 - val_loss: 846.9215 - val_mae: 846.9215\n",
      "Epoch 175/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 876.1951 - mae: 876.1951 - val_loss: 848.8267 - val_mae: 848.8267\n",
      "Epoch 176/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.0117 - mae: 877.0117 - val_loss: 851.2692 - val_mae: 851.2692\n",
      "Epoch 177/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.6210 - mae: 877.6210 - val_loss: 845.9246 - val_mae: 845.9246\n",
      "Epoch 178/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.5558 - mae: 877.5558 - val_loss: 846.0848 - val_mae: 846.0848\n",
      "Epoch 179/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 875.7669 - mae: 875.7669 - val_loss: 848.6938 - val_mae: 848.6938\n",
      "Epoch 180/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.8917 - mae: 877.8917 - val_loss: 846.0957 - val_mae: 846.0957\n",
      "Epoch 181/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.0202 - mae: 879.0202 - val_loss: 849.2047 - val_mae: 849.2047\n",
      "Epoch 182/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.0441 - mae: 878.0441 - val_loss: 849.8123 - val_mae: 849.8123\n",
      "Epoch 183/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 875.5594 - mae: 875.5594 - val_loss: 846.6133 - val_mae: 846.6133\n",
      "Epoch 184/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 875.5170 - mae: 875.5170 - val_loss: 847.9655 - val_mae: 847.9655\n",
      "Epoch 185/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 876.5284 - mae: 876.5284 - val_loss: 848.2341 - val_mae: 848.2341\n",
      "Epoch 186/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.7700 - mae: 880.7700 - val_loss: 845.7441 - val_mae: 845.7441\n",
      "Epoch 187/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 876.8184 - mae: 876.8184 - val_loss: 847.9155 - val_mae: 847.9155\n",
      "Epoch 188/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 875.6075 - mae: 875.6075 - val_loss: 846.9899 - val_mae: 846.9899\n",
      "Epoch 189/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.0916 - mae: 878.0916 - val_loss: 845.9948 - val_mae: 845.9948\n",
      "Epoch 190/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 875.6545 - mae: 875.6545 - val_loss: 846.6606 - val_mae: 846.6606\n",
      "Epoch 191/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 875.8284 - mae: 875.8284 - val_loss: 847.3160 - val_mae: 847.3160\n",
      "Epoch 192/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 876.0173 - mae: 876.0173 - val_loss: 846.2346 - val_mae: 846.2346\n",
      "Epoch 193/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 876.8018 - mae: 876.8018 - val_loss: 848.2770 - val_mae: 848.2770\n",
      "Epoch 194/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 876.5779 - mae: 876.5779 - val_loss: 849.9670 - val_mae: 849.9670\n",
      "Epoch 195/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 876.8682 - mae: 876.8682 - val_loss: 847.0939 - val_mae: 847.0939\n",
      "Epoch 196/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.2610 - mae: 877.2610 - val_loss: 847.8510 - val_mae: 847.8510\n",
      "Epoch 197/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.4484 - mae: 877.4484 - val_loss: 847.6137 - val_mae: 847.6137\n",
      "Epoch 198/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 876.3320 - mae: 876.3320 - val_loss: 845.3701 - val_mae: 845.3701\n",
      "Epoch 199/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 874.1055 - mae: 874.1055 - val_loss: 845.3863 - val_mae: 845.3863\n",
      "Epoch 200/200\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 875.7451 - mae: 875.7451 - val_loss: 847.3163 - val_mae: 847.3163\n",
      "Fold 3 - Loss: 847.3160, MAE: 847.3160\n",
      "393/393 [==============================] - 0s 460us/step\n",
      "[Test results]\n",
      "MAPE: 0.3421\n",
      "MAE: 847.3161\n",
      "MSE: 1.2051e+06\n",
      "MSE: 1205136.0462\n",
      "RMSE: 1097.7869\n",
      "\n",
      "\n",
      "Cross Validation 3-Fold 결과:\n",
      "MAE 평균: 855.2596, 표준편차: 6.8041\n",
      "\n",
      "295/295 [==============================] - 0s 413us/step\n",
      "[Test results]\n",
      "MAPE: 0.3404\n",
      "MAE: 852.3971\n",
      "MSE: 1.2084e+06\n",
      "MSE: 1208380.4727\n",
      "RMSE: 1099.2636\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "# 3-Fold Cross Validation\n",
    "kfold = KFold(n_splits=3, shuffle=True, random_state=7)\n",
    "mae_per_fold = []\n",
    "\n",
    "fold_no = 1\n",
    "for train_index, val_index in kfold.split(X_train1):\n",
    "    print(f\"Fold {fold_no} / 3\")\n",
    "    \n",
    "    # 데이터 분할\n",
    "    X_fold_train, X_fold_val = X_train1[train_index], X_train1[val_index]\n",
    "    y_fold_train, y_fold_val = y_train1.iloc[train_index], y_train1.iloc[val_index]\n",
    "    \n",
    "    # 모델 정의\n",
    "    model1 = Sequential([\n",
    "        Dense(128, activation='relu', input_shape=(X_fold_train.shape[1],)),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    \n",
    "    # 모델 컴파일\n",
    "    model1.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='mae',\n",
    "                  metrics=['mae'])\n",
    "    \n",
    "    # 학습\n",
    "    with tf.device(\"/device:GPU:0\"):\n",
    "        model1.fit(X_fold_train, y_fold_train,\n",
    "                  epochs=200, \n",
    "                  batch_size=128, \n",
    "                  validation_data=(X_fold_val, y_fold_val), \n",
    "                  verbose=1)\n",
    "        \n",
    "        # 폴드별 평가\n",
    "        loss, mae = model1.evaluate(X_fold_val, y_fold_val, verbose=0)\n",
    "        print(f\"Fold {fold_no} - Loss: {loss:.4f}, MAE: {mae:.4f}\")\n",
    "        mae_per_fold.append(mae)\n",
    "    \n",
    "    fold_pred = model1.predict(X_fold_val)\n",
    "    print_test_results2(y_fold_val, fold_pred)\n",
    "    \n",
    "    fold_no += 1\n",
    "\n",
    "# 평균 MAE와 표준편차 계산\n",
    "print(f\"\\nCross Validation 3-Fold 결과:\")\n",
    "print(f\"MAE 평균: {np.mean(mae_per_fold):.4f}, 표준편차: {np.std(mae_per_fold):.4f}\\n\")\n",
    "\n",
    "# 최종 평가 (test set 사용)\n",
    "ensemble_pred_1 = model1.predict(X_test1)\n",
    "print_test_results2(y_test1, ensemble_pred_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-3. RF + DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47156, 3) <class 'pandas.core.frame.DataFrame'>\n",
      "(47156,) <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "df_concat_2 = pd.concat([df_rf_predict, df_dnn_predict, df_y_test], axis=1)\n",
    "df_concat_2.columns = ['RF', 'DNN', 'True']\n",
    "\n",
    "X2 = df_concat_2[['RF', 'DNN']]\n",
    "y2 = df_concat_2['True']\n",
    "\n",
    "print(X1.shape, type(X2))\n",
    "print(y1.shape, type(y2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.2, random_state=7)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train2 = scaler.fit_transform(X_train2)\n",
    "X_test2 = scaler.transform(X_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Fold Experiments(k=3, 5, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Cross Validation: 3-Fold 시작 ---\n",
      "\n",
      "Fold 1 / 3\n",
      "Epoch 1/100\n",
      "197/197 [==============================] - 1s 2ms/step - loss: 2284.8145 - mae: 2284.8145 - val_loss: 1109.2766 - val_mae: 1109.2766\n",
      "Epoch 2/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 993.6223 - mae: 993.6223 - val_loss: 895.7069 - val_mae: 895.7069\n",
      "Epoch 3/100\n",
      "197/197 [==============================] - 0s 1ms/step - loss: 899.2522 - mae: 899.2522 - val_loss: 867.3839 - val_mae: 867.3839\n",
      "Epoch 4/100\n",
      "197/197 [==============================] - 0s 1ms/step - loss: 885.8541 - mae: 885.8541 - val_loss: 858.9851 - val_mae: 858.9851\n",
      "Epoch 5/100\n",
      "197/197 [==============================] - 0s 1ms/step - loss: 891.9809 - mae: 891.9809 - val_loss: 857.6217 - val_mae: 857.6217\n",
      "Epoch 6/100\n",
      "197/197 [==============================] - 0s 1ms/step - loss: 887.2106 - mae: 887.2106 - val_loss: 856.1957 - val_mae: 856.1957\n",
      "Epoch 7/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.3329 - mae: 884.3329 - val_loss: 856.1638 - val_mae: 856.1638\n",
      "Epoch 8/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.1620 - mae: 884.1620 - val_loss: 856.4799 - val_mae: 856.4799\n",
      "Epoch 9/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.0137 - mae: 884.0137 - val_loss: 863.2528 - val_mae: 863.2528\n",
      "Epoch 10/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 886.7673 - mae: 886.7673 - val_loss: 857.3215 - val_mae: 857.3215\n",
      "Epoch 11/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.1669 - mae: 884.1669 - val_loss: 859.3006 - val_mae: 859.3006\n",
      "Epoch 12/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 886.7474 - mae: 886.7474 - val_loss: 860.7832 - val_mae: 860.7832\n",
      "Epoch 13/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 886.0966 - mae: 886.0966 - val_loss: 861.7249 - val_mae: 861.7249\n",
      "Epoch 14/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 888.0384 - mae: 888.0384 - val_loss: 859.0002 - val_mae: 859.0002\n",
      "Epoch 15/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.9642 - mae: 883.9642 - val_loss: 859.9435 - val_mae: 859.9435\n",
      "Epoch 16/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.8567 - mae: 883.8567 - val_loss: 858.5455 - val_mae: 858.5455\n",
      "Epoch 17/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.4458 - mae: 883.4458 - val_loss: 857.4902 - val_mae: 857.4902\n",
      "Epoch 18/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 888.6907 - mae: 888.6907 - val_loss: 858.5017 - val_mae: 858.5017\n",
      "Epoch 19/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 887.0067 - mae: 887.0067 - val_loss: 858.9357 - val_mae: 858.9357\n",
      "Epoch 20/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.8890 - mae: 883.8890 - val_loss: 855.4905 - val_mae: 855.4905\n",
      "Epoch 21/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.0628 - mae: 883.0628 - val_loss: 863.9393 - val_mae: 863.9393\n",
      "Epoch 22/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.7017 - mae: 884.7017 - val_loss: 864.0178 - val_mae: 864.0178\n",
      "Epoch 23/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.6214 - mae: 883.6214 - val_loss: 854.6799 - val_mae: 854.6799\n",
      "Epoch 24/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.6175 - mae: 883.6175 - val_loss: 857.2043 - val_mae: 857.2043\n",
      "Epoch 25/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.3237 - mae: 880.3237 - val_loss: 855.6487 - val_mae: 855.6487\n",
      "Epoch 26/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.7672 - mae: 885.7672 - val_loss: 854.2662 - val_mae: 854.2662\n",
      "Epoch 27/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.9640 - mae: 884.9640 - val_loss: 857.3001 - val_mae: 857.3001\n",
      "Epoch 28/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.3907 - mae: 883.3907 - val_loss: 854.9691 - val_mae: 854.9691\n",
      "Epoch 29/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.6202 - mae: 882.6202 - val_loss: 858.8109 - val_mae: 858.8109\n",
      "Epoch 30/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.4768 - mae: 885.4768 - val_loss: 859.0145 - val_mae: 859.0145\n",
      "Epoch 31/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.4637 - mae: 883.4637 - val_loss: 853.9685 - val_mae: 853.9685\n",
      "Epoch 32/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.2761 - mae: 882.2761 - val_loss: 862.4823 - val_mae: 862.4823\n",
      "Epoch 33/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.9504 - mae: 884.9504 - val_loss: 858.9700 - val_mae: 858.9700\n",
      "Epoch 34/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 886.5864 - mae: 886.5864 - val_loss: 855.8328 - val_mae: 855.8328\n",
      "Epoch 35/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.9930 - mae: 881.9930 - val_loss: 859.9026 - val_mae: 859.9026\n",
      "Epoch 36/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.4875 - mae: 882.4875 - val_loss: 858.1232 - val_mae: 858.1232\n",
      "Epoch 37/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.8885 - mae: 882.8885 - val_loss: 853.9661 - val_mae: 853.9661\n",
      "Epoch 38/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.8515 - mae: 883.8515 - val_loss: 855.8419 - val_mae: 855.8419\n",
      "Epoch 39/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.8591 - mae: 880.8591 - val_loss: 854.1885 - val_mae: 854.1885\n",
      "Epoch 40/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.7721 - mae: 881.7721 - val_loss: 863.7963 - val_mae: 863.7963\n",
      "Epoch 41/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.0405 - mae: 883.0405 - val_loss: 855.8517 - val_mae: 855.8517\n",
      "Epoch 42/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.7343 - mae: 881.7343 - val_loss: 855.6315 - val_mae: 855.6315\n",
      "Epoch 43/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.9841 - mae: 880.9841 - val_loss: 855.5157 - val_mae: 855.5157\n",
      "Epoch 44/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.6321 - mae: 880.6321 - val_loss: 856.8069 - val_mae: 856.8069\n",
      "Epoch 45/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.4766 - mae: 883.4766 - val_loss: 859.5665 - val_mae: 859.5665\n",
      "Epoch 46/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.9213 - mae: 882.9213 - val_loss: 853.1895 - val_mae: 853.1895\n",
      "Epoch 47/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.6402 - mae: 879.6402 - val_loss: 859.1372 - val_mae: 859.1372\n",
      "Epoch 48/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.7845 - mae: 881.7845 - val_loss: 855.5057 - val_mae: 855.5057\n",
      "Epoch 49/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.5670 - mae: 882.5670 - val_loss: 858.5957 - val_mae: 858.5957\n",
      "Epoch 50/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.7214 - mae: 882.7214 - val_loss: 853.9055 - val_mae: 853.9055\n",
      "Epoch 51/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.7680 - mae: 884.7680 - val_loss: 857.0418 - val_mae: 857.0418\n",
      "Epoch 52/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.8766 - mae: 880.8766 - val_loss: 868.1803 - val_mae: 868.1803\n",
      "Epoch 53/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.9905 - mae: 880.9905 - val_loss: 853.3317 - val_mae: 853.3317\n",
      "Epoch 54/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.2682 - mae: 880.2682 - val_loss: 852.5198 - val_mae: 852.5198\n",
      "Epoch 55/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.2736 - mae: 881.2736 - val_loss: 852.8842 - val_mae: 852.8842\n",
      "Epoch 56/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.9844 - mae: 880.9844 - val_loss: 859.4183 - val_mae: 859.4183\n",
      "Epoch 57/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.0159 - mae: 883.0159 - val_loss: 862.1031 - val_mae: 862.1031\n",
      "Epoch 58/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.3551 - mae: 880.3551 - val_loss: 855.2495 - val_mae: 855.2495\n",
      "Epoch 59/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.5663 - mae: 881.5663 - val_loss: 853.6774 - val_mae: 853.6774\n",
      "Epoch 60/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.4138 - mae: 883.4138 - val_loss: 853.7426 - val_mae: 853.7426\n",
      "Epoch 61/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.3406 - mae: 879.3406 - val_loss: 853.8457 - val_mae: 853.8457\n",
      "Epoch 62/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.8602 - mae: 881.8602 - val_loss: 860.2849 - val_mae: 860.2849\n",
      "Epoch 63/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.5025 - mae: 879.5025 - val_loss: 854.1465 - val_mae: 854.1465\n",
      "Epoch 64/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.4688 - mae: 879.4688 - val_loss: 857.1913 - val_mae: 857.1913\n",
      "Epoch 65/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.4008 - mae: 880.4008 - val_loss: 855.1909 - val_mae: 855.1909\n",
      "Epoch 66/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.6677 - mae: 881.6677 - val_loss: 855.1751 - val_mae: 855.1751\n",
      "Epoch 67/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.6907 - mae: 884.6907 - val_loss: 860.1407 - val_mae: 860.1407\n",
      "Epoch 68/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.3054 - mae: 880.3054 - val_loss: 851.6393 - val_mae: 851.6393\n",
      "Epoch 69/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.2280 - mae: 881.2280 - val_loss: 851.9262 - val_mae: 851.9262\n",
      "Epoch 70/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.4757 - mae: 878.4757 - val_loss: 857.0912 - val_mae: 857.0912\n",
      "Epoch 71/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.0806 - mae: 881.0806 - val_loss: 854.9028 - val_mae: 854.9028\n",
      "Epoch 72/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.1820 - mae: 880.1820 - val_loss: 854.8806 - val_mae: 854.8806\n",
      "Epoch 73/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.7092 - mae: 881.7092 - val_loss: 853.7252 - val_mae: 853.7252\n",
      "Epoch 74/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.3786 - mae: 880.3786 - val_loss: 851.5552 - val_mae: 851.5552\n",
      "Epoch 75/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.6001 - mae: 880.6001 - val_loss: 852.4684 - val_mae: 852.4684\n",
      "Epoch 76/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.5234 - mae: 881.5234 - val_loss: 853.0389 - val_mae: 853.0389\n",
      "Epoch 77/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.1023 - mae: 879.1023 - val_loss: 853.0220 - val_mae: 853.0220\n",
      "Epoch 78/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.6077 - mae: 878.6077 - val_loss: 851.7958 - val_mae: 851.7958\n",
      "Epoch 79/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.9688 - mae: 879.9688 - val_loss: 851.9238 - val_mae: 851.9238\n",
      "Epoch 80/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.6780 - mae: 879.6780 - val_loss: 850.7955 - val_mae: 850.7955\n",
      "Epoch 81/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.9124 - mae: 880.9124 - val_loss: 851.3190 - val_mae: 851.3190\n",
      "Epoch 82/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.0278 - mae: 881.0278 - val_loss: 854.3887 - val_mae: 854.3887\n",
      "Epoch 83/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.4875 - mae: 878.4875 - val_loss: 853.0764 - val_mae: 853.0764\n",
      "Epoch 84/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.2349 - mae: 881.2349 - val_loss: 855.6768 - val_mae: 855.6768\n",
      "Epoch 85/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.7804 - mae: 878.7804 - val_loss: 852.6530 - val_mae: 852.6530\n",
      "Epoch 86/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.0291 - mae: 879.0291 - val_loss: 854.8871 - val_mae: 854.8871\n",
      "Epoch 87/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.8638 - mae: 879.8638 - val_loss: 855.5140 - val_mae: 855.5140\n",
      "Epoch 88/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.3928 - mae: 880.3928 - val_loss: 851.9240 - val_mae: 851.9240\n",
      "Epoch 89/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.2223 - mae: 879.2223 - val_loss: 850.5480 - val_mae: 850.5480\n",
      "Epoch 90/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.2379 - mae: 882.2379 - val_loss: 852.2048 - val_mae: 852.2048\n",
      "Epoch 91/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.5689 - mae: 880.5689 - val_loss: 851.4233 - val_mae: 851.4233\n",
      "Epoch 92/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.8627 - mae: 878.8627 - val_loss: 853.0790 - val_mae: 853.0790\n",
      "Epoch 93/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.9850 - mae: 882.9850 - val_loss: 852.6951 - val_mae: 852.6951\n",
      "Epoch 94/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.9521 - mae: 878.9521 - val_loss: 857.0448 - val_mae: 857.0448\n",
      "Epoch 95/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.3744 - mae: 879.3744 - val_loss: 851.0669 - val_mae: 851.0669\n",
      "Epoch 96/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.3074 - mae: 881.3074 - val_loss: 851.9929 - val_mae: 851.9929\n",
      "Epoch 97/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.2985 - mae: 878.2985 - val_loss: 857.4996 - val_mae: 857.4996\n",
      "Epoch 98/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.3468 - mae: 880.3468 - val_loss: 855.7626 - val_mae: 855.7626\n",
      "Epoch 99/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.7679 - mae: 878.7679 - val_loss: 855.7001 - val_mae: 855.7001\n",
      "Epoch 100/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 875.3073 - mae: 875.3073 - val_loss: 860.0775 - val_mae: 860.0775\n",
      "Fold 1 - Loss: 860.0771, MAE: 860.0771\n",
      "393/393 [==============================] - 0s 478us/step\n",
      "Fold 2 / 3\n",
      "Epoch 1/100\n",
      "197/197 [==============================] - 1s 2ms/step - loss: 2292.8853 - mae: 2292.8853 - val_loss: 1093.0575 - val_mae: 1093.0575\n",
      "Epoch 2/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 992.0164 - mae: 992.0164 - val_loss: 903.8488 - val_mae: 903.8488\n",
      "Epoch 3/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 896.0010 - mae: 896.0010 - val_loss: 871.7944 - val_mae: 871.7944\n",
      "Epoch 4/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.2893 - mae: 884.2893 - val_loss: 867.8495 - val_mae: 867.8495\n",
      "Epoch 5/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 887.2177 - mae: 887.2177 - val_loss: 871.2227 - val_mae: 871.2227\n",
      "Epoch 6/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.5828 - mae: 884.5828 - val_loss: 866.0579 - val_mae: 866.0579\n",
      "Epoch 7/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.6851 - mae: 884.6851 - val_loss: 864.2006 - val_mae: 864.2006\n",
      "Epoch 8/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.5197 - mae: 882.5197 - val_loss: 868.2122 - val_mae: 868.2122\n",
      "Epoch 9/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.8203 - mae: 883.8203 - val_loss: 868.0317 - val_mae: 868.0317\n",
      "Epoch 10/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.3663 - mae: 881.3663 - val_loss: 868.6154 - val_mae: 868.6154\n",
      "Epoch 11/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.9743 - mae: 883.9743 - val_loss: 864.8965 - val_mae: 864.8965\n",
      "Epoch 12/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.8245 - mae: 884.8245 - val_loss: 869.4910 - val_mae: 869.4910\n",
      "Epoch 13/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.2794 - mae: 881.2794 - val_loss: 872.6091 - val_mae: 872.6091\n",
      "Epoch 14/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.4445 - mae: 883.4445 - val_loss: 865.9436 - val_mae: 865.9436\n",
      "Epoch 15/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.0021 - mae: 882.0021 - val_loss: 865.8577 - val_mae: 865.8577\n",
      "Epoch 16/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.4324 - mae: 884.4324 - val_loss: 865.6825 - val_mae: 865.6825\n",
      "Epoch 17/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.9863 - mae: 881.9863 - val_loss: 863.4839 - val_mae: 863.4839\n",
      "Epoch 18/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.1047 - mae: 881.1047 - val_loss: 865.9947 - val_mae: 865.9947\n",
      "Epoch 19/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.2501 - mae: 881.2501 - val_loss: 866.8931 - val_mae: 866.8931\n",
      "Epoch 20/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.0066 - mae: 882.0066 - val_loss: 865.4994 - val_mae: 865.4994\n",
      "Epoch 21/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.9821 - mae: 880.9821 - val_loss: 866.6157 - val_mae: 866.6157\n",
      "Epoch 22/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.5282 - mae: 881.5282 - val_loss: 868.7551 - val_mae: 868.7551\n",
      "Epoch 23/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.2957 - mae: 880.2957 - val_loss: 865.5187 - val_mae: 865.5187\n",
      "Epoch 24/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.2972 - mae: 882.2972 - val_loss: 863.1568 - val_mae: 863.1568\n",
      "Epoch 25/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.4735 - mae: 883.4735 - val_loss: 865.0931 - val_mae: 865.0931\n",
      "Epoch 26/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.0414 - mae: 878.0414 - val_loss: 863.5264 - val_mae: 863.5264\n",
      "Epoch 27/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.8848 - mae: 881.8848 - val_loss: 866.4249 - val_mae: 866.4249\n",
      "Epoch 28/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.3646 - mae: 882.3646 - val_loss: 872.5858 - val_mae: 872.5858\n",
      "Epoch 29/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.9824 - mae: 880.9824 - val_loss: 865.8159 - val_mae: 865.8159\n",
      "Epoch 30/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.3862 - mae: 880.3862 - val_loss: 868.2215 - val_mae: 868.2215\n",
      "Epoch 31/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.7473 - mae: 880.7473 - val_loss: 862.7667 - val_mae: 862.7667\n",
      "Epoch 32/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.3703 - mae: 882.3703 - val_loss: 867.8101 - val_mae: 867.8101\n",
      "Epoch 33/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.5297 - mae: 881.5297 - val_loss: 867.4811 - val_mae: 867.4811\n",
      "Epoch 34/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.6661 - mae: 883.6661 - val_loss: 867.2604 - val_mae: 867.2604\n",
      "Epoch 35/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.5505 - mae: 879.5505 - val_loss: 865.2677 - val_mae: 865.2677\n",
      "Epoch 36/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.0264 - mae: 882.0264 - val_loss: 867.7505 - val_mae: 867.7505\n",
      "Epoch 37/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.1422 - mae: 881.1422 - val_loss: 872.7626 - val_mae: 872.7626\n",
      "Epoch 38/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.7871 - mae: 879.7871 - val_loss: 866.6419 - val_mae: 866.6419\n",
      "Epoch 39/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.2195 - mae: 880.2195 - val_loss: 865.0204 - val_mae: 865.0204\n",
      "Epoch 40/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.6030 - mae: 880.6030 - val_loss: 868.1198 - val_mae: 868.1198\n",
      "Epoch 41/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.8989 - mae: 879.8989 - val_loss: 868.9019 - val_mae: 868.9019\n",
      "Epoch 42/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.9565 - mae: 879.9565 - val_loss: 865.8746 - val_mae: 865.8746\n",
      "Epoch 43/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.1317 - mae: 878.1317 - val_loss: 867.1680 - val_mae: 867.1680\n",
      "Epoch 44/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.0712 - mae: 880.0712 - val_loss: 864.3793 - val_mae: 864.3793\n",
      "Epoch 45/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.8115 - mae: 880.8115 - val_loss: 864.7853 - val_mae: 864.7853\n",
      "Epoch 46/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.4575 - mae: 880.4575 - val_loss: 864.1295 - val_mae: 864.1295\n",
      "Epoch 47/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.5096 - mae: 877.5096 - val_loss: 863.5588 - val_mae: 863.5588\n",
      "Epoch 48/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.2539 - mae: 880.2539 - val_loss: 863.2013 - val_mae: 863.2013\n",
      "Epoch 49/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.3518 - mae: 880.3518 - val_loss: 867.4139 - val_mae: 867.4139\n",
      "Epoch 50/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.2440 - mae: 878.2440 - val_loss: 866.6366 - val_mae: 866.6366\n",
      "Epoch 51/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.2971 - mae: 878.2971 - val_loss: 867.6970 - val_mae: 867.6970\n",
      "Epoch 52/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.3517 - mae: 880.3517 - val_loss: 865.4967 - val_mae: 865.4967\n",
      "Epoch 53/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.3954 - mae: 881.3954 - val_loss: 863.9534 - val_mae: 863.9534\n",
      "Epoch 54/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.0871 - mae: 878.0871 - val_loss: 865.0704 - val_mae: 865.0704\n",
      "Epoch 55/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.9803 - mae: 877.9803 - val_loss: 864.1525 - val_mae: 864.1525\n",
      "Epoch 56/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.1501 - mae: 878.1501 - val_loss: 866.4507 - val_mae: 866.4507\n",
      "Epoch 57/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.7630 - mae: 879.7630 - val_loss: 868.4631 - val_mae: 868.4631\n",
      "Epoch 58/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.5646 - mae: 880.5646 - val_loss: 864.6706 - val_mae: 864.6706\n",
      "Epoch 59/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.9232 - mae: 879.9232 - val_loss: 865.8884 - val_mae: 865.8884\n",
      "Epoch 60/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.9792 - mae: 879.9792 - val_loss: 864.1102 - val_mae: 864.1102\n",
      "Epoch 61/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.7556 - mae: 879.7556 - val_loss: 871.3528 - val_mae: 871.3528\n",
      "Epoch 62/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.4685 - mae: 877.4685 - val_loss: 863.3381 - val_mae: 863.3381\n",
      "Epoch 63/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.1820 - mae: 881.1820 - val_loss: 867.8456 - val_mae: 867.8456\n",
      "Epoch 64/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.0504 - mae: 880.0504 - val_loss: 865.7583 - val_mae: 865.7583\n",
      "Epoch 65/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.4802 - mae: 879.4802 - val_loss: 869.3843 - val_mae: 869.3843\n",
      "Epoch 66/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.7985 - mae: 878.7985 - val_loss: 864.8155 - val_mae: 864.8155\n",
      "Epoch 67/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.8863 - mae: 877.8863 - val_loss: 863.9047 - val_mae: 863.9047\n",
      "Epoch 68/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.9455 - mae: 878.9455 - val_loss: 866.1623 - val_mae: 866.1623\n",
      "Epoch 69/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.2551 - mae: 878.2551 - val_loss: 864.0266 - val_mae: 864.0266\n",
      "Epoch 70/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.4249 - mae: 882.4249 - val_loss: 864.6207 - val_mae: 864.6207\n",
      "Epoch 71/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.7421 - mae: 881.7421 - val_loss: 862.7643 - val_mae: 862.7643\n",
      "Epoch 72/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 876.8332 - mae: 876.8332 - val_loss: 869.4210 - val_mae: 869.4210\n",
      "Epoch 73/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.1014 - mae: 878.1014 - val_loss: 865.2854 - val_mae: 865.2854\n",
      "Epoch 74/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 876.8736 - mae: 876.8736 - val_loss: 864.9371 - val_mae: 864.9371\n",
      "Epoch 75/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.0854 - mae: 880.0854 - val_loss: 862.4947 - val_mae: 862.4947\n",
      "Epoch 76/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.3345 - mae: 877.3345 - val_loss: 865.2335 - val_mae: 865.2335\n",
      "Epoch 77/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.6747 - mae: 877.6747 - val_loss: 865.2148 - val_mae: 865.2148\n",
      "Epoch 78/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.8461 - mae: 878.8461 - val_loss: 868.2478 - val_mae: 868.2478\n",
      "Epoch 79/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.0963 - mae: 880.0963 - val_loss: 869.7464 - val_mae: 869.7464\n",
      "Epoch 80/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.0102 - mae: 878.0102 - val_loss: 866.4882 - val_mae: 866.4882\n",
      "Epoch 81/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.7812 - mae: 878.7812 - val_loss: 865.1646 - val_mae: 865.1646\n",
      "Epoch 82/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.6692 - mae: 878.6692 - val_loss: 869.0929 - val_mae: 869.0929\n",
      "Epoch 83/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.7802 - mae: 879.7802 - val_loss: 867.3494 - val_mae: 867.3494\n",
      "Epoch 84/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.5441 - mae: 878.5441 - val_loss: 865.0024 - val_mae: 865.0024\n",
      "Epoch 85/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.5411 - mae: 878.5411 - val_loss: 865.0335 - val_mae: 865.0335\n",
      "Epoch 86/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.9697 - mae: 877.9697 - val_loss: 867.2382 - val_mae: 867.2382\n",
      "Epoch 87/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.6401 - mae: 879.6401 - val_loss: 871.2065 - val_mae: 871.2065\n",
      "Epoch 88/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.4562 - mae: 877.4562 - val_loss: 866.9527 - val_mae: 866.9527\n",
      "Epoch 89/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.0079 - mae: 880.0079 - val_loss: 862.5773 - val_mae: 862.5773\n",
      "Epoch 90/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 876.4028 - mae: 876.4028 - val_loss: 868.7311 - val_mae: 868.7311\n",
      "Epoch 91/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.7425 - mae: 877.7425 - val_loss: 868.7329 - val_mae: 868.7329\n",
      "Epoch 92/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 879.8543 - mae: 879.8543 - val_loss: 864.4952 - val_mae: 864.4952\n",
      "Epoch 93/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 878.4001 - mae: 878.4001 - val_loss: 864.7805 - val_mae: 864.7805\n",
      "Epoch 94/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.2771 - mae: 877.2771 - val_loss: 864.9042 - val_mae: 864.9042\n",
      "Epoch 95/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 880.5698 - mae: 880.5698 - val_loss: 865.8877 - val_mae: 865.8877\n",
      "Epoch 96/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.9528 - mae: 877.9528 - val_loss: 868.6810 - val_mae: 868.6810\n",
      "Epoch 97/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.5514 - mae: 881.5514 - val_loss: 867.8845 - val_mae: 867.8845\n",
      "Epoch 98/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 876.2134 - mae: 876.2134 - val_loss: 866.0603 - val_mae: 866.0603\n",
      "Epoch 99/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.8725 - mae: 877.8725 - val_loss: 867.7070 - val_mae: 867.7070\n",
      "Epoch 100/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 877.7029 - mae: 877.7029 - val_loss: 863.7881 - val_mae: 863.7881\n",
      "Fold 2 - Loss: 863.7887, MAE: 863.7887\n",
      "393/393 [==============================] - 0s 481us/step\n",
      "Fold 3 / 3\n",
      "Epoch 1/100\n",
      "197/197 [==============================] - 1s 2ms/step - loss: 2329.0994 - mae: 2329.0994 - val_loss: 1094.5760 - val_mae: 1094.5760\n",
      "Epoch 2/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 999.9205 - mae: 999.9205 - val_loss: 891.7050 - val_mae: 891.7050\n",
      "Epoch 3/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 903.9841 - mae: 903.9841 - val_loss: 862.8425 - val_mae: 862.8425\n",
      "Epoch 4/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 889.7867 - mae: 889.7867 - val_loss: 857.6307 - val_mae: 857.6307\n",
      "Epoch 5/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 887.9763 - mae: 887.9763 - val_loss: 855.2592 - val_mae: 855.2592\n",
      "Epoch 6/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 887.0414 - mae: 887.0414 - val_loss: 854.8727 - val_mae: 854.8727\n",
      "Epoch 7/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 889.5413 - mae: 889.5413 - val_loss: 853.2268 - val_mae: 853.2268\n",
      "Epoch 8/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 889.1173 - mae: 889.1173 - val_loss: 859.7642 - val_mae: 859.7642\n",
      "Epoch 9/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 888.7961 - mae: 888.7961 - val_loss: 857.4843 - val_mae: 857.4843\n",
      "Epoch 10/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 888.3790 - mae: 888.3790 - val_loss: 853.2278 - val_mae: 853.2278\n",
      "Epoch 11/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 886.9208 - mae: 886.9208 - val_loss: 853.8281 - val_mae: 853.8281\n",
      "Epoch 12/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 887.6584 - mae: 887.6584 - val_loss: 863.1621 - val_mae: 863.1621\n",
      "Epoch 13/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 886.9202 - mae: 886.9202 - val_loss: 854.7477 - val_mae: 854.7477\n",
      "Epoch 14/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 887.8407 - mae: 887.8407 - val_loss: 856.8972 - val_mae: 856.8972\n",
      "Epoch 15/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.7252 - mae: 884.7252 - val_loss: 853.0096 - val_mae: 853.0096\n",
      "Epoch 16/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 888.9271 - mae: 888.9271 - val_loss: 853.8066 - val_mae: 853.8066\n",
      "Epoch 17/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 889.8028 - mae: 889.8028 - val_loss: 852.4460 - val_mae: 852.4460\n",
      "Epoch 18/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 887.4772 - mae: 887.4772 - val_loss: 853.4138 - val_mae: 853.4138\n",
      "Epoch 19/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 887.1042 - mae: 887.1042 - val_loss: 857.8737 - val_mae: 857.8737\n",
      "Epoch 20/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.6981 - mae: 885.6981 - val_loss: 854.6003 - val_mae: 854.6003\n",
      "Epoch 21/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 887.3834 - mae: 887.3834 - val_loss: 859.9493 - val_mae: 859.9493\n",
      "Epoch 22/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 886.0859 - mae: 886.0859 - val_loss: 858.8853 - val_mae: 858.8853\n",
      "Epoch 23/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 886.5245 - mae: 886.5245 - val_loss: 856.4428 - val_mae: 856.4428\n",
      "Epoch 24/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 886.9584 - mae: 886.9584 - val_loss: 854.8625 - val_mae: 854.8625\n",
      "Epoch 25/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.1922 - mae: 885.1922 - val_loss: 853.0569 - val_mae: 853.0569\n",
      "Epoch 26/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.8680 - mae: 885.8680 - val_loss: 852.9422 - val_mae: 852.9422\n",
      "Epoch 27/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 889.7543 - mae: 889.7543 - val_loss: 854.6281 - val_mae: 854.6281\n",
      "Epoch 28/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 886.8679 - mae: 886.8679 - val_loss: 857.5628 - val_mae: 857.5628\n",
      "Epoch 29/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 886.8265 - mae: 886.8265 - val_loss: 859.1995 - val_mae: 859.1995\n",
      "Epoch 30/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 888.4468 - mae: 888.4468 - val_loss: 854.7628 - val_mae: 854.7628\n",
      "Epoch 31/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.5707 - mae: 884.5707 - val_loss: 854.7099 - val_mae: 854.7099\n",
      "Epoch 32/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 887.1893 - mae: 887.1893 - val_loss: 858.3380 - val_mae: 858.3380\n",
      "Epoch 33/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.7094 - mae: 885.7094 - val_loss: 853.3111 - val_mae: 853.3111\n",
      "Epoch 34/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 887.3763 - mae: 887.3763 - val_loss: 853.1076 - val_mae: 853.1076\n",
      "Epoch 35/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.6189 - mae: 884.6189 - val_loss: 856.4305 - val_mae: 856.4305\n",
      "Epoch 36/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 887.6568 - mae: 887.6568 - val_loss: 858.2680 - val_mae: 858.2680\n",
      "Epoch 37/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 886.0183 - mae: 886.0183 - val_loss: 851.9551 - val_mae: 851.9551\n",
      "Epoch 38/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.6803 - mae: 883.6803 - val_loss: 851.2817 - val_mae: 851.2817\n",
      "Epoch 39/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.7706 - mae: 884.7706 - val_loss: 851.7926 - val_mae: 851.7926\n",
      "Epoch 40/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.7829 - mae: 885.7829 - val_loss: 851.3445 - val_mae: 851.3445\n",
      "Epoch 41/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 886.2864 - mae: 886.2864 - val_loss: 851.2915 - val_mae: 851.2915\n",
      "Epoch 42/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.7488 - mae: 882.7488 - val_loss: 851.6861 - val_mae: 851.6861\n",
      "Epoch 43/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.7833 - mae: 882.7833 - val_loss: 857.8409 - val_mae: 857.8409\n",
      "Epoch 44/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.8370 - mae: 882.8370 - val_loss: 852.3504 - val_mae: 852.3504\n",
      "Epoch 45/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.7728 - mae: 885.7728 - val_loss: 854.4074 - val_mae: 854.4074\n",
      "Epoch 46/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.0629 - mae: 885.0629 - val_loss: 854.2499 - val_mae: 854.2499\n",
      "Epoch 47/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 887.4525 - mae: 887.4525 - val_loss: 851.7808 - val_mae: 851.7808\n",
      "Epoch 48/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.9888 - mae: 885.9888 - val_loss: 850.9183 - val_mae: 850.9183\n",
      "Epoch 49/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.4117 - mae: 885.4117 - val_loss: 853.4548 - val_mae: 853.4548\n",
      "Epoch 50/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.5718 - mae: 885.5718 - val_loss: 855.9473 - val_mae: 855.9473\n",
      "Epoch 51/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.3420 - mae: 885.3420 - val_loss: 858.3458 - val_mae: 858.3458\n",
      "Epoch 52/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.0555 - mae: 885.0555 - val_loss: 852.8456 - val_mae: 852.8456\n",
      "Epoch 53/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.7404 - mae: 884.7404 - val_loss: 854.2996 - val_mae: 854.2996\n",
      "Epoch 54/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 887.0898 - mae: 887.0898 - val_loss: 851.7101 - val_mae: 851.7101\n",
      "Epoch 55/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.4313 - mae: 885.4313 - val_loss: 852.6978 - val_mae: 852.6978\n",
      "Epoch 56/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 887.5797 - mae: 887.5797 - val_loss: 852.7845 - val_mae: 852.7845\n",
      "Epoch 57/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 886.8966 - mae: 886.8966 - val_loss: 854.7431 - val_mae: 854.7431\n",
      "Epoch 58/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 886.7943 - mae: 886.7943 - val_loss: 851.5709 - val_mae: 851.5709\n",
      "Epoch 59/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.8359 - mae: 885.8359 - val_loss: 851.6165 - val_mae: 851.6165\n",
      "Epoch 60/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 886.1269 - mae: 886.1269 - val_loss: 851.0558 - val_mae: 851.0558\n",
      "Epoch 61/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.4196 - mae: 884.4196 - val_loss: 850.9016 - val_mae: 850.9016\n",
      "Epoch 62/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.4371 - mae: 884.4371 - val_loss: 851.1086 - val_mae: 851.1086\n",
      "Epoch 63/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.5860 - mae: 883.5860 - val_loss: 855.4288 - val_mae: 855.4288\n",
      "Epoch 64/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.3629 - mae: 882.3629 - val_loss: 851.3999 - val_mae: 851.3999\n",
      "Epoch 65/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.1950 - mae: 885.1950 - val_loss: 852.3557 - val_mae: 852.3557\n",
      "Epoch 66/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.5067 - mae: 884.5067 - val_loss: 850.7505 - val_mae: 850.7505\n",
      "Epoch 67/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.4912 - mae: 885.4912 - val_loss: 852.0139 - val_mae: 852.0139\n",
      "Epoch 68/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.9637 - mae: 884.9637 - val_loss: 851.0314 - val_mae: 851.0314\n",
      "Epoch 69/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.8343 - mae: 884.8343 - val_loss: 853.1535 - val_mae: 853.1535\n",
      "Epoch 70/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.2712 - mae: 885.2712 - val_loss: 852.6506 - val_mae: 852.6506\n",
      "Epoch 71/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.1281 - mae: 885.1281 - val_loss: 854.3096 - val_mae: 854.3096\n",
      "Epoch 72/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.1098 - mae: 882.1098 - val_loss: 856.2809 - val_mae: 856.2809\n",
      "Epoch 73/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 886.4313 - mae: 886.4313 - val_loss: 858.4808 - val_mae: 858.4808\n",
      "Epoch 74/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.4827 - mae: 884.4827 - val_loss: 854.1824 - val_mae: 854.1824\n",
      "Epoch 75/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.8251 - mae: 884.8251 - val_loss: 851.5403 - val_mae: 851.5403\n",
      "Epoch 76/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.6107 - mae: 884.6107 - val_loss: 850.7418 - val_mae: 850.7418\n",
      "Epoch 77/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.1523 - mae: 884.1523 - val_loss: 856.7514 - val_mae: 856.7514\n",
      "Epoch 78/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.3153 - mae: 884.3153 - val_loss: 852.0941 - val_mae: 852.0941\n",
      "Epoch 79/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.0438 - mae: 884.0438 - val_loss: 853.7968 - val_mae: 853.7968\n",
      "Epoch 80/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.7578 - mae: 884.7578 - val_loss: 853.8440 - val_mae: 853.8440\n",
      "Epoch 81/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.8961 - mae: 883.8961 - val_loss: 858.0165 - val_mae: 858.0165\n",
      "Epoch 82/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.8261 - mae: 882.8261 - val_loss: 855.9431 - val_mae: 855.9431\n",
      "Epoch 83/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.0856 - mae: 884.0856 - val_loss: 850.8334 - val_mae: 850.8334\n",
      "Epoch 84/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.8638 - mae: 885.8638 - val_loss: 851.5797 - val_mae: 851.5797\n",
      "Epoch 85/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.4705 - mae: 882.4705 - val_loss: 856.8169 - val_mae: 856.8169\n",
      "Epoch 86/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.3187 - mae: 884.3187 - val_loss: 851.3557 - val_mae: 851.3557\n",
      "Epoch 87/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.4777 - mae: 882.4777 - val_loss: 851.1709 - val_mae: 851.1709\n",
      "Epoch 88/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.8209 - mae: 884.8209 - val_loss: 851.3623 - val_mae: 851.3623\n",
      "Epoch 89/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.6265 - mae: 885.6265 - val_loss: 858.6718 - val_mae: 858.6718\n",
      "Epoch 90/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.5176 - mae: 884.5176 - val_loss: 851.5035 - val_mae: 851.5035\n",
      "Epoch 91/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.7412 - mae: 883.7412 - val_loss: 852.7927 - val_mae: 852.7927\n",
      "Epoch 92/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.5855 - mae: 883.5855 - val_loss: 852.7452 - val_mae: 852.7452\n",
      "Epoch 93/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 887.7702 - mae: 887.7702 - val_loss: 850.6280 - val_mae: 850.6280\n",
      "Epoch 94/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 886.0230 - mae: 886.0230 - val_loss: 854.0263 - val_mae: 854.0263\n",
      "Epoch 95/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 884.3577 - mae: 884.3577 - val_loss: 856.5966 - val_mae: 856.5966\n",
      "Epoch 96/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 882.4779 - mae: 882.4779 - val_loss: 850.9247 - val_mae: 850.9247\n",
      "Epoch 97/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 881.4841 - mae: 881.4841 - val_loss: 850.4670 - val_mae: 850.4670\n",
      "Epoch 98/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.2043 - mae: 885.2043 - val_loss: 853.8371 - val_mae: 853.8371\n",
      "Epoch 99/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 885.1840 - mae: 885.1840 - val_loss: 853.5590 - val_mae: 853.5590\n",
      "Epoch 100/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 883.1279 - mae: 883.1279 - val_loss: 865.5066 - val_mae: 865.5066\n",
      "Fold 3 - Loss: 865.5062, MAE: 865.5062\n",
      "393/393 [==============================] - 0s 488us/step\n",
      "[각 Fold별 평균 성능]\n",
      "mae : 863.1239666666667\n",
      "mape : 0.34440000000000004\n",
      "mse : 1239151.1379\n",
      "rmse : 1113.1597333333334\n",
      "\n",
      "--- Cross Validation: 5-Fold 시작 ---\n",
      "\n",
      "Fold 1 / 5\n",
      "Epoch 1/100\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 2039.6183 - mae: 2039.6183 - val_loss: 1037.3182 - val_mae: 1037.3182\n",
      "Epoch 2/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 949.1106 - mae: 949.1106 - val_loss: 878.1804 - val_mae: 878.1804\n",
      "Epoch 3/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 894.4044 - mae: 894.4044 - val_loss: 862.4488 - val_mae: 862.4488\n",
      "Epoch 4/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 886.8040 - mae: 886.8040 - val_loss: 860.2374 - val_mae: 860.2374\n",
      "Epoch 5/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.3349 - mae: 885.3349 - val_loss: 862.5266 - val_mae: 862.5266\n",
      "Epoch 6/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.7088 - mae: 885.7088 - val_loss: 865.3212 - val_mae: 865.3212\n",
      "Epoch 7/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.1146 - mae: 885.1146 - val_loss: 859.8125 - val_mae: 859.8125\n",
      "Epoch 8/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.0402 - mae: 884.0402 - val_loss: 860.1459 - val_mae: 860.1459\n",
      "Epoch 9/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.4382 - mae: 883.4382 - val_loss: 860.2296 - val_mae: 860.2296\n",
      "Epoch 10/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.5028 - mae: 884.5028 - val_loss: 870.2115 - val_mae: 870.2115\n",
      "Epoch 11/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.8229 - mae: 884.8229 - val_loss: 860.3642 - val_mae: 860.3642\n",
      "Epoch 12/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.0103 - mae: 884.0103 - val_loss: 861.8932 - val_mae: 861.8932\n",
      "Epoch 13/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.0192 - mae: 882.0192 - val_loss: 860.2424 - val_mae: 860.2424\n",
      "Epoch 14/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.2188 - mae: 883.2188 - val_loss: 857.8263 - val_mae: 857.8263\n",
      "Epoch 15/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.4600 - mae: 882.4600 - val_loss: 862.1249 - val_mae: 862.1249\n",
      "Epoch 16/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 883.8170 - mae: 883.8170 - val_loss: 860.4390 - val_mae: 860.4390\n",
      "Epoch 17/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.9303 - mae: 882.9303 - val_loss: 859.3170 - val_mae: 859.3170\n",
      "Epoch 18/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.4512 - mae: 882.4512 - val_loss: 859.9507 - val_mae: 859.9507\n",
      "Epoch 19/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.6682 - mae: 882.6682 - val_loss: 857.8824 - val_mae: 857.8824\n",
      "Epoch 20/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.0524 - mae: 883.0524 - val_loss: 861.2076 - val_mae: 861.2076\n",
      "Epoch 21/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.2454 - mae: 882.2454 - val_loss: 860.5284 - val_mae: 860.5284\n",
      "Epoch 22/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.5982 - mae: 883.5982 - val_loss: 859.0800 - val_mae: 859.0800\n",
      "Epoch 23/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.3337 - mae: 883.3337 - val_loss: 863.0569 - val_mae: 863.0569\n",
      "Epoch 24/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.9940 - mae: 883.9940 - val_loss: 856.6843 - val_mae: 856.6843\n",
      "Epoch 25/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.6092 - mae: 882.6092 - val_loss: 859.0598 - val_mae: 859.0598\n",
      "Epoch 26/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.0409 - mae: 885.0409 - val_loss: 858.5088 - val_mae: 858.5088\n",
      "Epoch 27/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.8314 - mae: 884.8314 - val_loss: 856.8962 - val_mae: 856.8962\n",
      "Epoch 28/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.6271 - mae: 883.6271 - val_loss: 860.1000 - val_mae: 860.1000\n",
      "Epoch 29/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.4822 - mae: 882.4822 - val_loss: 859.2763 - val_mae: 859.2763\n",
      "Epoch 30/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.7082 - mae: 880.7082 - val_loss: 856.6237 - val_mae: 856.6237\n",
      "Epoch 31/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.0222 - mae: 883.0222 - val_loss: 860.2482 - val_mae: 860.2482\n",
      "Epoch 32/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.7842 - mae: 881.7842 - val_loss: 861.1857 - val_mae: 861.1857\n",
      "Epoch 33/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.8802 - mae: 884.8802 - val_loss: 862.0574 - val_mae: 862.0574\n",
      "Epoch 34/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.4514 - mae: 880.4514 - val_loss: 863.4070 - val_mae: 863.4070\n",
      "Epoch 35/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.3145 - mae: 884.3145 - val_loss: 861.7784 - val_mae: 861.7784\n",
      "Epoch 36/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.0833 - mae: 883.0833 - val_loss: 859.2309 - val_mae: 859.2309\n",
      "Epoch 37/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.3223 - mae: 884.3223 - val_loss: 858.5760 - val_mae: 858.5760\n",
      "Epoch 38/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.8708 - mae: 882.8708 - val_loss: 856.1943 - val_mae: 856.1943\n",
      "Epoch 39/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.5015 - mae: 881.5015 - val_loss: 857.1629 - val_mae: 857.1629\n",
      "Epoch 40/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.1169 - mae: 881.1169 - val_loss: 859.5897 - val_mae: 859.5897\n",
      "Epoch 41/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.2925 - mae: 880.2925 - val_loss: 856.6606 - val_mae: 856.6606\n",
      "Epoch 42/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.1960 - mae: 882.1960 - val_loss: 856.5459 - val_mae: 856.5459\n",
      "Epoch 43/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.5276 - mae: 880.5276 - val_loss: 858.6992 - val_mae: 858.6992\n",
      "Epoch 44/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.5977 - mae: 879.5977 - val_loss: 862.8589 - val_mae: 862.8589\n",
      "Epoch 45/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.0930 - mae: 881.0930 - val_loss: 858.6090 - val_mae: 858.6090\n",
      "Epoch 46/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.5931 - mae: 878.5931 - val_loss: 857.0121 - val_mae: 857.0121\n",
      "Epoch 47/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.2621 - mae: 881.2621 - val_loss: 857.0635 - val_mae: 857.0635\n",
      "Epoch 48/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.0885 - mae: 881.0885 - val_loss: 857.8527 - val_mae: 857.8527\n",
      "Epoch 49/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.5426 - mae: 881.5426 - val_loss: 855.5882 - val_mae: 855.5882\n",
      "Epoch 50/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.6906 - mae: 880.6906 - val_loss: 857.6252 - val_mae: 857.6252\n",
      "Epoch 51/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.0508 - mae: 880.0508 - val_loss: 855.7068 - val_mae: 855.7068\n",
      "Epoch 52/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.1643 - mae: 881.1643 - val_loss: 860.5894 - val_mae: 860.5894\n",
      "Epoch 53/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.7809 - mae: 878.7809 - val_loss: 857.9614 - val_mae: 857.9614\n",
      "Epoch 54/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.1384 - mae: 880.1384 - val_loss: 860.2303 - val_mae: 860.2303\n",
      "Epoch 55/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.6386 - mae: 880.6386 - val_loss: 858.2509 - val_mae: 858.2509\n",
      "Epoch 56/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.3448 - mae: 879.3448 - val_loss: 859.2905 - val_mae: 859.2905\n",
      "Epoch 57/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.2809 - mae: 880.2809 - val_loss: 858.8927 - val_mae: 858.8927\n",
      "Epoch 58/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.6641 - mae: 883.6641 - val_loss: 857.5796 - val_mae: 857.5796\n",
      "Epoch 59/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.6441 - mae: 879.6441 - val_loss: 856.3386 - val_mae: 856.3386\n",
      "Epoch 60/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.6309 - mae: 882.6309 - val_loss: 855.5462 - val_mae: 855.5462\n",
      "Epoch 61/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.2131 - mae: 884.2131 - val_loss: 859.0931 - val_mae: 859.0931\n",
      "Epoch 62/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.1119 - mae: 879.1119 - val_loss: 855.5768 - val_mae: 855.5768\n",
      "Epoch 63/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.0402 - mae: 882.0402 - val_loss: 856.1791 - val_mae: 856.1791\n",
      "Epoch 64/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.9281 - mae: 879.9281 - val_loss: 855.4863 - val_mae: 855.4863\n",
      "Epoch 65/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.3380 - mae: 880.3380 - val_loss: 858.7889 - val_mae: 858.7889\n",
      "Epoch 66/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.7334 - mae: 879.7334 - val_loss: 856.2913 - val_mae: 856.2913\n",
      "Epoch 67/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.6887 - mae: 881.6887 - val_loss: 857.1548 - val_mae: 857.1548\n",
      "Epoch 68/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.3294 - mae: 882.3294 - val_loss: 854.0811 - val_mae: 854.0811\n",
      "Epoch 69/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 881.9387 - mae: 881.9387 - val_loss: 855.8788 - val_mae: 855.8788\n",
      "Epoch 70/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 879.6187 - mae: 879.6187 - val_loss: 856.8237 - val_mae: 856.8237\n",
      "Epoch 71/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.7125 - mae: 880.7125 - val_loss: 857.2845 - val_mae: 857.2845\n",
      "Epoch 72/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.8105 - mae: 882.8105 - val_loss: 857.1168 - val_mae: 857.1168\n",
      "Epoch 73/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.3669 - mae: 877.3669 - val_loss: 856.0813 - val_mae: 856.0813\n",
      "Epoch 74/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.4293 - mae: 879.4293 - val_loss: 857.0628 - val_mae: 857.0628\n",
      "Epoch 75/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.0098 - mae: 882.0098 - val_loss: 858.5504 - val_mae: 858.5504\n",
      "Epoch 76/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.4580 - mae: 879.4580 - val_loss: 856.1794 - val_mae: 856.1794\n",
      "Epoch 77/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.1450 - mae: 880.1450 - val_loss: 859.5341 - val_mae: 859.5341\n",
      "Epoch 78/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.0072 - mae: 878.0072 - val_loss: 854.0913 - val_mae: 854.0913\n",
      "Epoch 79/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.5155 - mae: 878.5155 - val_loss: 858.2434 - val_mae: 858.2434\n",
      "Epoch 80/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.6696 - mae: 880.6696 - val_loss: 857.0056 - val_mae: 857.0056\n",
      "Epoch 81/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.8217 - mae: 876.8217 - val_loss: 857.4075 - val_mae: 857.4075\n",
      "Epoch 82/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.4129 - mae: 879.4129 - val_loss: 853.1091 - val_mae: 853.1091\n",
      "Epoch 83/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 878.0595 - mae: 878.0595 - val_loss: 853.4175 - val_mae: 853.4175\n",
      "Epoch 84/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.6512 - mae: 878.6512 - val_loss: 853.7432 - val_mae: 853.7432\n",
      "Epoch 85/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 876.9402 - mae: 876.9402 - val_loss: 854.5554 - val_mae: 854.5554\n",
      "Epoch 86/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 878.3323 - mae: 878.3323 - val_loss: 854.7872 - val_mae: 854.7872\n",
      "Epoch 87/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.5480 - mae: 880.5480 - val_loss: 855.7390 - val_mae: 855.7390\n",
      "Epoch 88/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.7836 - mae: 879.7836 - val_loss: 852.8066 - val_mae: 852.8066\n",
      "Epoch 89/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.0408 - mae: 877.0408 - val_loss: 855.3596 - val_mae: 855.3596\n",
      "Epoch 90/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.9944 - mae: 877.9944 - val_loss: 853.1922 - val_mae: 853.1922\n",
      "Epoch 91/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.5401 - mae: 876.5401 - val_loss: 854.9269 - val_mae: 854.9269\n",
      "Epoch 92/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.2179 - mae: 879.2179 - val_loss: 856.2860 - val_mae: 856.2860\n",
      "Epoch 93/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 875.6008 - mae: 875.6008 - val_loss: 854.2086 - val_mae: 854.2086\n",
      "Epoch 94/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.3208 - mae: 879.3208 - val_loss: 853.9329 - val_mae: 853.9329\n",
      "Epoch 95/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.0411 - mae: 880.0411 - val_loss: 852.5539 - val_mae: 852.5539\n",
      "Epoch 96/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.9955 - mae: 876.9955 - val_loss: 853.9839 - val_mae: 853.9839\n",
      "Epoch 97/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.1458 - mae: 879.1458 - val_loss: 855.4648 - val_mae: 855.4648\n",
      "Epoch 98/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.9566 - mae: 876.9566 - val_loss: 855.1978 - val_mae: 855.1978\n",
      "Epoch 99/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.1102 - mae: 878.1102 - val_loss: 852.6814 - val_mae: 852.6814\n",
      "Epoch 100/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.7651 - mae: 878.7651 - val_loss: 854.9673 - val_mae: 854.9673\n",
      "Fold 1 - Loss: 854.9672, MAE: 854.9672\n",
      "236/236 [==============================] - 0s 490us/step\n",
      "Fold 2 / 5\n",
      "Epoch 1/100\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 2044.8098 - mae: 2044.8098 - val_loss: 1044.0413 - val_mae: 1044.0413\n",
      "Epoch 2/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 942.4899 - mae: 942.4899 - val_loss: 874.9219 - val_mae: 874.9219\n",
      "Epoch 3/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 892.0912 - mae: 892.0912 - val_loss: 861.0574 - val_mae: 861.0574\n",
      "Epoch 4/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 886.8345 - mae: 886.8345 - val_loss: 858.0225 - val_mae: 858.0225\n",
      "Epoch 5/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 886.4225 - mae: 886.4225 - val_loss: 861.2864 - val_mae: 861.2864\n",
      "Epoch 6/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 888.3516 - mae: 888.3516 - val_loss: 857.0553 - val_mae: 857.0553\n",
      "Epoch 7/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.9280 - mae: 885.9280 - val_loss: 856.3915 - val_mae: 856.3915\n",
      "Epoch 8/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 886.7974 - mae: 886.7974 - val_loss: 858.6114 - val_mae: 858.6114\n",
      "Epoch 9/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 887.1285 - mae: 887.1285 - val_loss: 857.0185 - val_mae: 857.0185\n",
      "Epoch 10/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 886.0410 - mae: 886.0410 - val_loss: 858.2692 - val_mae: 858.2692\n",
      "Epoch 11/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.6182 - mae: 885.6182 - val_loss: 855.1257 - val_mae: 855.1257\n",
      "Epoch 12/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.1674 - mae: 885.1674 - val_loss: 856.1815 - val_mae: 856.1815\n",
      "Epoch 13/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.7801 - mae: 884.7801 - val_loss: 856.6052 - val_mae: 856.6052\n",
      "Epoch 14/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.6497 - mae: 885.6497 - val_loss: 858.1415 - val_mae: 858.1415\n",
      "Epoch 15/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 887.4812 - mae: 887.4812 - val_loss: 856.8090 - val_mae: 856.8090\n",
      "Epoch 16/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.3871 - mae: 885.3871 - val_loss: 863.8964 - val_mae: 863.8964\n",
      "Epoch 17/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 886.7619 - mae: 886.7619 - val_loss: 856.4631 - val_mae: 856.4631\n",
      "Epoch 18/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.3633 - mae: 885.3633 - val_loss: 859.8656 - val_mae: 859.8656\n",
      "Epoch 19/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.2737 - mae: 884.2737 - val_loss: 857.6331 - val_mae: 857.6331\n",
      "Epoch 20/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.9483 - mae: 883.9483 - val_loss: 856.1702 - val_mae: 856.1702\n",
      "Epoch 21/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.6777 - mae: 884.6777 - val_loss: 858.5338 - val_mae: 858.5338\n",
      "Epoch 22/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.6505 - mae: 882.6505 - val_loss: 856.2812 - val_mae: 856.2812\n",
      "Epoch 23/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 886.2900 - mae: 886.2900 - val_loss: 859.0435 - val_mae: 859.0435\n",
      "Epoch 24/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 886.0891 - mae: 886.0891 - val_loss: 859.4914 - val_mae: 859.4914\n",
      "Epoch 25/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.2743 - mae: 884.2743 - val_loss: 860.5775 - val_mae: 860.5775\n",
      "Epoch 26/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.8298 - mae: 883.8298 - val_loss: 856.7220 - val_mae: 856.7220\n",
      "Epoch 27/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.6322 - mae: 883.6322 - val_loss: 856.3412 - val_mae: 856.3412\n",
      "Epoch 28/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.1442 - mae: 884.1442 - val_loss: 857.2369 - val_mae: 857.2369\n",
      "Epoch 29/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.0373 - mae: 885.0373 - val_loss: 859.0858 - val_mae: 859.0858\n",
      "Epoch 30/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.9685 - mae: 883.9685 - val_loss: 858.8898 - val_mae: 858.8898\n",
      "Epoch 31/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.8234 - mae: 883.8234 - val_loss: 855.7667 - val_mae: 855.7667\n",
      "Epoch 32/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.3002 - mae: 880.3002 - val_loss: 860.4158 - val_mae: 860.4158\n",
      "Epoch 33/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.9333 - mae: 882.9333 - val_loss: 859.0161 - val_mae: 859.0161\n",
      "Epoch 34/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.3340 - mae: 883.3340 - val_loss: 863.3078 - val_mae: 863.3078\n",
      "Epoch 35/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.4888 - mae: 880.4888 - val_loss: 856.3316 - val_mae: 856.3316\n",
      "Epoch 36/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.0320 - mae: 883.0320 - val_loss: 856.9373 - val_mae: 856.9373\n",
      "Epoch 37/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.5220 - mae: 885.5220 - val_loss: 857.8590 - val_mae: 857.8590\n",
      "Epoch 38/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.1867 - mae: 883.1867 - val_loss: 857.6776 - val_mae: 857.6776\n",
      "Epoch 39/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.8372 - mae: 881.8372 - val_loss: 861.9598 - val_mae: 861.9598\n",
      "Epoch 40/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.7719 - mae: 880.7719 - val_loss: 858.1284 - val_mae: 858.1284\n",
      "Epoch 41/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.5669 - mae: 883.5669 - val_loss: 859.2414 - val_mae: 859.2414\n",
      "Epoch 42/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.0499 - mae: 882.0499 - val_loss: 857.8749 - val_mae: 857.8749\n",
      "Epoch 43/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.5457 - mae: 885.5457 - val_loss: 862.2292 - val_mae: 862.2292\n",
      "Epoch 44/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 886.2001 - mae: 886.2001 - val_loss: 855.3235 - val_mae: 855.3235\n",
      "Epoch 45/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.4297 - mae: 885.4297 - val_loss: 856.0090 - val_mae: 856.0090\n",
      "Epoch 46/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.9070 - mae: 881.9070 - val_loss: 864.1355 - val_mae: 864.1355\n",
      "Epoch 47/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.6774 - mae: 882.6774 - val_loss: 857.5314 - val_mae: 857.5314\n",
      "Epoch 48/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.5167 - mae: 885.5167 - val_loss: 855.8487 - val_mae: 855.8487\n",
      "Epoch 49/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.9197 - mae: 881.9197 - val_loss: 860.4767 - val_mae: 860.4767\n",
      "Epoch 50/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.3553 - mae: 885.3553 - val_loss: 858.2620 - val_mae: 858.2620\n",
      "Epoch 51/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.0178 - mae: 882.0178 - val_loss: 860.9536 - val_mae: 860.9536\n",
      "Epoch 52/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.1788 - mae: 882.1788 - val_loss: 861.9444 - val_mae: 861.9444\n",
      "Epoch 53/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.7623 - mae: 882.7623 - val_loss: 862.3250 - val_mae: 862.3250\n",
      "Epoch 54/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.7286 - mae: 881.7286 - val_loss: 857.0020 - val_mae: 857.0020\n",
      "Epoch 55/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 886.0366 - mae: 886.0366 - val_loss: 861.9767 - val_mae: 861.9767\n",
      "Epoch 56/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.4641 - mae: 881.4641 - val_loss: 855.6415 - val_mae: 855.6415\n",
      "Epoch 57/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.1100 - mae: 882.1100 - val_loss: 861.1489 - val_mae: 861.1489\n",
      "Epoch 58/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.6819 - mae: 884.6819 - val_loss: 865.4701 - val_mae: 865.4701\n",
      "Epoch 59/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.4468 - mae: 882.4468 - val_loss: 857.2693 - val_mae: 857.2693\n",
      "Epoch 60/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.9839 - mae: 883.9839 - val_loss: 861.3797 - val_mae: 861.3797\n",
      "Epoch 61/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.2057 - mae: 883.2057 - val_loss: 867.1219 - val_mae: 867.1219\n",
      "Epoch 62/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.7978 - mae: 883.7978 - val_loss: 862.7181 - val_mae: 862.7181\n",
      "Epoch 63/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 882.3069 - mae: 882.3069 - val_loss: 861.3849 - val_mae: 861.3849\n",
      "Epoch 64/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.1746 - mae: 882.1746 - val_loss: 859.4241 - val_mae: 859.4241\n",
      "Epoch 65/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 879.9198 - mae: 879.9198 - val_loss: 855.7098 - val_mae: 855.7098\n",
      "Epoch 66/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.8476 - mae: 881.8476 - val_loss: 860.5832 - val_mae: 860.5832\n",
      "Epoch 67/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.4450 - mae: 882.4450 - val_loss: 856.9533 - val_mae: 856.9533\n",
      "Epoch 68/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.4068 - mae: 882.4068 - val_loss: 859.0261 - val_mae: 859.0261\n",
      "Epoch 69/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.0328 - mae: 883.0328 - val_loss: 860.7248 - val_mae: 860.7248\n",
      "Epoch 70/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.6038 - mae: 882.6038 - val_loss: 863.0851 - val_mae: 863.0851\n",
      "Epoch 71/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.3892 - mae: 882.3892 - val_loss: 859.0380 - val_mae: 859.0380\n",
      "Epoch 72/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.0330 - mae: 882.0330 - val_loss: 860.6733 - val_mae: 860.6733\n",
      "Epoch 73/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.1142 - mae: 882.1142 - val_loss: 859.4079 - val_mae: 859.4079\n",
      "Epoch 74/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.3474 - mae: 882.3474 - val_loss: 860.0240 - val_mae: 860.0240\n",
      "Epoch 75/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.9025 - mae: 881.9025 - val_loss: 854.9221 - val_mae: 854.9221\n",
      "Epoch 76/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.1631 - mae: 882.1631 - val_loss: 867.4846 - val_mae: 867.4846\n",
      "Epoch 77/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.7081 - mae: 881.7081 - val_loss: 862.5925 - val_mae: 862.5925\n",
      "Epoch 78/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.3917 - mae: 880.3917 - val_loss: 861.1022 - val_mae: 861.1022\n",
      "Epoch 79/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.4517 - mae: 880.4517 - val_loss: 861.3864 - val_mae: 861.3864\n",
      "Epoch 80/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.3703 - mae: 882.3703 - val_loss: 859.6548 - val_mae: 859.6548\n",
      "Epoch 81/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.5209 - mae: 878.5209 - val_loss: 864.0654 - val_mae: 864.0654\n",
      "Epoch 82/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.0022 - mae: 884.0022 - val_loss: 858.9450 - val_mae: 858.9450\n",
      "Epoch 83/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.1451 - mae: 883.1451 - val_loss: 866.3369 - val_mae: 866.3369\n",
      "Epoch 84/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.7446 - mae: 880.7446 - val_loss: 859.9862 - val_mae: 859.9862\n",
      "Epoch 85/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.2064 - mae: 880.2064 - val_loss: 863.6833 - val_mae: 863.6833\n",
      "Epoch 86/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.6658 - mae: 881.6658 - val_loss: 858.8352 - val_mae: 858.8352\n",
      "Epoch 87/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.9235 - mae: 880.9235 - val_loss: 856.0903 - val_mae: 856.0903\n",
      "Epoch 88/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.8353 - mae: 882.8353 - val_loss: 862.5672 - val_mae: 862.5672\n",
      "Epoch 89/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.6900 - mae: 882.6900 - val_loss: 859.8431 - val_mae: 859.8431\n",
      "Epoch 90/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.1030 - mae: 879.1030 - val_loss: 857.6415 - val_mae: 857.6415\n",
      "Epoch 91/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.4256 - mae: 877.4256 - val_loss: 864.5727 - val_mae: 864.5727\n",
      "Epoch 92/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.0541 - mae: 880.0541 - val_loss: 856.8594 - val_mae: 856.8594\n",
      "Epoch 93/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.9634 - mae: 880.9634 - val_loss: 863.8354 - val_mae: 863.8354\n",
      "Epoch 94/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.3834 - mae: 881.3834 - val_loss: 858.5154 - val_mae: 858.5154\n",
      "Epoch 95/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 882.5359 - mae: 882.5359 - val_loss: 857.9576 - val_mae: 857.9576\n",
      "Epoch 96/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.4246 - mae: 883.4246 - val_loss: 863.7059 - val_mae: 863.7059\n",
      "Epoch 97/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.8643 - mae: 879.8643 - val_loss: 857.5420 - val_mae: 857.5420\n",
      "Epoch 98/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.9105 - mae: 879.9105 - val_loss: 856.9034 - val_mae: 856.9034\n",
      "Epoch 99/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 881.5552 - mae: 881.5552 - val_loss: 858.4467 - val_mae: 858.4467\n",
      "Epoch 100/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.9698 - mae: 878.9698 - val_loss: 857.1774 - val_mae: 857.1774\n",
      "Fold 2 - Loss: 857.1776, MAE: 857.1776\n",
      "236/236 [==============================] - 0s 526us/step\n",
      "Fold 3 / 5\n",
      "Epoch 1/100\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 2146.9519 - mae: 2146.9519 - val_loss: 1042.7676 - val_mae: 1042.7676\n",
      "Epoch 2/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 964.5665 - mae: 964.5665 - val_loss: 883.5596 - val_mae: 883.5596\n",
      "Epoch 3/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 894.3811 - mae: 894.3811 - val_loss: 864.1856 - val_mae: 864.1856\n",
      "Epoch 4/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 888.1775 - mae: 888.1775 - val_loss: 862.3258 - val_mae: 862.3258\n",
      "Epoch 5/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 886.7620 - mae: 886.7620 - val_loss: 861.5344 - val_mae: 861.5344\n",
      "Epoch 6/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.8850 - mae: 885.8850 - val_loss: 868.2215 - val_mae: 868.2215\n",
      "Epoch 7/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 886.9778 - mae: 886.9778 - val_loss: 860.7870 - val_mae: 860.7870\n",
      "Epoch 8/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 886.3615 - mae: 886.3615 - val_loss: 861.4549 - val_mae: 861.4549\n",
      "Epoch 9/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.9109 - mae: 884.9109 - val_loss: 861.0380 - val_mae: 861.0380\n",
      "Epoch 10/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 888.0639 - mae: 888.0639 - val_loss: 864.9372 - val_mae: 864.9372\n",
      "Epoch 11/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.0010 - mae: 883.0010 - val_loss: 861.6599 - val_mae: 861.6599\n",
      "Epoch 12/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.3145 - mae: 884.3145 - val_loss: 860.1584 - val_mae: 860.1584\n",
      "Epoch 13/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.9615 - mae: 884.9615 - val_loss: 862.0131 - val_mae: 862.0131\n",
      "Epoch 14/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.9955 - mae: 883.9955 - val_loss: 859.8578 - val_mae: 859.8578\n",
      "Epoch 15/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.1873 - mae: 885.1873 - val_loss: 866.0237 - val_mae: 866.0237\n",
      "Epoch 16/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.9978 - mae: 881.9978 - val_loss: 859.2304 - val_mae: 859.2304\n",
      "Epoch 17/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.6306 - mae: 884.6306 - val_loss: 863.8339 - val_mae: 863.8339\n",
      "Epoch 18/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.4958 - mae: 883.4958 - val_loss: 863.2151 - val_mae: 863.2151\n",
      "Epoch 19/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.1848 - mae: 884.1848 - val_loss: 864.9644 - val_mae: 864.9644\n",
      "Epoch 20/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.6650 - mae: 882.6650 - val_loss: 862.0818 - val_mae: 862.0818\n",
      "Epoch 21/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.8043 - mae: 882.8043 - val_loss: 861.6510 - val_mae: 861.6510\n",
      "Epoch 22/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.9943 - mae: 883.9943 - val_loss: 861.7632 - val_mae: 861.7632\n",
      "Epoch 23/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.8952 - mae: 883.8952 - val_loss: 865.3867 - val_mae: 865.3867\n",
      "Epoch 24/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.6512 - mae: 881.6512 - val_loss: 860.8140 - val_mae: 860.8140\n",
      "Epoch 25/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.8580 - mae: 881.8580 - val_loss: 860.1624 - val_mae: 860.1624\n",
      "Epoch 26/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.3806 - mae: 883.3806 - val_loss: 864.6638 - val_mae: 864.6638\n",
      "Epoch 27/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.8286 - mae: 883.8286 - val_loss: 864.6916 - val_mae: 864.6916\n",
      "Epoch 28/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.0109 - mae: 885.0109 - val_loss: 863.9440 - val_mae: 863.9440\n",
      "Epoch 29/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.0013 - mae: 884.0013 - val_loss: 869.0139 - val_mae: 869.0139\n",
      "Epoch 30/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.5085 - mae: 885.5085 - val_loss: 861.0901 - val_mae: 861.0901\n",
      "Epoch 31/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.5107 - mae: 884.5107 - val_loss: 866.2527 - val_mae: 866.2527\n",
      "Epoch 32/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.7272 - mae: 883.7272 - val_loss: 862.3381 - val_mae: 862.3381\n",
      "Epoch 33/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.5317 - mae: 883.5317 - val_loss: 859.4125 - val_mae: 859.4125\n",
      "Epoch 34/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.1589 - mae: 883.1589 - val_loss: 862.0554 - val_mae: 862.0554\n",
      "Epoch 35/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.5515 - mae: 880.5515 - val_loss: 858.9751 - val_mae: 858.9751\n",
      "Epoch 36/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.4584 - mae: 882.4584 - val_loss: 860.7520 - val_mae: 860.7520\n",
      "Epoch 37/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.3162 - mae: 882.3162 - val_loss: 860.5700 - val_mae: 860.5700\n",
      "Epoch 38/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.3640 - mae: 882.3640 - val_loss: 860.2189 - val_mae: 860.2189\n",
      "Epoch 39/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.4833 - mae: 883.4833 - val_loss: 860.3958 - val_mae: 860.3958\n",
      "Epoch 40/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.9437 - mae: 884.9437 - val_loss: 864.3110 - val_mae: 864.3110\n",
      "Epoch 41/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.3755 - mae: 882.3755 - val_loss: 860.5225 - val_mae: 860.5225\n",
      "Epoch 42/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.3130 - mae: 884.3130 - val_loss: 863.5747 - val_mae: 863.5747\n",
      "Epoch 43/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.7657 - mae: 882.7657 - val_loss: 860.5818 - val_mae: 860.5818\n",
      "Epoch 44/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.3996 - mae: 881.3996 - val_loss: 860.5086 - val_mae: 860.5086\n",
      "Epoch 45/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.9129 - mae: 883.9129 - val_loss: 860.0795 - val_mae: 860.0795\n",
      "Epoch 46/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.5393 - mae: 883.5393 - val_loss: 859.6591 - val_mae: 859.6591\n",
      "Epoch 47/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.5714 - mae: 881.5714 - val_loss: 860.4162 - val_mae: 860.4162\n",
      "Epoch 48/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.4128 - mae: 881.4128 - val_loss: 862.2795 - val_mae: 862.2795\n",
      "Epoch 49/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.5121 - mae: 883.5121 - val_loss: 863.7584 - val_mae: 863.7584\n",
      "Epoch 50/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.4604 - mae: 882.4604 - val_loss: 864.1944 - val_mae: 864.1944\n",
      "Epoch 51/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.5779 - mae: 881.5779 - val_loss: 863.3462 - val_mae: 863.3462\n",
      "Epoch 52/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.8655 - mae: 882.8655 - val_loss: 862.4843 - val_mae: 862.4843\n",
      "Epoch 53/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.6237 - mae: 881.6237 - val_loss: 861.5280 - val_mae: 861.5280\n",
      "Epoch 54/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.1985 - mae: 882.1985 - val_loss: 864.5129 - val_mae: 864.5129\n",
      "Epoch 55/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.9382 - mae: 881.9382 - val_loss: 858.2509 - val_mae: 858.2509\n",
      "Epoch 56/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.6621 - mae: 881.6621 - val_loss: 858.1898 - val_mae: 858.1898\n",
      "Epoch 57/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.8636 - mae: 882.8636 - val_loss: 858.7012 - val_mae: 858.7012\n",
      "Epoch 58/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.2135 - mae: 881.2135 - val_loss: 860.3569 - val_mae: 860.3569\n",
      "Epoch 59/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.1003 - mae: 882.1003 - val_loss: 861.1387 - val_mae: 861.1387\n",
      "Epoch 60/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.9957 - mae: 878.9957 - val_loss: 858.8019 - val_mae: 858.8019\n",
      "Epoch 61/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.2811 - mae: 882.2811 - val_loss: 862.1119 - val_mae: 862.1119\n",
      "Epoch 62/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.6646 - mae: 879.6646 - val_loss: 864.1448 - val_mae: 864.1448\n",
      "Epoch 63/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.0289 - mae: 881.0289 - val_loss: 858.8734 - val_mae: 858.8734\n",
      "Epoch 64/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.4306 - mae: 878.4306 - val_loss: 859.2193 - val_mae: 859.2193\n",
      "Epoch 65/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.1346 - mae: 882.1346 - val_loss: 859.0853 - val_mae: 859.0853\n",
      "Epoch 66/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.5706 - mae: 881.5706 - val_loss: 860.2560 - val_mae: 860.2560\n",
      "Epoch 67/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 881.1650 - mae: 881.1650 - val_loss: 861.5202 - val_mae: 861.5202\n",
      "Epoch 68/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.0737 - mae: 879.0737 - val_loss: 860.9864 - val_mae: 860.9864\n",
      "Epoch 69/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 880.4532 - mae: 880.4532 - val_loss: 858.2473 - val_mae: 858.2473\n",
      "Epoch 70/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 881.8180 - mae: 881.8180 - val_loss: 863.3329 - val_mae: 863.3329\n",
      "Epoch 71/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 880.7245 - mae: 880.7245 - val_loss: 857.8134 - val_mae: 857.8134\n",
      "Epoch 72/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 878.4893 - mae: 878.4893 - val_loss: 858.0034 - val_mae: 858.0034\n",
      "Epoch 73/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 881.5540 - mae: 881.5540 - val_loss: 858.4552 - val_mae: 858.4552\n",
      "Epoch 74/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.0540 - mae: 880.0540 - val_loss: 860.4080 - val_mae: 860.4080\n",
      "Epoch 75/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.9688 - mae: 881.9688 - val_loss: 859.4446 - val_mae: 859.4446\n",
      "Epoch 76/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.8568 - mae: 880.8568 - val_loss: 859.7626 - val_mae: 859.7626\n",
      "Epoch 77/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.6349 - mae: 879.6349 - val_loss: 858.4723 - val_mae: 858.4723\n",
      "Epoch 78/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.8365 - mae: 880.8365 - val_loss: 857.8680 - val_mae: 857.8680\n",
      "Epoch 79/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.6719 - mae: 881.6719 - val_loss: 857.1381 - val_mae: 857.1381\n",
      "Epoch 80/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.5201 - mae: 880.5201 - val_loss: 862.1715 - val_mae: 862.1715\n",
      "Epoch 81/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 879.6177 - mae: 879.6177 - val_loss: 858.2222 - val_mae: 858.2222\n",
      "Epoch 82/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 878.9859 - mae: 878.9859 - val_loss: 859.0421 - val_mae: 859.0421\n",
      "Epoch 83/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 881.7133 - mae: 881.7133 - val_loss: 857.8117 - val_mae: 857.8117\n",
      "Epoch 84/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 880.8107 - mae: 880.8107 - val_loss: 863.7231 - val_mae: 863.7231\n",
      "Epoch 85/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 877.1940 - mae: 877.1940 - val_loss: 857.5644 - val_mae: 857.5644\n",
      "Epoch 86/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.1731 - mae: 878.1731 - val_loss: 856.0369 - val_mae: 856.0369\n",
      "Epoch 87/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.4708 - mae: 879.4708 - val_loss: 856.8156 - val_mae: 856.8156\n",
      "Epoch 88/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.4471 - mae: 878.4471 - val_loss: 856.0490 - val_mae: 856.0490\n",
      "Epoch 89/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.9268 - mae: 878.9268 - val_loss: 860.4706 - val_mae: 860.4706\n",
      "Epoch 90/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.8339 - mae: 878.8339 - val_loss: 859.2387 - val_mae: 859.2387\n",
      "Epoch 91/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 876.7632 - mae: 876.7632 - val_loss: 857.6463 - val_mae: 857.6463\n",
      "Epoch 92/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 880.7533 - mae: 880.7533 - val_loss: 856.8244 - val_mae: 856.8244\n",
      "Epoch 93/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 880.2488 - mae: 880.2488 - val_loss: 855.7521 - val_mae: 855.7521\n",
      "Epoch 94/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 878.8641 - mae: 878.8641 - val_loss: 855.6671 - val_mae: 855.6671\n",
      "Epoch 95/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 877.9419 - mae: 877.9419 - val_loss: 859.3322 - val_mae: 859.3322\n",
      "Epoch 96/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.4510 - mae: 878.4510 - val_loss: 856.6105 - val_mae: 856.6105\n",
      "Epoch 97/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.5721 - mae: 877.5721 - val_loss: 859.2431 - val_mae: 859.2431\n",
      "Epoch 98/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 878.4586 - mae: 878.4586 - val_loss: 856.4751 - val_mae: 856.4751\n",
      "Epoch 99/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 878.5488 - mae: 878.5488 - val_loss: 856.3499 - val_mae: 856.3499\n",
      "Epoch 100/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 877.2621 - mae: 877.2621 - val_loss: 860.0831 - val_mae: 860.0831\n",
      "Fold 3 - Loss: 860.0833, MAE: 860.0833\n",
      "236/236 [==============================] - 0s 484us/step\n",
      "Fold 4 / 5\n",
      "Epoch 1/100\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 2176.4170 - mae: 2176.4170 - val_loss: 1055.0247 - val_mae: 1055.0247\n",
      "Epoch 2/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 962.5686 - mae: 962.5686 - val_loss: 895.7929 - val_mae: 895.7929\n",
      "Epoch 3/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 890.1315 - mae: 890.1315 - val_loss: 875.2124 - val_mae: 875.2124\n",
      "Epoch 4/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.3731 - mae: 884.3731 - val_loss: 872.8425 - val_mae: 872.8425\n",
      "Epoch 5/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.4025 - mae: 884.4025 - val_loss: 872.9252 - val_mae: 872.9252\n",
      "Epoch 6/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 882.6850 - mae: 882.6850 - val_loss: 877.6823 - val_mae: 877.6823\n",
      "Epoch 7/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 884.0000 - mae: 884.0000 - val_loss: 878.4520 - val_mae: 878.4520\n",
      "Epoch 8/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 883.1334 - mae: 883.1334 - val_loss: 871.3498 - val_mae: 871.3498\n",
      "Epoch 9/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 882.9726 - mae: 882.9726 - val_loss: 875.7375 - val_mae: 875.7375\n",
      "Epoch 10/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 884.4773 - mae: 884.4773 - val_loss: 877.9716 - val_mae: 877.9716\n",
      "Epoch 11/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 882.8353 - mae: 882.8353 - val_loss: 871.6859 - val_mae: 871.6859\n",
      "Epoch 12/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.0083 - mae: 880.0083 - val_loss: 873.6129 - val_mae: 873.6129\n",
      "Epoch 13/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 885.2830 - mae: 885.2830 - val_loss: 870.5827 - val_mae: 870.5827\n",
      "Epoch 14/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 882.3145 - mae: 882.3145 - val_loss: 874.3811 - val_mae: 874.3811\n",
      "Epoch 15/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 881.1481 - mae: 881.1481 - val_loss: 874.0613 - val_mae: 874.0613\n",
      "Epoch 16/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 880.8318 - mae: 880.8318 - val_loss: 874.5493 - val_mae: 874.5493\n",
      "Epoch 17/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 878.5635 - mae: 878.5635 - val_loss: 870.7975 - val_mae: 870.7975\n",
      "Epoch 18/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 880.7263 - mae: 880.7263 - val_loss: 873.0860 - val_mae: 873.0860\n",
      "Epoch 19/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 880.0821 - mae: 880.0821 - val_loss: 870.4370 - val_mae: 870.4370\n",
      "Epoch 20/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 882.0169 - mae: 882.0169 - val_loss: 870.5427 - val_mae: 870.5427\n",
      "Epoch 21/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 879.9321 - mae: 879.9321 - val_loss: 870.4118 - val_mae: 870.4118\n",
      "Epoch 22/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 880.8307 - mae: 880.8307 - val_loss: 872.4777 - val_mae: 872.4777\n",
      "Epoch 23/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 879.5651 - mae: 879.5651 - val_loss: 873.4182 - val_mae: 873.4182\n",
      "Epoch 24/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 880.4012 - mae: 880.4012 - val_loss: 869.6641 - val_mae: 869.6641\n",
      "Epoch 25/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 880.9648 - mae: 880.9648 - val_loss: 876.1017 - val_mae: 876.1017\n",
      "Epoch 26/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 880.6392 - mae: 880.6392 - val_loss: 872.7674 - val_mae: 872.7674\n",
      "Epoch 27/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 881.1626 - mae: 881.1626 - val_loss: 877.2798 - val_mae: 877.2798\n",
      "Epoch 28/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 881.4799 - mae: 881.4799 - val_loss: 872.0063 - val_mae: 872.0063\n",
      "Epoch 29/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 881.3896 - mae: 881.3896 - val_loss: 872.4717 - val_mae: 872.4717\n",
      "Epoch 30/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 880.3855 - mae: 880.3855 - val_loss: 870.3602 - val_mae: 870.3602\n",
      "Epoch 31/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 877.5610 - mae: 877.5610 - val_loss: 872.5170 - val_mae: 872.5170\n",
      "Epoch 32/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 879.6099 - mae: 879.6099 - val_loss: 872.5307 - val_mae: 872.5307\n",
      "Epoch 33/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 880.5172 - mae: 880.5172 - val_loss: 877.8983 - val_mae: 877.8983\n",
      "Epoch 34/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 881.0995 - mae: 881.0995 - val_loss: 873.0076 - val_mae: 873.0076\n",
      "Epoch 35/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 879.3548 - mae: 879.3548 - val_loss: 873.3577 - val_mae: 873.3577\n",
      "Epoch 36/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 878.9854 - mae: 878.9854 - val_loss: 869.9689 - val_mae: 869.9689\n",
      "Epoch 37/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 879.3212 - mae: 879.3212 - val_loss: 869.6073 - val_mae: 869.6073\n",
      "Epoch 38/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.3580 - mae: 878.3580 - val_loss: 876.7835 - val_mae: 876.7835\n",
      "Epoch 39/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.4891 - mae: 877.4891 - val_loss: 872.2200 - val_mae: 872.2200\n",
      "Epoch 40/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.2404 - mae: 878.2404 - val_loss: 874.4969 - val_mae: 874.4969\n",
      "Epoch 41/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 878.2491 - mae: 878.2491 - val_loss: 871.2167 - val_mae: 871.2167\n",
      "Epoch 42/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 878.9597 - mae: 878.9597 - val_loss: 871.2167 - val_mae: 871.2167\n",
      "Epoch 43/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 877.5051 - mae: 877.5051 - val_loss: 870.7566 - val_mae: 870.7566\n",
      "Epoch 44/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 879.1471 - mae: 879.1471 - val_loss: 878.3274 - val_mae: 878.3274\n",
      "Epoch 45/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 877.9205 - mae: 877.9205 - val_loss: 870.8050 - val_mae: 870.8050\n",
      "Epoch 46/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.5375 - mae: 879.5375 - val_loss: 874.1922 - val_mae: 874.1922\n",
      "Epoch 47/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.9657 - mae: 877.9657 - val_loss: 872.0970 - val_mae: 872.0970\n",
      "Epoch 48/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.6313 - mae: 878.6313 - val_loss: 872.6082 - val_mae: 872.6082\n",
      "Epoch 49/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.0081 - mae: 879.0081 - val_loss: 872.2619 - val_mae: 872.2619\n",
      "Epoch 50/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.1916 - mae: 880.1916 - val_loss: 872.1035 - val_mae: 872.1035\n",
      "Epoch 51/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.1138 - mae: 880.1138 - val_loss: 877.0342 - val_mae: 877.0342\n",
      "Epoch 52/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 875.8828 - mae: 875.8828 - val_loss: 873.3293 - val_mae: 873.3293\n",
      "Epoch 53/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.6580 - mae: 878.6580 - val_loss: 877.7872 - val_mae: 877.7872\n",
      "Epoch 54/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.3159 - mae: 879.3159 - val_loss: 874.5704 - val_mae: 874.5704\n",
      "Epoch 55/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.8175 - mae: 877.8175 - val_loss: 870.2604 - val_mae: 870.2604\n",
      "Epoch 56/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.2643 - mae: 879.2643 - val_loss: 873.8596 - val_mae: 873.8596\n",
      "Epoch 57/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.0490 - mae: 880.0490 - val_loss: 868.8685 - val_mae: 868.8685\n",
      "Epoch 58/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.7344 - mae: 877.7344 - val_loss: 872.1022 - val_mae: 872.1022\n",
      "Epoch 59/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.1487 - mae: 879.1487 - val_loss: 872.9721 - val_mae: 872.9721\n",
      "Epoch 60/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.6910 - mae: 878.6910 - val_loss: 871.1823 - val_mae: 871.1823\n",
      "Epoch 61/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.5173 - mae: 878.5173 - val_loss: 870.5210 - val_mae: 870.5210\n",
      "Epoch 62/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.1488 - mae: 879.1488 - val_loss: 875.5568 - val_mae: 875.5568\n",
      "Epoch 63/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.6642 - mae: 877.6642 - val_loss: 870.7756 - val_mae: 870.7756\n",
      "Epoch 64/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.1125 - mae: 877.1125 - val_loss: 871.5837 - val_mae: 871.5837\n",
      "Epoch 65/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.8434 - mae: 879.8434 - val_loss: 871.5278 - val_mae: 871.5278\n",
      "Epoch 66/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.6496 - mae: 877.6496 - val_loss: 869.7036 - val_mae: 869.7036\n",
      "Epoch 67/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.6298 - mae: 877.6298 - val_loss: 876.5311 - val_mae: 876.5311\n",
      "Epoch 68/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.7437 - mae: 877.7437 - val_loss: 876.4430 - val_mae: 876.4430\n",
      "Epoch 69/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.8611 - mae: 877.8611 - val_loss: 873.7790 - val_mae: 873.7790\n",
      "Epoch 70/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.5042 - mae: 877.5042 - val_loss: 875.4883 - val_mae: 875.4883\n",
      "Epoch 71/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.7700 - mae: 876.7700 - val_loss: 869.6278 - val_mae: 869.6278\n",
      "Epoch 72/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.3271 - mae: 877.3271 - val_loss: 871.5067 - val_mae: 871.5067\n",
      "Epoch 73/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.3508 - mae: 879.3508 - val_loss: 872.8021 - val_mae: 872.8021\n",
      "Epoch 74/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.0240 - mae: 878.0240 - val_loss: 873.4905 - val_mae: 873.4905\n",
      "Epoch 75/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 878.9507 - mae: 878.9507 - val_loss: 869.8476 - val_mae: 869.8476\n",
      "Epoch 76/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 876.5964 - mae: 876.5964 - val_loss: 873.0104 - val_mae: 873.0104\n",
      "Epoch 77/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 876.5270 - mae: 876.5270 - val_loss: 871.6910 - val_mae: 871.6910\n",
      "Epoch 78/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 875.2749 - mae: 875.2749 - val_loss: 868.5436 - val_mae: 868.5436\n",
      "Epoch 79/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 879.2149 - mae: 879.2149 - val_loss: 867.8162 - val_mae: 867.8162\n",
      "Epoch 80/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.3699 - mae: 878.3699 - val_loss: 871.2079 - val_mae: 871.2079\n",
      "Epoch 81/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.3444 - mae: 877.3444 - val_loss: 868.8462 - val_mae: 868.8462\n",
      "Epoch 82/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.7820 - mae: 877.7820 - val_loss: 875.8909 - val_mae: 875.8909\n",
      "Epoch 83/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.7733 - mae: 877.7733 - val_loss: 872.4131 - val_mae: 872.4131\n",
      "Epoch 84/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.4845 - mae: 876.4845 - val_loss: 869.6326 - val_mae: 869.6326\n",
      "Epoch 85/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.0193 - mae: 877.0193 - val_loss: 870.4342 - val_mae: 870.4342\n",
      "Epoch 86/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.7982 - mae: 877.7982 - val_loss: 870.7256 - val_mae: 870.7256\n",
      "Epoch 87/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 876.7988 - mae: 876.7988 - val_loss: 872.8964 - val_mae: 872.8964\n",
      "Epoch 88/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 874.6761 - mae: 874.6761 - val_loss: 868.5836 - val_mae: 868.5836\n",
      "Epoch 89/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 876.1513 - mae: 876.1513 - val_loss: 871.3270 - val_mae: 871.3270\n",
      "Epoch 90/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.5475 - mae: 876.5475 - val_loss: 873.5914 - val_mae: 873.5914\n",
      "Epoch 91/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 875.2173 - mae: 875.2173 - val_loss: 872.4675 - val_mae: 872.4675\n",
      "Epoch 92/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.4141 - mae: 876.4141 - val_loss: 869.8083 - val_mae: 869.8083\n",
      "Epoch 93/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.1937 - mae: 877.1937 - val_loss: 872.7628 - val_mae: 872.7628\n",
      "Epoch 94/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 875.0845 - mae: 875.0845 - val_loss: 868.1693 - val_mae: 868.1693\n",
      "Epoch 95/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 876.0013 - mae: 876.0013 - val_loss: 876.4456 - val_mae: 876.4456\n",
      "Epoch 96/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 877.9733 - mae: 877.9733 - val_loss: 871.5275 - val_mae: 871.5275\n",
      "Epoch 97/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 875.1195 - mae: 875.1195 - val_loss: 870.7126 - val_mae: 870.7126\n",
      "Epoch 98/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 875.6414 - mae: 875.6414 - val_loss: 869.5504 - val_mae: 869.5504\n",
      "Epoch 99/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 877.2189 - mae: 877.2189 - val_loss: 870.2912 - val_mae: 870.2912\n",
      "Epoch 100/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 873.1969 - mae: 873.1969 - val_loss: 866.7255 - val_mae: 866.7255\n",
      "Fold 4 - Loss: 866.7256, MAE: 866.7256\n",
      "236/236 [==============================] - 0s 509us/step\n",
      "Fold 5 / 5\n",
      "Epoch 1/100\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 2133.2632 - mae: 2133.2632 - val_loss: 1032.0286 - val_mae: 1032.0286\n",
      "Epoch 2/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 967.0544 - mae: 967.0544 - val_loss: 865.7815 - val_mae: 865.7815\n",
      "Epoch 3/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 895.3799 - mae: 895.3799 - val_loss: 850.1614 - val_mae: 850.1614\n",
      "Epoch 4/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 889.2549 - mae: 889.2549 - val_loss: 846.8397 - val_mae: 846.8397\n",
      "Epoch 5/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 889.8032 - mae: 889.8032 - val_loss: 847.2522 - val_mae: 847.2522\n",
      "Epoch 6/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 888.7256 - mae: 888.7256 - val_loss: 850.0374 - val_mae: 850.0374\n",
      "Epoch 7/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 886.8896 - mae: 886.8896 - val_loss: 849.1231 - val_mae: 849.1231\n",
      "Epoch 8/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 886.0507 - mae: 886.0507 - val_loss: 845.8745 - val_mae: 845.8745\n",
      "Epoch 9/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 888.8544 - mae: 888.8544 - val_loss: 847.7730 - val_mae: 847.7730\n",
      "Epoch 10/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 889.0052 - mae: 889.0052 - val_loss: 845.8083 - val_mae: 845.8083\n",
      "Epoch 11/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 887.9887 - mae: 887.9887 - val_loss: 844.6140 - val_mae: 844.6140\n",
      "Epoch 12/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 887.5739 - mae: 887.5739 - val_loss: 846.8741 - val_mae: 846.8741\n",
      "Epoch 13/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.4735 - mae: 884.4735 - val_loss: 849.7723 - val_mae: 849.7723\n",
      "Epoch 14/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 888.5377 - mae: 888.5377 - val_loss: 850.3323 - val_mae: 850.3323\n",
      "Epoch 15/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 884.4716 - mae: 884.4716 - val_loss: 845.7349 - val_mae: 845.7349\n",
      "Epoch 16/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 883.6068 - mae: 883.6068 - val_loss: 846.8915 - val_mae: 846.8915\n",
      "Epoch 17/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 890.5092 - mae: 890.5092 - val_loss: 845.3475 - val_mae: 845.3475\n",
      "Epoch 18/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 887.5997 - mae: 887.5997 - val_loss: 845.0264 - val_mae: 845.0264\n",
      "Epoch 19/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 887.6386 - mae: 887.6386 - val_loss: 845.5974 - val_mae: 845.5974\n",
      "Epoch 20/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 887.3490 - mae: 887.3490 - val_loss: 850.9142 - val_mae: 850.9142\n",
      "Epoch 21/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 886.3430 - mae: 886.3430 - val_loss: 846.7708 - val_mae: 846.7708\n",
      "Epoch 22/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 888.8383 - mae: 888.8383 - val_loss: 844.0277 - val_mae: 844.0277\n",
      "Epoch 23/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 886.8234 - mae: 886.8234 - val_loss: 845.2271 - val_mae: 845.2271\n",
      "Epoch 24/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 886.1631 - mae: 886.1631 - val_loss: 846.3522 - val_mae: 846.3522\n",
      "Epoch 25/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.6530 - mae: 885.6530 - val_loss: 844.6497 - val_mae: 844.6497\n",
      "Epoch 26/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 888.2571 - mae: 888.2571 - val_loss: 842.5135 - val_mae: 842.5135\n",
      "Epoch 27/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 886.9319 - mae: 886.9319 - val_loss: 842.1886 - val_mae: 842.1886\n",
      "Epoch 28/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 888.3370 - mae: 888.3370 - val_loss: 842.7772 - val_mae: 842.7772\n",
      "Epoch 29/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 887.0951 - mae: 887.0951 - val_loss: 843.3179 - val_mae: 843.3179\n",
      "Epoch 30/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 888.5345 - mae: 888.5345 - val_loss: 845.2433 - val_mae: 845.2433\n",
      "Epoch 31/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 886.5353 - mae: 886.5353 - val_loss: 844.2448 - val_mae: 844.2448\n",
      "Epoch 32/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.4216 - mae: 885.4216 - val_loss: 844.8088 - val_mae: 844.8088\n",
      "Epoch 33/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.4855 - mae: 884.4855 - val_loss: 848.3011 - val_mae: 848.3011\n",
      "Epoch 34/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 887.6525 - mae: 887.6525 - val_loss: 848.6913 - val_mae: 848.6913\n",
      "Epoch 35/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 887.9376 - mae: 887.9376 - val_loss: 843.4147 - val_mae: 843.4147\n",
      "Epoch 36/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 887.9248 - mae: 887.9248 - val_loss: 845.3090 - val_mae: 845.3090\n",
      "Epoch 37/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 885.8078 - mae: 885.8078 - val_loss: 843.7182 - val_mae: 843.7182\n",
      "Epoch 38/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 889.3873 - mae: 889.3873 - val_loss: 847.9075 - val_mae: 847.9075\n",
      "Epoch 39/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 885.2418 - mae: 885.2418 - val_loss: 842.9978 - val_mae: 842.9978\n",
      "Epoch 40/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 886.8341 - mae: 886.8341 - val_loss: 844.0726 - val_mae: 844.0726\n",
      "Epoch 41/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 884.1492 - mae: 884.1492 - val_loss: 842.5375 - val_mae: 842.5375\n",
      "Epoch 42/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 886.9770 - mae: 886.9770 - val_loss: 843.9322 - val_mae: 843.9322\n",
      "Epoch 43/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 887.0513 - mae: 887.0513 - val_loss: 846.0498 - val_mae: 846.0498\n",
      "Epoch 44/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 886.9236 - mae: 886.9236 - val_loss: 844.5610 - val_mae: 844.5610\n",
      "Epoch 45/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.7535 - mae: 884.7535 - val_loss: 845.8580 - val_mae: 845.8580\n",
      "Epoch 46/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 887.6227 - mae: 887.6227 - val_loss: 845.3019 - val_mae: 845.3019\n",
      "Epoch 47/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 885.2576 - mae: 885.2576 - val_loss: 843.8911 - val_mae: 843.8911\n",
      "Epoch 48/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 885.7531 - mae: 885.7531 - val_loss: 847.0156 - val_mae: 847.0156\n",
      "Epoch 49/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 884.6061 - mae: 884.6061 - val_loss: 843.0958 - val_mae: 843.0958\n",
      "Epoch 50/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 884.8503 - mae: 884.8503 - val_loss: 843.1795 - val_mae: 843.1795\n",
      "Epoch 51/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 889.1445 - mae: 889.1445 - val_loss: 845.0023 - val_mae: 845.0023\n",
      "Epoch 52/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 887.8278 - mae: 887.8278 - val_loss: 845.7133 - val_mae: 845.7133\n",
      "Epoch 53/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.5891 - mae: 885.5891 - val_loss: 843.6688 - val_mae: 843.6688\n",
      "Epoch 54/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 887.3963 - mae: 887.3963 - val_loss: 844.1685 - val_mae: 844.1685\n",
      "Epoch 55/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 885.6096 - mae: 885.6096 - val_loss: 843.3137 - val_mae: 843.3137\n",
      "Epoch 56/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 887.5306 - mae: 887.5306 - val_loss: 842.9490 - val_mae: 842.9490\n",
      "Epoch 57/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.5458 - mae: 884.5458 - val_loss: 843.9921 - val_mae: 843.9921\n",
      "Epoch 58/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 886.3823 - mae: 886.3823 - val_loss: 843.9860 - val_mae: 843.9860\n",
      "Epoch 59/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 885.0381 - mae: 885.0381 - val_loss: 848.1332 - val_mae: 848.1332\n",
      "Epoch 60/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 884.6693 - mae: 884.6693 - val_loss: 844.3999 - val_mae: 844.3999\n",
      "Epoch 61/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 884.4071 - mae: 884.4071 - val_loss: 842.5209 - val_mae: 842.5209\n",
      "Epoch 62/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 883.8823 - mae: 883.8823 - val_loss: 845.5535 - val_mae: 845.5535\n",
      "Epoch 63/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.3751 - mae: 884.3751 - val_loss: 846.4552 - val_mae: 846.4552\n",
      "Epoch 64/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 887.5665 - mae: 887.5665 - val_loss: 848.9042 - val_mae: 848.9042\n",
      "Epoch 65/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 884.4106 - mae: 884.4106 - val_loss: 845.0146 - val_mae: 845.0146\n",
      "Epoch 66/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 884.7663 - mae: 884.7663 - val_loss: 842.7599 - val_mae: 842.7599\n",
      "Epoch 67/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 887.0449 - mae: 887.0449 - val_loss: 845.7474 - val_mae: 845.7474\n",
      "Epoch 68/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 886.3419 - mae: 886.3419 - val_loss: 843.1906 - val_mae: 843.1906\n",
      "Epoch 69/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 886.9852 - mae: 886.9852 - val_loss: 844.2683 - val_mae: 844.2683\n",
      "Epoch 70/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 887.9584 - mae: 887.9584 - val_loss: 848.0905 - val_mae: 848.0905\n",
      "Epoch 71/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 886.0500 - mae: 886.0500 - val_loss: 845.8621 - val_mae: 845.8621\n",
      "Epoch 72/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 886.0891 - mae: 886.0891 - val_loss: 843.5986 - val_mae: 843.5986\n",
      "Epoch 73/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.5328 - mae: 884.5328 - val_loss: 843.7545 - val_mae: 843.7545\n",
      "Epoch 74/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.1087 - mae: 884.1087 - val_loss: 848.6227 - val_mae: 848.6227\n",
      "Epoch 75/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.8105 - mae: 884.8105 - val_loss: 841.4719 - val_mae: 841.4719\n",
      "Epoch 76/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 883.0775 - mae: 883.0775 - val_loss: 841.4747 - val_mae: 841.4747\n",
      "Epoch 77/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 884.4188 - mae: 884.4188 - val_loss: 845.8116 - val_mae: 845.8116\n",
      "Epoch 78/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 885.8732 - mae: 885.8732 - val_loss: 842.4586 - val_mae: 842.4586\n",
      "Epoch 79/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.4604 - mae: 884.4604 - val_loss: 842.5740 - val_mae: 842.5740\n",
      "Epoch 80/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.8528 - mae: 884.8528 - val_loss: 846.1569 - val_mae: 846.1569\n",
      "Epoch 81/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.9254 - mae: 884.9254 - val_loss: 840.8802 - val_mae: 840.8802\n",
      "Epoch 82/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.3743 - mae: 884.3743 - val_loss: 842.0891 - val_mae: 842.0891\n",
      "Epoch 83/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 886.3688 - mae: 886.3688 - val_loss: 841.5558 - val_mae: 841.5558\n",
      "Epoch 84/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.9822 - mae: 883.9822 - val_loss: 843.3477 - val_mae: 843.3477\n",
      "Epoch 85/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.9851 - mae: 884.9851 - val_loss: 840.4559 - val_mae: 840.4559\n",
      "Epoch 86/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.8693 - mae: 881.8693 - val_loss: 842.0859 - val_mae: 842.0859\n",
      "Epoch 87/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.1553 - mae: 884.1553 - val_loss: 842.0037 - val_mae: 842.0037\n",
      "Epoch 88/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 884.4043 - mae: 884.4043 - val_loss: 841.0010 - val_mae: 841.0010\n",
      "Epoch 89/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 883.7246 - mae: 883.7246 - val_loss: 840.1722 - val_mae: 840.1722\n",
      "Epoch 90/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 881.1844 - mae: 881.1844 - val_loss: 839.7128 - val_mae: 839.7128\n",
      "Epoch 91/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 883.3796 - mae: 883.3796 - val_loss: 840.4818 - val_mae: 840.4818\n",
      "Epoch 92/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.2708 - mae: 883.2708 - val_loss: 839.3134 - val_mae: 839.3134\n",
      "Epoch 93/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.5012 - mae: 882.5012 - val_loss: 844.7506 - val_mae: 844.7506\n",
      "Epoch 94/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.8994 - mae: 882.8994 - val_loss: 844.7410 - val_mae: 844.7410\n",
      "Epoch 95/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 882.7920 - mae: 882.7920 - val_loss: 840.3611 - val_mae: 840.3611\n",
      "Epoch 96/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 882.1331 - mae: 882.1331 - val_loss: 839.7803 - val_mae: 839.7803\n",
      "Epoch 97/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 884.6300 - mae: 884.6300 - val_loss: 838.8184 - val_mae: 838.8184\n",
      "Epoch 98/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.2582 - mae: 882.2582 - val_loss: 839.6664 - val_mae: 839.6664\n",
      "Epoch 99/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.7830 - mae: 884.7830 - val_loss: 839.0612 - val_mae: 839.0612\n",
      "Epoch 100/100\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 879.9162 - mae: 879.9162 - val_loss: 841.0627 - val_mae: 841.0627\n",
      "Fold 5 - Loss: 841.0627, MAE: 841.0627\n",
      "236/236 [==============================] - 0s 422us/step\n",
      "[각 Fold별 평균 성능]\n",
      "mae : 856.00324\n",
      "mape : 0.34412000000000004\n",
      "mse : 1222870.35104\n",
      "rmse : 1105.7787\n",
      "\n",
      "--- Cross Validation: 7-Fold 시작 ---\n",
      "\n",
      "Fold 1 / 7\n",
      "Epoch 1/100\n",
      "253/253 [==============================] - 1s 1ms/step - loss: 2179.1287 - mae: 2179.1287 - val_loss: 1054.3179 - val_mae: 1054.3179\n",
      "Epoch 2/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 968.1085 - mae: 968.1085 - val_loss: 871.9147 - val_mae: 871.9147\n",
      "Epoch 3/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 894.9780 - mae: 894.9780 - val_loss: 863.3128 - val_mae: 863.3128\n",
      "Epoch 4/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 891.6893 - mae: 891.6893 - val_loss: 858.2709 - val_mae: 858.2709\n",
      "Epoch 5/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 890.5130 - mae: 890.5130 - val_loss: 854.3166 - val_mae: 854.3166\n",
      "Epoch 6/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 888.8942 - mae: 888.8942 - val_loss: 855.1622 - val_mae: 855.1622\n",
      "Epoch 7/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 887.0016 - mae: 887.0016 - val_loss: 855.7165 - val_mae: 855.7165\n",
      "Epoch 8/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 889.1117 - mae: 889.1117 - val_loss: 851.0270 - val_mae: 851.0270\n",
      "Epoch 9/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 887.1953 - mae: 887.1953 - val_loss: 851.7490 - val_mae: 851.7490\n",
      "Epoch 10/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 889.6981 - mae: 889.6981 - val_loss: 857.6821 - val_mae: 857.6821\n",
      "Epoch 11/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 888.3215 - mae: 888.3215 - val_loss: 852.7611 - val_mae: 852.7611\n",
      "Epoch 12/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 888.1904 - mae: 888.1904 - val_loss: 855.7554 - val_mae: 855.7554\n",
      "Epoch 13/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 885.7488 - mae: 885.7488 - val_loss: 856.3019 - val_mae: 856.3019\n",
      "Epoch 14/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 887.1981 - mae: 887.1981 - val_loss: 851.6177 - val_mae: 851.6177\n",
      "Epoch 15/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 888.1669 - mae: 888.1669 - val_loss: 851.7493 - val_mae: 851.7493\n",
      "Epoch 16/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 888.4039 - mae: 888.4039 - val_loss: 854.2252 - val_mae: 854.2252\n",
      "Epoch 17/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 887.4177 - mae: 887.4177 - val_loss: 853.5916 - val_mae: 853.5916\n",
      "Epoch 18/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 887.1460 - mae: 887.1460 - val_loss: 854.8499 - val_mae: 854.8499\n",
      "Epoch 19/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 885.8033 - mae: 885.8033 - val_loss: 855.6722 - val_mae: 855.6722\n",
      "Epoch 20/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 886.1241 - mae: 886.1241 - val_loss: 853.2098 - val_mae: 853.2098\n",
      "Epoch 21/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 886.3873 - mae: 886.3873 - val_loss: 853.9409 - val_mae: 853.9409\n",
      "Epoch 22/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 886.2409 - mae: 886.2409 - val_loss: 851.7905 - val_mae: 851.7905\n",
      "Epoch 23/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 884.7479 - mae: 884.7479 - val_loss: 850.3778 - val_mae: 850.3778\n",
      "Epoch 24/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 887.0200 - mae: 887.0200 - val_loss: 852.9904 - val_mae: 852.9904\n",
      "Epoch 25/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 887.5941 - mae: 887.5941 - val_loss: 851.7031 - val_mae: 851.7031\n",
      "Epoch 26/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 887.0876 - mae: 887.0876 - val_loss: 851.7511 - val_mae: 851.7511\n",
      "Epoch 27/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 884.9457 - mae: 884.9457 - val_loss: 852.1278 - val_mae: 852.1278\n",
      "Epoch 28/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 885.9352 - mae: 885.9352 - val_loss: 850.2410 - val_mae: 850.2410\n",
      "Epoch 29/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 885.0285 - mae: 885.0285 - val_loss: 855.6761 - val_mae: 855.6761\n",
      "Epoch 30/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 887.0856 - mae: 887.0856 - val_loss: 855.4460 - val_mae: 855.4460\n",
      "Epoch 31/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 885.9252 - mae: 885.9252 - val_loss: 854.9758 - val_mae: 854.9758\n",
      "Epoch 32/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 885.7364 - mae: 885.7364 - val_loss: 855.4783 - val_mae: 855.4783\n",
      "Epoch 33/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 885.1280 - mae: 885.1280 - val_loss: 851.6972 - val_mae: 851.6972\n",
      "Epoch 34/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.8881 - mae: 883.8881 - val_loss: 857.0278 - val_mae: 857.0278\n",
      "Epoch 35/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 887.2940 - mae: 887.2940 - val_loss: 855.2979 - val_mae: 855.2979\n",
      "Epoch 36/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.2600 - mae: 883.2600 - val_loss: 852.0435 - val_mae: 852.0435\n",
      "Epoch 37/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 885.5355 - mae: 885.5355 - val_loss: 852.0831 - val_mae: 852.0831\n",
      "Epoch 38/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 884.2905 - mae: 884.2905 - val_loss: 857.7969 - val_mae: 857.7969\n",
      "Epoch 39/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 887.5526 - mae: 887.5526 - val_loss: 850.6578 - val_mae: 850.6578\n",
      "Epoch 40/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 885.8137 - mae: 885.8137 - val_loss: 852.3010 - val_mae: 852.3010\n",
      "Epoch 41/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 886.9832 - mae: 886.9832 - val_loss: 850.9165 - val_mae: 850.9165\n",
      "Epoch 42/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 885.6378 - mae: 885.6378 - val_loss: 852.4347 - val_mae: 852.4347\n",
      "Epoch 43/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 886.6525 - mae: 886.6525 - val_loss: 854.8886 - val_mae: 854.8886\n",
      "Epoch 44/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 884.7395 - mae: 884.7395 - val_loss: 849.5628 - val_mae: 849.5628\n",
      "Epoch 45/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 885.4768 - mae: 885.4768 - val_loss: 850.4752 - val_mae: 850.4752\n",
      "Epoch 46/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.7927 - mae: 883.7927 - val_loss: 853.7664 - val_mae: 853.7664\n",
      "Epoch 47/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 886.1086 - mae: 886.1086 - val_loss: 852.5705 - val_mae: 852.5705\n",
      "Epoch 48/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 884.6214 - mae: 884.6214 - val_loss: 853.8688 - val_mae: 853.8688\n",
      "Epoch 49/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 886.8497 - mae: 886.8497 - val_loss: 851.6568 - val_mae: 851.6568\n",
      "Epoch 50/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 886.6964 - mae: 886.6964 - val_loss: 851.7314 - val_mae: 851.7314\n",
      "Epoch 51/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 886.2114 - mae: 886.2114 - val_loss: 852.4574 - val_mae: 852.4574\n",
      "Epoch 52/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 885.2773 - mae: 885.2773 - val_loss: 850.6420 - val_mae: 850.6420\n",
      "Epoch 53/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 884.8450 - mae: 884.8450 - val_loss: 855.4091 - val_mae: 855.4091\n",
      "Epoch 54/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.9094 - mae: 883.9094 - val_loss: 851.7383 - val_mae: 851.7383\n",
      "Epoch 55/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 886.9225 - mae: 886.9225 - val_loss: 851.7147 - val_mae: 851.7147\n",
      "Epoch 56/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 886.4705 - mae: 886.4705 - val_loss: 853.2943 - val_mae: 853.2943\n",
      "Epoch 57/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 884.9624 - mae: 884.9624 - val_loss: 852.3805 - val_mae: 852.3805\n",
      "Epoch 58/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 886.7379 - mae: 886.7379 - val_loss: 851.2617 - val_mae: 851.2617\n",
      "Epoch 59/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 886.4892 - mae: 886.4892 - val_loss: 851.1602 - val_mae: 851.1602\n",
      "Epoch 60/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 885.7099 - mae: 885.7099 - val_loss: 854.9286 - val_mae: 854.9286\n",
      "Epoch 61/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 885.4208 - mae: 885.4208 - val_loss: 855.8156 - val_mae: 855.8156\n",
      "Epoch 62/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 885.2797 - mae: 885.2797 - val_loss: 851.9912 - val_mae: 851.9912\n",
      "Epoch 63/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 885.2284 - mae: 885.2284 - val_loss: 851.3250 - val_mae: 851.3250\n",
      "Epoch 64/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 884.5285 - mae: 884.5285 - val_loss: 851.5325 - val_mae: 851.5325\n",
      "Epoch 65/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 883.9932 - mae: 883.9932 - val_loss: 852.0826 - val_mae: 852.0826\n",
      "Epoch 66/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 884.8866 - mae: 884.8866 - val_loss: 850.1608 - val_mae: 850.1608\n",
      "Epoch 67/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 883.8991 - mae: 883.8991 - val_loss: 850.8201 - val_mae: 850.8201\n",
      "Epoch 68/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.3625 - mae: 881.3625 - val_loss: 849.2230 - val_mae: 849.2230\n",
      "Epoch 69/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 884.6830 - mae: 884.6830 - val_loss: 849.7717 - val_mae: 849.7717\n",
      "Epoch 70/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.2882 - mae: 883.2882 - val_loss: 851.2232 - val_mae: 851.2232\n",
      "Epoch 71/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 884.9725 - mae: 884.9725 - val_loss: 854.6119 - val_mae: 854.6119\n",
      "Epoch 72/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 885.2133 - mae: 885.2133 - val_loss: 851.6365 - val_mae: 851.6365\n",
      "Epoch 73/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 884.1891 - mae: 884.1891 - val_loss: 849.2657 - val_mae: 849.2657\n",
      "Epoch 74/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 884.5249 - mae: 884.5249 - val_loss: 851.0563 - val_mae: 851.0563\n",
      "Epoch 75/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 884.1154 - mae: 884.1154 - val_loss: 848.9651 - val_mae: 848.9651\n",
      "Epoch 76/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 885.8799 - mae: 885.8799 - val_loss: 851.4624 - val_mae: 851.4624\n",
      "Epoch 77/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.3967 - mae: 882.3967 - val_loss: 850.1624 - val_mae: 850.1624\n",
      "Epoch 78/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.5866 - mae: 883.5866 - val_loss: 851.4808 - val_mae: 851.4808\n",
      "Epoch 79/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.9496 - mae: 881.9496 - val_loss: 854.0789 - val_mae: 854.0789\n",
      "Epoch 80/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.8198 - mae: 882.8198 - val_loss: 855.1513 - val_mae: 855.1513\n",
      "Epoch 81/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.6420 - mae: 882.6420 - val_loss: 849.2755 - val_mae: 849.2755\n",
      "Epoch 82/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 884.2518 - mae: 884.2518 - val_loss: 847.3924 - val_mae: 847.3924\n",
      "Epoch 83/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 885.3901 - mae: 885.3901 - val_loss: 847.5279 - val_mae: 847.5279\n",
      "Epoch 84/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.1317 - mae: 882.1317 - val_loss: 849.9797 - val_mae: 849.9797\n",
      "Epoch 85/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 884.8699 - mae: 884.8699 - val_loss: 847.0630 - val_mae: 847.0630\n",
      "Epoch 86/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 884.5535 - mae: 884.5535 - val_loss: 848.7113 - val_mae: 848.7113\n",
      "Epoch 87/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.7679 - mae: 883.7679 - val_loss: 847.5756 - val_mae: 847.5756\n",
      "Epoch 88/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.6480 - mae: 882.6480 - val_loss: 848.5432 - val_mae: 848.5432\n",
      "Epoch 89/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.5454 - mae: 881.5454 - val_loss: 849.6099 - val_mae: 849.6099\n",
      "Epoch 90/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.4138 - mae: 881.4138 - val_loss: 845.9575 - val_mae: 845.9575\n",
      "Epoch 91/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.5005 - mae: 882.5005 - val_loss: 847.5226 - val_mae: 847.5226\n",
      "Epoch 92/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 885.1326 - mae: 885.1326 - val_loss: 846.5934 - val_mae: 846.5934\n",
      "Epoch 93/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.9832 - mae: 880.9832 - val_loss: 846.2447 - val_mae: 846.2447\n",
      "Epoch 94/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 883.3590 - mae: 883.3590 - val_loss: 847.1141 - val_mae: 847.1141\n",
      "Epoch 95/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.5412 - mae: 881.5412 - val_loss: 846.0386 - val_mae: 846.0386\n",
      "Epoch 96/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.5730 - mae: 880.5730 - val_loss: 846.1042 - val_mae: 846.1042\n",
      "Epoch 97/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.2234 - mae: 881.2234 - val_loss: 851.1729 - val_mae: 851.1729\n",
      "Epoch 98/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.5154 - mae: 882.5154 - val_loss: 847.8672 - val_mae: 847.8672\n",
      "Epoch 99/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.1982 - mae: 881.1982 - val_loss: 846.8012 - val_mae: 846.8012\n",
      "Epoch 100/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 883.4014 - mae: 883.4014 - val_loss: 855.5721 - val_mae: 855.5721\n",
      "Fold 1 - Loss: 855.5723, MAE: 855.5723\n",
      "169/169 [==============================] - 0s 543us/step\n",
      "Fold 2 / 7\n",
      "Epoch 1/100\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 2009.4908 - mae: 2009.4908 - val_loss: 1029.1599 - val_mae: 1029.1599\n",
      "Epoch 2/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 932.7025 - mae: 932.7025 - val_loss: 875.6030 - val_mae: 875.6030\n",
      "Epoch 3/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 889.2144 - mae: 889.2144 - val_loss: 867.3250 - val_mae: 867.3250\n",
      "Epoch 4/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 885.9933 - mae: 885.9933 - val_loss: 863.3660 - val_mae: 863.3660\n",
      "Epoch 5/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 885.1306 - mae: 885.1306 - val_loss: 867.9648 - val_mae: 867.9648\n",
      "Epoch 6/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 884.0321 - mae: 884.0321 - val_loss: 872.2517 - val_mae: 872.2517\n",
      "Epoch 7/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 885.9058 - mae: 885.9058 - val_loss: 864.4349 - val_mae: 864.4349\n",
      "Epoch 8/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.4772 - mae: 882.4772 - val_loss: 867.1291 - val_mae: 867.1291\n",
      "Epoch 9/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 885.3339 - mae: 885.3339 - val_loss: 863.9599 - val_mae: 863.9599\n",
      "Epoch 10/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.3966 - mae: 881.3966 - val_loss: 870.3818 - val_mae: 870.3818\n",
      "Epoch 11/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 885.6119 - mae: 885.6119 - val_loss: 863.6381 - val_mae: 863.6381\n",
      "Epoch 12/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 884.7927 - mae: 884.7927 - val_loss: 869.0526 - val_mae: 869.0526\n",
      "Epoch 13/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 883.0859 - mae: 883.0859 - val_loss: 867.9191 - val_mae: 867.9191\n",
      "Epoch 14/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 883.5675 - mae: 883.5675 - val_loss: 864.9292 - val_mae: 864.9292\n",
      "Epoch 15/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 884.7154 - mae: 884.7154 - val_loss: 866.9658 - val_mae: 866.9658\n",
      "Epoch 16/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.4758 - mae: 882.4758 - val_loss: 866.2266 - val_mae: 866.2266\n",
      "Epoch 17/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.5989 - mae: 881.5989 - val_loss: 865.8609 - val_mae: 865.8609\n",
      "Epoch 18/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.0238 - mae: 883.0238 - val_loss: 863.2255 - val_mae: 863.2255\n",
      "Epoch 19/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.8340 - mae: 882.8340 - val_loss: 869.0828 - val_mae: 869.0828\n",
      "Epoch 20/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 878.6857 - mae: 878.6857 - val_loss: 864.4545 - val_mae: 864.4545\n",
      "Epoch 21/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.1677 - mae: 881.1677 - val_loss: 865.9488 - val_mae: 865.9488\n",
      "Epoch 22/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.5712 - mae: 881.5712 - val_loss: 864.8719 - val_mae: 864.8719\n",
      "Epoch 23/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.2813 - mae: 882.2813 - val_loss: 864.2097 - val_mae: 864.2097\n",
      "Epoch 24/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.1150 - mae: 882.1150 - val_loss: 863.3027 - val_mae: 863.3027\n",
      "Epoch 25/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.2823 - mae: 882.2823 - val_loss: 866.9058 - val_mae: 866.9058\n",
      "Epoch 26/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.1046 - mae: 882.1046 - val_loss: 864.3391 - val_mae: 864.3391\n",
      "Epoch 27/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.6107 - mae: 880.6107 - val_loss: 864.2818 - val_mae: 864.2818\n",
      "Epoch 28/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.8793 - mae: 881.8793 - val_loss: 864.5096 - val_mae: 864.5096\n",
      "Epoch 29/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.0099 - mae: 882.0099 - val_loss: 865.5511 - val_mae: 865.5511\n",
      "Epoch 30/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.5783 - mae: 880.5783 - val_loss: 862.6945 - val_mae: 862.6945\n",
      "Epoch 31/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.4800 - mae: 880.4800 - val_loss: 864.9904 - val_mae: 864.9904\n",
      "Epoch 32/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.3434 - mae: 881.3434 - val_loss: 865.2408 - val_mae: 865.2408\n",
      "Epoch 33/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.6918 - mae: 882.6918 - val_loss: 866.8015 - val_mae: 866.8015\n",
      "Epoch 34/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.9573 - mae: 881.9573 - val_loss: 863.4050 - val_mae: 863.4050\n",
      "Epoch 35/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.0530 - mae: 881.0530 - val_loss: 864.6516 - val_mae: 864.6516\n",
      "Epoch 36/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.9831 - mae: 880.9831 - val_loss: 869.1873 - val_mae: 869.1873\n",
      "Epoch 37/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.9293 - mae: 881.9293 - val_loss: 862.6898 - val_mae: 862.6898\n",
      "Epoch 38/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.5311 - mae: 881.5311 - val_loss: 866.0237 - val_mae: 866.0237\n",
      "Epoch 39/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.8395 - mae: 881.8395 - val_loss: 864.0869 - val_mae: 864.0869\n",
      "Epoch 40/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.8611 - mae: 880.8611 - val_loss: 864.5978 - val_mae: 864.5978\n",
      "Epoch 41/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.8399 - mae: 878.8399 - val_loss: 862.2307 - val_mae: 862.2307\n",
      "Epoch 42/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.9639 - mae: 881.9639 - val_loss: 864.9039 - val_mae: 864.9039\n",
      "Epoch 43/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.0778 - mae: 880.0778 - val_loss: 864.6440 - val_mae: 864.6440\n",
      "Epoch 44/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.1225 - mae: 882.1225 - val_loss: 865.9226 - val_mae: 865.9226\n",
      "Epoch 45/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.9431 - mae: 879.9431 - val_loss: 863.3876 - val_mae: 863.3876\n",
      "Epoch 46/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.1679 - mae: 878.1679 - val_loss: 866.5945 - val_mae: 866.5945\n",
      "Epoch 47/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.8169 - mae: 880.8169 - val_loss: 865.6432 - val_mae: 865.6432\n",
      "Epoch 48/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 877.0095 - mae: 877.0095 - val_loss: 864.7494 - val_mae: 864.7494\n",
      "Epoch 49/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.8918 - mae: 881.8918 - val_loss: 867.0427 - val_mae: 867.0427\n",
      "Epoch 50/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.8208 - mae: 880.8208 - val_loss: 870.4426 - val_mae: 870.4426\n",
      "Epoch 51/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.2641 - mae: 881.2641 - val_loss: 866.7625 - val_mae: 866.7625\n",
      "Epoch 52/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 879.5456 - mae: 879.5456 - val_loss: 869.4106 - val_mae: 869.4106\n",
      "Epoch 53/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.5806 - mae: 879.5806 - val_loss: 864.3431 - val_mae: 864.3431\n",
      "Epoch 54/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.4485 - mae: 879.4485 - val_loss: 865.7290 - val_mae: 865.7290\n",
      "Epoch 55/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.3095 - mae: 879.3095 - val_loss: 864.6038 - val_mae: 864.6038\n",
      "Epoch 56/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.3803 - mae: 879.3803 - val_loss: 868.4641 - val_mae: 868.4641\n",
      "Epoch 57/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 877.5336 - mae: 877.5336 - val_loss: 861.0435 - val_mae: 861.0435\n",
      "Epoch 58/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.3959 - mae: 880.3959 - val_loss: 863.6231 - val_mae: 863.6231\n",
      "Epoch 59/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.2249 - mae: 880.2249 - val_loss: 864.8688 - val_mae: 864.8688\n",
      "Epoch 60/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 879.2490 - mae: 879.2490 - val_loss: 864.9511 - val_mae: 864.9511\n",
      "Epoch 61/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.3674 - mae: 880.3674 - val_loss: 862.2089 - val_mae: 862.2089\n",
      "Epoch 62/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 876.4347 - mae: 876.4347 - val_loss: 861.8959 - val_mae: 861.8959\n",
      "Epoch 63/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.5482 - mae: 879.5482 - val_loss: 862.6874 - val_mae: 862.6874\n",
      "Epoch 64/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.1754 - mae: 878.1754 - val_loss: 867.3805 - val_mae: 867.3805\n",
      "Epoch 65/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.5916 - mae: 878.5916 - val_loss: 864.3198 - val_mae: 864.3198\n",
      "Epoch 66/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.4786 - mae: 878.4786 - val_loss: 862.1407 - val_mae: 862.1407\n",
      "Epoch 67/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.0009 - mae: 878.0009 - val_loss: 864.9429 - val_mae: 864.9429\n",
      "Epoch 68/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 878.7011 - mae: 878.7011 - val_loss: 862.0201 - val_mae: 862.0201\n",
      "Epoch 69/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 875.6411 - mae: 875.6411 - val_loss: 861.5215 - val_mae: 861.5215\n",
      "Epoch 70/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 877.6799 - mae: 877.6799 - val_loss: 863.4282 - val_mae: 863.4282\n",
      "Epoch 71/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 876.9226 - mae: 876.9226 - val_loss: 860.4885 - val_mae: 860.4885\n",
      "Epoch 72/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 877.3179 - mae: 877.3179 - val_loss: 868.3516 - val_mae: 868.3516\n",
      "Epoch 73/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.0898 - mae: 880.0898 - val_loss: 859.2449 - val_mae: 859.2449\n",
      "Epoch 74/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 877.1204 - mae: 877.1204 - val_loss: 859.7431 - val_mae: 859.7431\n",
      "Epoch 75/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 877.8300 - mae: 877.8300 - val_loss: 860.1575 - val_mae: 860.1575\n",
      "Epoch 76/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 877.9533 - mae: 877.9533 - val_loss: 860.4037 - val_mae: 860.4037\n",
      "Epoch 77/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 877.7848 - mae: 877.7848 - val_loss: 863.3372 - val_mae: 863.3372\n",
      "Epoch 78/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 878.3401 - mae: 878.3401 - val_loss: 861.0036 - val_mae: 861.0036\n",
      "Epoch 79/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 879.9531 - mae: 879.9531 - val_loss: 863.2836 - val_mae: 863.2836\n",
      "Epoch 80/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.5559 - mae: 879.5559 - val_loss: 865.3534 - val_mae: 865.3534\n",
      "Epoch 81/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 877.0674 - mae: 877.0674 - val_loss: 861.2178 - val_mae: 861.2178\n",
      "Epoch 82/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 875.5798 - mae: 875.5798 - val_loss: 860.3566 - val_mae: 860.3566\n",
      "Epoch 83/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 875.2101 - mae: 875.2101 - val_loss: 864.1744 - val_mae: 864.1744\n",
      "Epoch 84/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 876.5652 - mae: 876.5652 - val_loss: 858.9211 - val_mae: 858.9211\n",
      "Epoch 85/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 876.6490 - mae: 876.6490 - val_loss: 863.4794 - val_mae: 863.4794\n",
      "Epoch 86/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 877.4862 - mae: 877.4862 - val_loss: 865.5113 - val_mae: 865.5113\n",
      "Epoch 87/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 876.1659 - mae: 876.1659 - val_loss: 864.2972 - val_mae: 864.2972\n",
      "Epoch 88/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 876.7177 - mae: 876.7177 - val_loss: 859.1240 - val_mae: 859.1240\n",
      "Epoch 89/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 874.4254 - mae: 874.4254 - val_loss: 858.4713 - val_mae: 858.4713\n",
      "Epoch 90/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 877.5902 - mae: 877.5902 - val_loss: 860.1973 - val_mae: 860.1973\n",
      "Epoch 91/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 876.2976 - mae: 876.2976 - val_loss: 858.5552 - val_mae: 858.5552\n",
      "Epoch 92/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 876.8225 - mae: 876.8225 - val_loss: 860.0801 - val_mae: 860.0801\n",
      "Epoch 93/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 877.4169 - mae: 877.4169 - val_loss: 860.6491 - val_mae: 860.6491\n",
      "Epoch 94/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.4298 - mae: 880.4298 - val_loss: 862.6224 - val_mae: 862.6224\n",
      "Epoch 95/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 877.2835 - mae: 877.2835 - val_loss: 861.7595 - val_mae: 861.7595\n",
      "Epoch 96/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 876.2848 - mae: 876.2848 - val_loss: 858.9782 - val_mae: 858.9782\n",
      "Epoch 97/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 873.8729 - mae: 873.8729 - val_loss: 859.2173 - val_mae: 859.2173\n",
      "Epoch 98/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 876.1078 - mae: 876.1078 - val_loss: 859.4382 - val_mae: 859.4382\n",
      "Epoch 99/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 877.3655 - mae: 877.3655 - val_loss: 858.5814 - val_mae: 858.5814\n",
      "Epoch 100/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 874.4518 - mae: 874.4518 - val_loss: 858.7280 - val_mae: 858.7280\n",
      "Fold 2 - Loss: 858.7278, MAE: 858.7278\n",
      "169/169 [==============================] - 0s 484us/step\n",
      "Fold 3 / 7\n",
      "Epoch 1/100\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 1984.6766 - mae: 1984.6766 - val_loss: 1014.0034 - val_mae: 1014.0034\n",
      "Epoch 2/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 932.6733 - mae: 932.6733 - val_loss: 871.7695 - val_mae: 871.7695\n",
      "Epoch 3/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 893.5577 - mae: 893.5577 - val_loss: 861.5298 - val_mae: 861.5298\n",
      "Epoch 4/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 887.3312 - mae: 887.3312 - val_loss: 859.2784 - val_mae: 859.2784\n",
      "Epoch 5/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 888.0165 - mae: 888.0165 - val_loss: 862.2995 - val_mae: 862.2995\n",
      "Epoch 6/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 889.4911 - mae: 889.4911 - val_loss: 860.2665 - val_mae: 860.2665\n",
      "Epoch 7/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 884.8406 - mae: 884.8406 - val_loss: 864.3971 - val_mae: 864.3971\n",
      "Epoch 8/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 885.8629 - mae: 885.8629 - val_loss: 860.4948 - val_mae: 860.4948\n",
      "Epoch 9/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 884.8956 - mae: 884.8956 - val_loss: 857.4779 - val_mae: 857.4779\n",
      "Epoch 10/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 884.9979 - mae: 884.9979 - val_loss: 858.1878 - val_mae: 858.1878\n",
      "Epoch 11/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 888.8713 - mae: 888.8713 - val_loss: 855.2576 - val_mae: 855.2576\n",
      "Epoch 12/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.3701 - mae: 882.3701 - val_loss: 855.8473 - val_mae: 855.8473\n",
      "Epoch 13/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 884.9382 - mae: 884.9382 - val_loss: 854.6130 - val_mae: 854.6130\n",
      "Epoch 14/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.9345 - mae: 883.9345 - val_loss: 858.3707 - val_mae: 858.3707\n",
      "Epoch 15/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 886.3478 - mae: 886.3478 - val_loss: 861.3193 - val_mae: 861.3193\n",
      "Epoch 16/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 888.0623 - mae: 888.0623 - val_loss: 858.3445 - val_mae: 858.3445\n",
      "Epoch 17/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.3913 - mae: 883.3913 - val_loss: 857.4622 - val_mae: 857.4622\n",
      "Epoch 18/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 885.1633 - mae: 885.1633 - val_loss: 857.1105 - val_mae: 857.1105\n",
      "Epoch 19/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 885.0114 - mae: 885.0114 - val_loss: 859.7098 - val_mae: 859.7098\n",
      "Epoch 20/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.4376 - mae: 882.4376 - val_loss: 854.9688 - val_mae: 854.9688\n",
      "Epoch 21/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 886.8513 - mae: 886.8513 - val_loss: 859.5239 - val_mae: 859.5239\n",
      "Epoch 22/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 886.8877 - mae: 886.8877 - val_loss: 856.0616 - val_mae: 856.0616\n",
      "Epoch 23/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 884.4257 - mae: 884.4257 - val_loss: 857.8484 - val_mae: 857.8484\n",
      "Epoch 24/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 884.1807 - mae: 884.1807 - val_loss: 860.8198 - val_mae: 860.8198\n",
      "Epoch 25/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 884.9207 - mae: 884.9207 - val_loss: 856.2481 - val_mae: 856.2481\n",
      "Epoch 26/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.3444 - mae: 883.3444 - val_loss: 855.4715 - val_mae: 855.4715\n",
      "Epoch 27/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 884.0771 - mae: 884.0771 - val_loss: 856.5796 - val_mae: 856.5796\n",
      "Epoch 28/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 886.5068 - mae: 886.5068 - val_loss: 856.0092 - val_mae: 856.0092\n",
      "Epoch 29/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 885.8710 - mae: 885.8710 - val_loss: 861.8500 - val_mae: 861.8500\n",
      "Epoch 30/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.4416 - mae: 882.4416 - val_loss: 854.7107 - val_mae: 854.7107\n",
      "Epoch 31/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 883.6704 - mae: 883.6704 - val_loss: 857.9174 - val_mae: 857.9174\n",
      "Epoch 32/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.7229 - mae: 883.7229 - val_loss: 861.8097 - val_mae: 861.8097\n",
      "Epoch 33/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.6601 - mae: 883.6601 - val_loss: 858.9995 - val_mae: 858.9995\n",
      "Epoch 34/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.1799 - mae: 883.1799 - val_loss: 858.5070 - val_mae: 858.5070\n",
      "Epoch 35/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 885.9862 - mae: 885.9862 - val_loss: 855.6969 - val_mae: 855.6969\n",
      "Epoch 36/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.2766 - mae: 883.2766 - val_loss: 859.3251 - val_mae: 859.3251\n",
      "Epoch 37/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.6068 - mae: 882.6068 - val_loss: 856.6113 - val_mae: 856.6113\n",
      "Epoch 38/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.0625 - mae: 883.0625 - val_loss: 860.8762 - val_mae: 860.8762\n",
      "Epoch 39/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 885.0718 - mae: 885.0718 - val_loss: 859.0569 - val_mae: 859.0569\n",
      "Epoch 40/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.0466 - mae: 882.0466 - val_loss: 859.9824 - val_mae: 859.9824\n",
      "Epoch 41/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.8597 - mae: 882.8597 - val_loss: 859.8589 - val_mae: 859.8589\n",
      "Epoch 42/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 885.1517 - mae: 885.1517 - val_loss: 857.5028 - val_mae: 857.5028\n",
      "Epoch 43/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 885.1149 - mae: 885.1149 - val_loss: 856.2477 - val_mae: 856.2477\n",
      "Epoch 44/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 885.4731 - mae: 885.4731 - val_loss: 857.3623 - val_mae: 857.3623\n",
      "Epoch 45/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.5573 - mae: 882.5573 - val_loss: 858.1570 - val_mae: 858.1570\n",
      "Epoch 46/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.9686 - mae: 879.9686 - val_loss: 855.2988 - val_mae: 855.2988\n",
      "Epoch 47/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.0617 - mae: 883.0617 - val_loss: 855.0023 - val_mae: 855.0023\n",
      "Epoch 48/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.0373 - mae: 882.0373 - val_loss: 858.8260 - val_mae: 858.8260\n",
      "Epoch 49/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.7409 - mae: 881.7409 - val_loss: 860.5157 - val_mae: 860.5157\n",
      "Epoch 50/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 883.4306 - mae: 883.4306 - val_loss: 854.7493 - val_mae: 854.7493\n",
      "Epoch 51/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.2254 - mae: 881.2254 - val_loss: 861.8084 - val_mae: 861.8084\n",
      "Epoch 52/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.9053 - mae: 882.9053 - val_loss: 853.9777 - val_mae: 853.9777\n",
      "Epoch 53/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.8292 - mae: 882.8292 - val_loss: 854.4717 - val_mae: 854.4717\n",
      "Epoch 54/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 884.8928 - mae: 884.8928 - val_loss: 855.6014 - val_mae: 855.6014\n",
      "Epoch 55/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.2031 - mae: 882.2031 - val_loss: 857.4871 - val_mae: 857.4871\n",
      "Epoch 56/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 883.1681 - mae: 883.1681 - val_loss: 857.6578 - val_mae: 857.6578\n",
      "Epoch 57/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.9201 - mae: 882.9201 - val_loss: 857.0674 - val_mae: 857.0674\n",
      "Epoch 58/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.6740 - mae: 883.6740 - val_loss: 862.0235 - val_mae: 862.0235\n",
      "Epoch 59/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 884.2612 - mae: 884.2612 - val_loss: 860.1511 - val_mae: 860.1511\n",
      "Epoch 60/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.2773 - mae: 881.2773 - val_loss: 855.7470 - val_mae: 855.7470\n",
      "Epoch 61/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.5314 - mae: 879.5314 - val_loss: 856.3791 - val_mae: 856.3791\n",
      "Epoch 62/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.5697 - mae: 882.5697 - val_loss: 854.3381 - val_mae: 854.3381\n",
      "Epoch 63/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.5763 - mae: 881.5763 - val_loss: 860.0469 - val_mae: 860.0469\n",
      "Epoch 64/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.0253 - mae: 882.0253 - val_loss: 856.3839 - val_mae: 856.3839\n",
      "Epoch 65/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.5078 - mae: 880.5078 - val_loss: 854.9697 - val_mae: 854.9697\n",
      "Epoch 66/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 883.3648 - mae: 883.3648 - val_loss: 857.4587 - val_mae: 857.4587\n",
      "Epoch 67/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.2869 - mae: 881.2869 - val_loss: 854.4673 - val_mae: 854.4673\n",
      "Epoch 68/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.2733 - mae: 880.2733 - val_loss: 854.0332 - val_mae: 854.0332\n",
      "Epoch 69/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.3298 - mae: 882.3298 - val_loss: 854.5209 - val_mae: 854.5209\n",
      "Epoch 70/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.5468 - mae: 882.5468 - val_loss: 853.6813 - val_mae: 853.6813\n",
      "Epoch 71/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 883.8975 - mae: 883.8975 - val_loss: 852.4263 - val_mae: 852.4263\n",
      "Epoch 72/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.2529 - mae: 882.2529 - val_loss: 854.8798 - val_mae: 854.8798\n",
      "Epoch 73/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.1429 - mae: 882.1429 - val_loss: 853.3608 - val_mae: 853.3608\n",
      "Epoch 74/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.7137 - mae: 881.7137 - val_loss: 858.2824 - val_mae: 858.2824\n",
      "Epoch 75/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.7391 - mae: 882.7391 - val_loss: 854.2922 - val_mae: 854.2922\n",
      "Epoch 76/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.3639 - mae: 879.3639 - val_loss: 852.0119 - val_mae: 852.0119\n",
      "Epoch 77/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.8388 - mae: 878.8388 - val_loss: 857.9910 - val_mae: 857.9910\n",
      "Epoch 78/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.7999 - mae: 881.7999 - val_loss: 852.3675 - val_mae: 852.3675\n",
      "Epoch 79/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.6592 - mae: 881.6592 - val_loss: 855.1851 - val_mae: 855.1851\n",
      "Epoch 80/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.1808 - mae: 880.1808 - val_loss: 853.7192 - val_mae: 853.7192\n",
      "Epoch 81/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.0614 - mae: 881.0614 - val_loss: 854.0549 - val_mae: 854.0549\n",
      "Epoch 82/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.5880 - mae: 881.5880 - val_loss: 854.7668 - val_mae: 854.7668\n",
      "Epoch 83/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.1783 - mae: 880.1783 - val_loss: 853.9962 - val_mae: 853.9962\n",
      "Epoch 84/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.3477 - mae: 880.3477 - val_loss: 852.1158 - val_mae: 852.1158\n",
      "Epoch 85/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 877.9072 - mae: 877.9072 - val_loss: 855.7106 - val_mae: 855.7106\n",
      "Epoch 86/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.3841 - mae: 880.3841 - val_loss: 855.5245 - val_mae: 855.5245\n",
      "Epoch 87/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.4224 - mae: 879.4224 - val_loss: 854.2374 - val_mae: 854.2374\n",
      "Epoch 88/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.4566 - mae: 880.4566 - val_loss: 851.9276 - val_mae: 851.9276\n",
      "Epoch 89/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.4561 - mae: 880.4561 - val_loss: 854.3696 - val_mae: 854.3696\n",
      "Epoch 90/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 878.2458 - mae: 878.2458 - val_loss: 852.0571 - val_mae: 852.0571\n",
      "Epoch 91/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 877.0811 - mae: 877.0811 - val_loss: 851.7114 - val_mae: 851.7114\n",
      "Epoch 92/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.9004 - mae: 878.9004 - val_loss: 851.1081 - val_mae: 851.1081\n",
      "Epoch 93/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.1418 - mae: 879.1418 - val_loss: 852.0745 - val_mae: 852.0745\n",
      "Epoch 94/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 877.1497 - mae: 877.1497 - val_loss: 852.1700 - val_mae: 852.1700\n",
      "Epoch 95/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.9398 - mae: 880.9398 - val_loss: 852.7615 - val_mae: 852.7615\n",
      "Epoch 96/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.9124 - mae: 879.9124 - val_loss: 858.5330 - val_mae: 858.5330\n",
      "Epoch 97/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 876.5268 - mae: 876.5268 - val_loss: 852.9683 - val_mae: 852.9683\n",
      "Epoch 98/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 876.5552 - mae: 876.5552 - val_loss: 853.6492 - val_mae: 853.6492\n",
      "Epoch 99/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.1431 - mae: 880.1431 - val_loss: 851.7458 - val_mae: 851.7458\n",
      "Epoch 100/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.4344 - mae: 880.4344 - val_loss: 851.7479 - val_mae: 851.7479\n",
      "Fold 3 - Loss: 851.7478, MAE: 851.7478\n",
      "169/169 [==============================] - 0s 564us/step\n",
      "Fold 4 / 7\n",
      "Epoch 1/100\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 2010.1223 - mae: 2010.1223 - val_loss: 1003.8500 - val_mae: 1003.8500\n",
      "Epoch 2/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 939.6073 - mae: 939.6073 - val_loss: 872.2258 - val_mae: 872.2258\n",
      "Epoch 3/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 892.8415 - mae: 892.8415 - val_loss: 864.2780 - val_mae: 864.2780\n",
      "Epoch 4/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 885.5685 - mae: 885.5685 - val_loss: 862.7014 - val_mae: 862.7014\n",
      "Epoch 5/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 886.2285 - mae: 886.2285 - val_loss: 865.1573 - val_mae: 865.1573\n",
      "Epoch 6/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 885.1785 - mae: 885.1785 - val_loss: 864.7367 - val_mae: 864.7367\n",
      "Epoch 7/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 885.9922 - mae: 885.9922 - val_loss: 865.2393 - val_mae: 865.2393\n",
      "Epoch 8/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 885.8411 - mae: 885.8411 - val_loss: 863.4454 - val_mae: 863.4454\n",
      "Epoch 9/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 884.5840 - mae: 884.5840 - val_loss: 860.5874 - val_mae: 860.5874\n",
      "Epoch 10/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 884.7761 - mae: 884.7761 - val_loss: 864.1854 - val_mae: 864.1854\n",
      "Epoch 11/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.7512 - mae: 883.7512 - val_loss: 860.6495 - val_mae: 860.6495\n",
      "Epoch 12/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.0600 - mae: 883.0600 - val_loss: 861.9897 - val_mae: 861.9897\n",
      "Epoch 13/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 885.2218 - mae: 885.2218 - val_loss: 864.7151 - val_mae: 864.7151\n",
      "Epoch 14/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.5956 - mae: 882.5956 - val_loss: 860.8814 - val_mae: 860.8814\n",
      "Epoch 15/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.6074 - mae: 883.6074 - val_loss: 859.6254 - val_mae: 859.6254\n",
      "Epoch 16/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.5480 - mae: 883.5480 - val_loss: 861.7339 - val_mae: 861.7339\n",
      "Epoch 17/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 885.5869 - mae: 885.5869 - val_loss: 860.7868 - val_mae: 860.7868\n",
      "Epoch 18/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.6146 - mae: 882.6146 - val_loss: 859.4111 - val_mae: 859.4111\n",
      "Epoch 19/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 883.6696 - mae: 883.6696 - val_loss: 864.2098 - val_mae: 864.2098\n",
      "Epoch 20/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 886.0042 - mae: 886.0042 - val_loss: 860.6141 - val_mae: 860.6141\n",
      "Epoch 21/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.7598 - mae: 882.7598 - val_loss: 861.4381 - val_mae: 861.4381\n",
      "Epoch 22/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.3268 - mae: 882.3268 - val_loss: 859.5458 - val_mae: 859.5458\n",
      "Epoch 23/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 885.0018 - mae: 885.0018 - val_loss: 858.8632 - val_mae: 858.8632\n",
      "Epoch 24/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 885.5373 - mae: 885.5373 - val_loss: 864.6542 - val_mae: 864.6542\n",
      "Epoch 25/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.1697 - mae: 883.1697 - val_loss: 859.7407 - val_mae: 859.7407\n",
      "Epoch 26/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.4365 - mae: 883.4365 - val_loss: 859.9326 - val_mae: 859.9326\n",
      "Epoch 27/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.1411 - mae: 882.1411 - val_loss: 860.4028 - val_mae: 860.4028\n",
      "Epoch 28/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 884.1015 - mae: 884.1015 - val_loss: 863.0132 - val_mae: 863.0132\n",
      "Epoch 29/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.9858 - mae: 882.9858 - val_loss: 862.1876 - val_mae: 862.1876\n",
      "Epoch 30/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.8373 - mae: 881.8373 - val_loss: 867.7318 - val_mae: 867.7318\n",
      "Epoch 31/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 883.3301 - mae: 883.3301 - val_loss: 864.9844 - val_mae: 864.9844\n",
      "Epoch 32/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.9020 - mae: 881.9020 - val_loss: 865.8596 - val_mae: 865.8596\n",
      "Epoch 33/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.9383 - mae: 882.9383 - val_loss: 868.7112 - val_mae: 868.7112\n",
      "Epoch 34/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 883.1942 - mae: 883.1942 - val_loss: 858.3314 - val_mae: 858.3314\n",
      "Epoch 35/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 884.0408 - mae: 884.0408 - val_loss: 859.5640 - val_mae: 859.5640\n",
      "Epoch 36/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.0396 - mae: 883.0396 - val_loss: 860.5556 - val_mae: 860.5556\n",
      "Epoch 37/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 884.5579 - mae: 884.5579 - val_loss: 865.8491 - val_mae: 865.8491\n",
      "Epoch 38/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.3950 - mae: 881.3950 - val_loss: 860.6482 - val_mae: 860.6482\n",
      "Epoch 39/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 883.6888 - mae: 883.6888 - val_loss: 862.3727 - val_mae: 862.3727\n",
      "Epoch 40/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.3834 - mae: 883.3834 - val_loss: 860.3164 - val_mae: 860.3164\n",
      "Epoch 41/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.6699 - mae: 883.6699 - val_loss: 859.6527 - val_mae: 859.6527\n",
      "Epoch 42/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.8395 - mae: 881.8395 - val_loss: 860.2096 - val_mae: 860.2096\n",
      "Epoch 43/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 879.7164 - mae: 879.7164 - val_loss: 858.8638 - val_mae: 858.8638\n",
      "Epoch 44/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.5177 - mae: 881.5177 - val_loss: 866.3683 - val_mae: 866.3683\n",
      "Epoch 45/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 884.0817 - mae: 884.0817 - val_loss: 866.9034 - val_mae: 866.9034\n",
      "Epoch 46/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.6911 - mae: 880.6911 - val_loss: 859.8275 - val_mae: 859.8275\n",
      "Epoch 47/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 879.8452 - mae: 879.8452 - val_loss: 860.3129 - val_mae: 860.3129\n",
      "Epoch 48/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.7352 - mae: 883.7352 - val_loss: 862.1799 - val_mae: 862.1799\n",
      "Epoch 49/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.9438 - mae: 881.9438 - val_loss: 863.4836 - val_mae: 863.4836\n",
      "Epoch 50/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.4084 - mae: 882.4084 - val_loss: 861.6784 - val_mae: 861.6784\n",
      "Epoch 51/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 884.7021 - mae: 884.7021 - val_loss: 865.4979 - val_mae: 865.4979\n",
      "Epoch 52/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.9276 - mae: 880.9276 - val_loss: 860.6249 - val_mae: 860.6249\n",
      "Epoch 53/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 879.2260 - mae: 879.2260 - val_loss: 861.0502 - val_mae: 861.0502\n",
      "Epoch 54/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.1504 - mae: 881.1504 - val_loss: 858.0253 - val_mae: 858.0253\n",
      "Epoch 55/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.3040 - mae: 882.3040 - val_loss: 860.0985 - val_mae: 860.0985\n",
      "Epoch 56/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.7227 - mae: 881.7227 - val_loss: 864.6371 - val_mae: 864.6371\n",
      "Epoch 57/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.3710 - mae: 882.3710 - val_loss: 859.8971 - val_mae: 859.8971\n",
      "Epoch 58/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.5131 - mae: 883.5131 - val_loss: 860.2614 - val_mae: 860.2614\n",
      "Epoch 59/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.4153 - mae: 881.4153 - val_loss: 862.9484 - val_mae: 862.9484\n",
      "Epoch 60/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.8474 - mae: 880.8474 - val_loss: 861.9896 - val_mae: 861.9896\n",
      "Epoch 61/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.0518 - mae: 878.0518 - val_loss: 861.1201 - val_mae: 861.1201\n",
      "Epoch 62/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.0732 - mae: 880.0732 - val_loss: 858.7632 - val_mae: 858.7632\n",
      "Epoch 63/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.2896 - mae: 882.2896 - val_loss: 863.4742 - val_mae: 863.4742\n",
      "Epoch 64/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.6730 - mae: 880.6730 - val_loss: 863.1804 - val_mae: 863.1804\n",
      "Epoch 65/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.5497 - mae: 882.5497 - val_loss: 859.7767 - val_mae: 859.7767\n",
      "Epoch 66/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.0587 - mae: 880.0587 - val_loss: 862.5453 - val_mae: 862.5453\n",
      "Epoch 67/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 879.3011 - mae: 879.3011 - val_loss: 864.3983 - val_mae: 864.3983\n",
      "Epoch 68/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.8697 - mae: 881.8697 - val_loss: 867.2870 - val_mae: 867.2870\n",
      "Epoch 69/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.3933 - mae: 881.3933 - val_loss: 860.4197 - val_mae: 860.4197\n",
      "Epoch 70/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.7936 - mae: 880.7936 - val_loss: 860.0723 - val_mae: 860.0723\n",
      "Epoch 71/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.0427 - mae: 881.0427 - val_loss: 866.2192 - val_mae: 866.2192\n",
      "Epoch 72/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.4391 - mae: 880.4391 - val_loss: 859.6753 - val_mae: 859.6753\n",
      "Epoch 73/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.6494 - mae: 881.6494 - val_loss: 857.8481 - val_mae: 857.8481\n",
      "Epoch 74/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.1302 - mae: 882.1302 - val_loss: 864.5161 - val_mae: 864.5161\n",
      "Epoch 75/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.4900 - mae: 881.4900 - val_loss: 858.6783 - val_mae: 858.6783\n",
      "Epoch 76/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.4130 - mae: 881.4130 - val_loss: 858.1288 - val_mae: 858.1288\n",
      "Epoch 77/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.9456 - mae: 879.9456 - val_loss: 858.9511 - val_mae: 858.9511\n",
      "Epoch 78/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.1505 - mae: 880.1505 - val_loss: 859.6345 - val_mae: 859.6345\n",
      "Epoch 79/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.2076 - mae: 881.2076 - val_loss: 857.9319 - val_mae: 857.9319\n",
      "Epoch 80/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 877.4615 - mae: 877.4615 - val_loss: 862.1677 - val_mae: 862.1677\n",
      "Epoch 81/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.6445 - mae: 880.6445 - val_loss: 864.3159 - val_mae: 864.3159\n",
      "Epoch 82/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.3203 - mae: 881.3203 - val_loss: 859.0995 - val_mae: 859.0995\n",
      "Epoch 83/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.8721 - mae: 881.8721 - val_loss: 858.9438 - val_mae: 858.9438\n",
      "Epoch 84/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.1237 - mae: 882.1237 - val_loss: 859.0206 - val_mae: 859.0206\n",
      "Epoch 85/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.6631 - mae: 882.6631 - val_loss: 859.4798 - val_mae: 859.4798\n",
      "Epoch 86/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.7765 - mae: 879.7765 - val_loss: 866.9251 - val_mae: 866.9251\n",
      "Epoch 87/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.7855 - mae: 880.7855 - val_loss: 862.3188 - val_mae: 862.3188\n",
      "Epoch 88/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.1885 - mae: 879.1885 - val_loss: 864.3627 - val_mae: 864.3627\n",
      "Epoch 89/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.2676 - mae: 879.2676 - val_loss: 863.6320 - val_mae: 863.6320\n",
      "Epoch 90/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.6581 - mae: 880.6581 - val_loss: 857.0862 - val_mae: 857.0862\n",
      "Epoch 91/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 877.1791 - mae: 877.1791 - val_loss: 857.5922 - val_mae: 857.5922\n",
      "Epoch 92/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.6852 - mae: 881.6852 - val_loss: 862.4007 - val_mae: 862.4007\n",
      "Epoch 93/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 877.2675 - mae: 877.2675 - val_loss: 868.5906 - val_mae: 868.5906\n",
      "Epoch 94/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 877.2487 - mae: 877.2487 - val_loss: 861.8125 - val_mae: 861.8125\n",
      "Epoch 95/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.4136 - mae: 878.4136 - val_loss: 862.8773 - val_mae: 862.8773\n",
      "Epoch 96/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.9136 - mae: 879.9136 - val_loss: 858.8726 - val_mae: 858.8726\n",
      "Epoch 97/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 878.2446 - mae: 878.2446 - val_loss: 859.5988 - val_mae: 859.5988\n",
      "Epoch 98/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.0886 - mae: 879.0886 - val_loss: 859.9003 - val_mae: 859.9003\n",
      "Epoch 99/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.3386 - mae: 878.3386 - val_loss: 857.9770 - val_mae: 857.9770\n",
      "Epoch 100/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.7382 - mae: 879.7382 - val_loss: 859.7393 - val_mae: 859.7393\n",
      "Fold 4 - Loss: 859.7394, MAE: 859.7394\n",
      "169/169 [==============================] - 0s 555us/step\n",
      "Fold 5 / 7\n",
      "Epoch 1/100\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 1960.7325 - mae: 1960.7325 - val_loss: 1001.9241 - val_mae: 1001.9241\n",
      "Epoch 2/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 930.0205 - mae: 930.0205 - val_loss: 875.8979 - val_mae: 875.8979\n",
      "Epoch 3/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 885.3890 - mae: 885.3890 - val_loss: 869.1434 - val_mae: 869.1434\n",
      "Epoch 4/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 885.3446 - mae: 885.3446 - val_loss: 867.6066 - val_mae: 867.6066\n",
      "Epoch 5/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 884.3010 - mae: 884.3010 - val_loss: 865.4964 - val_mae: 865.4964\n",
      "Epoch 6/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 883.2143 - mae: 883.2143 - val_loss: 865.5728 - val_mae: 865.5728\n",
      "Epoch 7/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.9504 - mae: 882.9504 - val_loss: 866.3433 - val_mae: 866.3433\n",
      "Epoch 8/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.8942 - mae: 882.8942 - val_loss: 864.3351 - val_mae: 864.3351\n",
      "Epoch 9/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.2280 - mae: 883.2280 - val_loss: 867.3177 - val_mae: 867.3177\n",
      "Epoch 10/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.6859 - mae: 883.6859 - val_loss: 870.2496 - val_mae: 870.2496\n",
      "Epoch 11/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.5313 - mae: 883.5313 - val_loss: 867.6320 - val_mae: 867.6320\n",
      "Epoch 12/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 884.2802 - mae: 884.2802 - val_loss: 864.3114 - val_mae: 864.3114\n",
      "Epoch 13/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.1802 - mae: 881.1802 - val_loss: 865.3841 - val_mae: 865.3841\n",
      "Epoch 14/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.5464 - mae: 880.5464 - val_loss: 868.9286 - val_mae: 868.9286\n",
      "Epoch 15/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.0944 - mae: 881.0944 - val_loss: 867.4138 - val_mae: 867.4138\n",
      "Epoch 16/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.7825 - mae: 882.7825 - val_loss: 867.2872 - val_mae: 867.2872\n",
      "Epoch 17/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.9995 - mae: 882.9995 - val_loss: 869.0701 - val_mae: 869.0701\n",
      "Epoch 18/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.5728 - mae: 881.5728 - val_loss: 868.7924 - val_mae: 868.7924\n",
      "Epoch 19/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.3788 - mae: 880.3788 - val_loss: 867.9344 - val_mae: 867.9344\n",
      "Epoch 20/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.5063 - mae: 880.5063 - val_loss: 866.1636 - val_mae: 866.1636\n",
      "Epoch 21/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 878.9529 - mae: 878.9529 - val_loss: 867.0848 - val_mae: 867.0848\n",
      "Epoch 22/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.0005 - mae: 881.0005 - val_loss: 864.4603 - val_mae: 864.4603\n",
      "Epoch 23/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.7037 - mae: 880.7037 - val_loss: 866.4040 - val_mae: 866.4040\n",
      "Epoch 24/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.9098 - mae: 880.9098 - val_loss: 864.3816 - val_mae: 864.3816\n",
      "Epoch 25/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.9938 - mae: 880.9938 - val_loss: 867.4382 - val_mae: 867.4382\n",
      "Epoch 26/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 879.0806 - mae: 879.0806 - val_loss: 866.0826 - val_mae: 866.0826\n",
      "Epoch 27/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.5130 - mae: 881.5130 - val_loss: 865.3497 - val_mae: 865.3497\n",
      "Epoch 28/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.9330 - mae: 880.9330 - val_loss: 864.7503 - val_mae: 864.7503\n",
      "Epoch 29/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.0696 - mae: 882.0696 - val_loss: 867.8337 - val_mae: 867.8337\n",
      "Epoch 30/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.9760 - mae: 880.9760 - val_loss: 868.1192 - val_mae: 868.1192\n",
      "Epoch 31/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.7449 - mae: 880.7449 - val_loss: 865.9665 - val_mae: 865.9665\n",
      "Epoch 32/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 884.0723 - mae: 884.0723 - val_loss: 867.5859 - val_mae: 867.5859\n",
      "Epoch 33/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.8423 - mae: 880.8423 - val_loss: 865.9761 - val_mae: 865.9761\n",
      "Epoch 34/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.5491 - mae: 882.5491 - val_loss: 865.6985 - val_mae: 865.6985\n",
      "Epoch 35/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.2721 - mae: 880.2721 - val_loss: 863.6080 - val_mae: 863.6080\n",
      "Epoch 36/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.8651 - mae: 881.8651 - val_loss: 864.0338 - val_mae: 864.0338\n",
      "Epoch 37/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.9600 - mae: 880.9600 - val_loss: 864.8489 - val_mae: 864.8489\n",
      "Epoch 38/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.1655 - mae: 882.1655 - val_loss: 864.1402 - val_mae: 864.1402\n",
      "Epoch 39/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.0760 - mae: 880.0760 - val_loss: 863.6698 - val_mae: 863.6698\n",
      "Epoch 40/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.4305 - mae: 880.4305 - val_loss: 863.8076 - val_mae: 863.8076\n",
      "Epoch 41/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.5605 - mae: 882.5605 - val_loss: 862.9978 - val_mae: 862.9978\n",
      "Epoch 42/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.5831 - mae: 879.5831 - val_loss: 867.8207 - val_mae: 867.8207\n",
      "Epoch 43/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.0750 - mae: 880.0750 - val_loss: 864.8317 - val_mae: 864.8317\n",
      "Epoch 44/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.5983 - mae: 882.5983 - val_loss: 866.8409 - val_mae: 866.8409\n",
      "Epoch 45/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.9153 - mae: 881.9153 - val_loss: 863.8776 - val_mae: 863.8776\n",
      "Epoch 46/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 879.2786 - mae: 879.2786 - val_loss: 864.5825 - val_mae: 864.5825\n",
      "Epoch 47/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 878.6726 - mae: 878.6726 - val_loss: 865.1238 - val_mae: 865.1238\n",
      "Epoch 48/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 879.2582 - mae: 879.2582 - val_loss: 867.5995 - val_mae: 867.5995\n",
      "Epoch 49/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.1335 - mae: 880.1335 - val_loss: 864.3373 - val_mae: 864.3373\n",
      "Epoch 50/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.2191 - mae: 879.2191 - val_loss: 865.3713 - val_mae: 865.3713\n",
      "Epoch 51/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.0635 - mae: 881.0635 - val_loss: 864.5683 - val_mae: 864.5683\n",
      "Epoch 52/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.1005 - mae: 880.1005 - val_loss: 862.7833 - val_mae: 862.7833\n",
      "Epoch 53/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.6872 - mae: 880.6872 - val_loss: 863.2751 - val_mae: 863.2751\n",
      "Epoch 54/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.5090 - mae: 881.5090 - val_loss: 866.4236 - val_mae: 866.4236\n",
      "Epoch 55/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.5216 - mae: 880.5216 - val_loss: 863.2808 - val_mae: 863.2808\n",
      "Epoch 56/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.5238 - mae: 882.5238 - val_loss: 862.4326 - val_mae: 862.4326\n",
      "Epoch 57/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 879.1639 - mae: 879.1639 - val_loss: 861.8129 - val_mae: 861.8129\n",
      "Epoch 58/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.0057 - mae: 879.0057 - val_loss: 864.2674 - val_mae: 864.2674\n",
      "Epoch 59/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.6213 - mae: 879.6213 - val_loss: 862.4722 - val_mae: 862.4722\n",
      "Epoch 60/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 877.5010 - mae: 877.5010 - val_loss: 861.4914 - val_mae: 861.4914\n",
      "Epoch 61/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.9407 - mae: 879.9407 - val_loss: 867.1028 - val_mae: 867.1028\n",
      "Epoch 62/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 877.9865 - mae: 877.9865 - val_loss: 865.1964 - val_mae: 865.1964\n",
      "Epoch 63/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 879.4138 - mae: 879.4138 - val_loss: 861.0048 - val_mae: 861.0048\n",
      "Epoch 64/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 877.7053 - mae: 877.7053 - val_loss: 863.0854 - val_mae: 863.0854\n",
      "Epoch 65/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 875.8781 - mae: 875.8781 - val_loss: 862.7158 - val_mae: 862.7158\n",
      "Epoch 66/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 875.6461 - mae: 875.6461 - val_loss: 862.0898 - val_mae: 862.0898\n",
      "Epoch 67/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 879.5097 - mae: 879.5097 - val_loss: 861.1564 - val_mae: 861.1564\n",
      "Epoch 68/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 878.6891 - mae: 878.6891 - val_loss: 862.0399 - val_mae: 862.0399\n",
      "Epoch 69/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.8171 - mae: 880.8171 - val_loss: 863.4474 - val_mae: 863.4474\n",
      "Epoch 70/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 878.8721 - mae: 878.8721 - val_loss: 866.4442 - val_mae: 866.4442\n",
      "Epoch 71/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 877.8497 - mae: 877.8497 - val_loss: 861.7799 - val_mae: 861.7799\n",
      "Epoch 72/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 877.5867 - mae: 877.5867 - val_loss: 859.7491 - val_mae: 859.7491\n",
      "Epoch 73/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 877.6516 - mae: 877.6516 - val_loss: 863.1195 - val_mae: 863.1195\n",
      "Epoch 74/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 878.0472 - mae: 878.0472 - val_loss: 859.1312 - val_mae: 859.1312\n",
      "Epoch 75/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 877.9039 - mae: 877.9039 - val_loss: 861.5457 - val_mae: 861.5457\n",
      "Epoch 76/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 877.9480 - mae: 877.9480 - val_loss: 858.8027 - val_mae: 858.8027\n",
      "Epoch 77/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 877.8109 - mae: 877.8109 - val_loss: 859.7059 - val_mae: 859.7059\n",
      "Epoch 78/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 875.7961 - mae: 875.7961 - val_loss: 862.1124 - val_mae: 862.1124\n",
      "Epoch 79/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 879.3361 - mae: 879.3361 - val_loss: 859.1981 - val_mae: 859.1981\n",
      "Epoch 80/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 877.2092 - mae: 877.2092 - val_loss: 864.8596 - val_mae: 864.8596\n",
      "Epoch 81/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 878.1562 - mae: 878.1562 - val_loss: 858.7341 - val_mae: 858.7341\n",
      "Epoch 82/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 878.0935 - mae: 878.0935 - val_loss: 859.2869 - val_mae: 859.2869\n",
      "Epoch 83/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 876.2174 - mae: 876.2174 - val_loss: 857.9802 - val_mae: 857.9802\n",
      "Epoch 84/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 877.1580 - mae: 877.1580 - val_loss: 859.6819 - val_mae: 859.6819\n",
      "Epoch 85/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 878.4445 - mae: 878.4445 - val_loss: 858.1097 - val_mae: 858.1097\n",
      "Epoch 86/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 878.4315 - mae: 878.4315 - val_loss: 858.2521 - val_mae: 858.2521\n",
      "Epoch 87/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 875.6017 - mae: 875.6017 - val_loss: 858.9915 - val_mae: 858.9915\n",
      "Epoch 88/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 876.5859 - mae: 876.5859 - val_loss: 859.9024 - val_mae: 859.9024\n",
      "Epoch 89/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 876.5872 - mae: 876.5872 - val_loss: 860.3218 - val_mae: 860.3218\n",
      "Epoch 90/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 875.7781 - mae: 875.7781 - val_loss: 857.6511 - val_mae: 857.6511\n",
      "Epoch 91/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 875.5951 - mae: 875.5951 - val_loss: 862.4839 - val_mae: 862.4839\n",
      "Epoch 92/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 878.0367 - mae: 878.0367 - val_loss: 859.2874 - val_mae: 859.2874\n",
      "Epoch 93/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 877.7784 - mae: 877.7784 - val_loss: 860.2483 - val_mae: 860.2483\n",
      "Epoch 94/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 875.2525 - mae: 875.2525 - val_loss: 863.0872 - val_mae: 863.0872\n",
      "Epoch 95/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 877.8325 - mae: 877.8325 - val_loss: 857.0701 - val_mae: 857.0701\n",
      "Epoch 96/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 877.0451 - mae: 877.0451 - val_loss: 858.1447 - val_mae: 858.1447\n",
      "Epoch 97/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 876.2266 - mae: 876.2266 - val_loss: 858.6819 - val_mae: 858.6819\n",
      "Epoch 98/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 877.8100 - mae: 877.8100 - val_loss: 861.2517 - val_mae: 861.2517\n",
      "Epoch 99/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 873.6181 - mae: 873.6181 - val_loss: 859.5391 - val_mae: 859.5391\n",
      "Epoch 100/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 876.6245 - mae: 876.6245 - val_loss: 862.7855 - val_mae: 862.7855\n",
      "Fold 5 - Loss: 862.7854, MAE: 862.7854\n",
      "169/169 [==============================] - 0s 478us/step\n",
      "Fold 6 / 7\n",
      "Epoch 1/100\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 1965.3562 - mae: 1965.3562 - val_loss: 997.8951 - val_mae: 997.8951\n",
      "Epoch 2/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 931.1112 - mae: 931.1112 - val_loss: 867.6358 - val_mae: 867.6358\n",
      "Epoch 3/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 890.1034 - mae: 890.1034 - val_loss: 858.6368 - val_mae: 858.6368\n",
      "Epoch 4/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 886.0236 - mae: 886.0236 - val_loss: 861.0139 - val_mae: 861.0139\n",
      "Epoch 5/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 886.7255 - mae: 886.7255 - val_loss: 859.4301 - val_mae: 859.4301\n",
      "Epoch 6/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 886.4342 - mae: 886.4342 - val_loss: 861.4829 - val_mae: 861.4829\n",
      "Epoch 7/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 885.4863 - mae: 885.4863 - val_loss: 856.1231 - val_mae: 856.1231\n",
      "Epoch 8/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.4593 - mae: 883.4593 - val_loss: 857.8895 - val_mae: 857.8895\n",
      "Epoch 9/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 884.2944 - mae: 884.2944 - val_loss: 856.7117 - val_mae: 856.7117\n",
      "Epoch 10/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 884.4793 - mae: 884.4793 - val_loss: 859.3883 - val_mae: 859.3883\n",
      "Epoch 11/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 886.8275 - mae: 886.8275 - val_loss: 859.1896 - val_mae: 859.1896\n",
      "Epoch 12/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 885.6369 - mae: 885.6369 - val_loss: 855.5659 - val_mae: 855.5659\n",
      "Epoch 13/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 885.1682 - mae: 885.1682 - val_loss: 857.9158 - val_mae: 857.9158\n",
      "Epoch 14/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.6759 - mae: 882.6759 - val_loss: 854.8978 - val_mae: 854.8978\n",
      "Epoch 15/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 885.3322 - mae: 885.3322 - val_loss: 854.6014 - val_mae: 854.6014\n",
      "Epoch 16/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 885.2842 - mae: 885.2842 - val_loss: 859.1174 - val_mae: 859.1174\n",
      "Epoch 17/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 885.7213 - mae: 885.7213 - val_loss: 858.4039 - val_mae: 858.4039\n",
      "Epoch 18/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 886.5805 - mae: 886.5805 - val_loss: 854.2073 - val_mae: 854.2073\n",
      "Epoch 19/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 884.8609 - mae: 884.8609 - val_loss: 854.6880 - val_mae: 854.6880\n",
      "Epoch 20/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.5794 - mae: 882.5794 - val_loss: 856.2487 - val_mae: 856.2487\n",
      "Epoch 21/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.4540 - mae: 882.4540 - val_loss: 857.8901 - val_mae: 857.8901\n",
      "Epoch 22/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 884.8622 - mae: 884.8622 - val_loss: 854.7231 - val_mae: 854.7231\n",
      "Epoch 23/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 885.3029 - mae: 885.3029 - val_loss: 855.1074 - val_mae: 855.1074\n",
      "Epoch 24/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 885.4018 - mae: 885.4018 - val_loss: 855.4719 - val_mae: 855.4719\n",
      "Epoch 25/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 883.2134 - mae: 883.2134 - val_loss: 861.2137 - val_mae: 861.2137\n",
      "Epoch 26/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.3207 - mae: 882.3207 - val_loss: 854.1826 - val_mae: 854.1826\n",
      "Epoch 27/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 884.8297 - mae: 884.8297 - val_loss: 856.9980 - val_mae: 856.9980\n",
      "Epoch 28/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.8765 - mae: 881.8765 - val_loss: 855.8607 - val_mae: 855.8607\n",
      "Epoch 29/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.3608 - mae: 881.3608 - val_loss: 856.8323 - val_mae: 856.8323\n",
      "Epoch 30/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.2600 - mae: 882.2600 - val_loss: 856.7715 - val_mae: 856.7715\n",
      "Epoch 31/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 883.7715 - mae: 883.7715 - val_loss: 854.6049 - val_mae: 854.6049\n",
      "Epoch 32/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.9487 - mae: 882.9487 - val_loss: 856.3148 - val_mae: 856.3148\n",
      "Epoch 33/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 884.5090 - mae: 884.5090 - val_loss: 857.7625 - val_mae: 857.7625\n",
      "Epoch 34/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.1329 - mae: 882.1329 - val_loss: 855.8489 - val_mae: 855.8489\n",
      "Epoch 35/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.6970 - mae: 881.6970 - val_loss: 855.2933 - val_mae: 855.2933\n",
      "Epoch 36/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.4454 - mae: 883.4454 - val_loss: 858.8439 - val_mae: 858.8439\n",
      "Epoch 37/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.5592 - mae: 881.5592 - val_loss: 855.9738 - val_mae: 855.9738\n",
      "Epoch 38/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.6659 - mae: 882.6659 - val_loss: 859.1063 - val_mae: 859.1063\n",
      "Epoch 39/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.6600 - mae: 882.6600 - val_loss: 855.7008 - val_mae: 855.7008\n",
      "Epoch 40/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 883.5973 - mae: 883.5973 - val_loss: 854.2255 - val_mae: 854.2255\n",
      "Epoch 41/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.3755 - mae: 882.3755 - val_loss: 855.5021 - val_mae: 855.5021\n",
      "Epoch 42/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.0817 - mae: 882.0817 - val_loss: 855.4978 - val_mae: 855.4978\n",
      "Epoch 43/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.2198 - mae: 882.2198 - val_loss: 853.7981 - val_mae: 853.7981\n",
      "Epoch 44/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.7477 - mae: 881.7477 - val_loss: 854.2740 - val_mae: 854.2740\n",
      "Epoch 45/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.4226 - mae: 881.4226 - val_loss: 853.1850 - val_mae: 853.1850\n",
      "Epoch 46/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.8473 - mae: 880.8473 - val_loss: 857.0823 - val_mae: 857.0823\n",
      "Epoch 47/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 883.3160 - mae: 883.3160 - val_loss: 853.1195 - val_mae: 853.1195\n",
      "Epoch 48/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.1267 - mae: 881.1267 - val_loss: 858.8625 - val_mae: 858.8625\n",
      "Epoch 49/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.1890 - mae: 882.1890 - val_loss: 859.7119 - val_mae: 859.7119\n",
      "Epoch 50/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.0143 - mae: 881.0143 - val_loss: 853.2899 - val_mae: 853.2899\n",
      "Epoch 51/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.6953 - mae: 879.6953 - val_loss: 854.7192 - val_mae: 854.7192\n",
      "Epoch 52/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.9536 - mae: 879.9536 - val_loss: 854.3976 - val_mae: 854.3976\n",
      "Epoch 53/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.3491 - mae: 880.3491 - val_loss: 854.8309 - val_mae: 854.8309\n",
      "Epoch 54/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.2569 - mae: 882.2569 - val_loss: 855.9863 - val_mae: 855.9863\n",
      "Epoch 55/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.2660 - mae: 879.2660 - val_loss: 854.5172 - val_mae: 854.5172\n",
      "Epoch 56/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.5162 - mae: 880.5162 - val_loss: 856.4738 - val_mae: 856.4738\n",
      "Epoch 57/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.8141 - mae: 880.8141 - val_loss: 852.8857 - val_mae: 852.8857\n",
      "Epoch 58/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.7155 - mae: 878.7155 - val_loss: 851.5699 - val_mae: 851.5699\n",
      "Epoch 59/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.4767 - mae: 880.4767 - val_loss: 856.0289 - val_mae: 856.0289\n",
      "Epoch 60/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.5940 - mae: 880.5940 - val_loss: 853.8518 - val_mae: 853.8518\n",
      "Epoch 61/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 876.7720 - mae: 876.7720 - val_loss: 851.4472 - val_mae: 851.4472\n",
      "Epoch 62/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.6845 - mae: 881.6845 - val_loss: 851.6292 - val_mae: 851.6292\n",
      "Epoch 63/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.5980 - mae: 879.5980 - val_loss: 851.6407 - val_mae: 851.6407\n",
      "Epoch 64/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.1185 - mae: 880.1185 - val_loss: 853.9229 - val_mae: 853.9229\n",
      "Epoch 65/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.5402 - mae: 878.5402 - val_loss: 855.1070 - val_mae: 855.1070\n",
      "Epoch 66/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.9622 - mae: 880.9622 - val_loss: 852.5164 - val_mae: 852.5164\n",
      "Epoch 67/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.3933 - mae: 880.3933 - val_loss: 851.4535 - val_mae: 851.4535\n",
      "Epoch 68/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.7610 - mae: 879.7610 - val_loss: 855.1103 - val_mae: 855.1103\n",
      "Epoch 69/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.9706 - mae: 879.9706 - val_loss: 860.8162 - val_mae: 860.8162\n",
      "Epoch 70/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.7191 - mae: 880.7191 - val_loss: 858.1870 - val_mae: 858.1870\n",
      "Epoch 71/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.1896 - mae: 878.1896 - val_loss: 852.2340 - val_mae: 852.2340\n",
      "Epoch 72/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.1907 - mae: 878.1907 - val_loss: 851.7132 - val_mae: 851.7132\n",
      "Epoch 73/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.3004 - mae: 878.3004 - val_loss: 858.0989 - val_mae: 858.0989\n",
      "Epoch 74/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 876.1619 - mae: 876.1619 - val_loss: 856.3439 - val_mae: 856.3439\n",
      "Epoch 75/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.1760 - mae: 879.1760 - val_loss: 850.8640 - val_mae: 850.8640\n",
      "Epoch 76/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 877.6206 - mae: 877.6206 - val_loss: 853.7588 - val_mae: 853.7588\n",
      "Epoch 77/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.2587 - mae: 878.2587 - val_loss: 855.5706 - val_mae: 855.5706\n",
      "Epoch 78/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.6204 - mae: 878.6204 - val_loss: 850.7790 - val_mae: 850.7790\n",
      "Epoch 79/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.2810 - mae: 878.2810 - val_loss: 852.8839 - val_mae: 852.8839\n",
      "Epoch 80/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 874.8160 - mae: 874.8160 - val_loss: 856.0787 - val_mae: 856.0787\n",
      "Epoch 81/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 876.8662 - mae: 876.8662 - val_loss: 850.2704 - val_mae: 850.2704\n",
      "Epoch 82/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.5568 - mae: 879.5568 - val_loss: 851.0035 - val_mae: 851.0035\n",
      "Epoch 83/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.8455 - mae: 878.8455 - val_loss: 851.7201 - val_mae: 851.7201\n",
      "Epoch 84/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 879.0120 - mae: 879.0120 - val_loss: 852.3708 - val_mae: 852.3708\n",
      "Epoch 85/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 876.3680 - mae: 876.3680 - val_loss: 852.7812 - val_mae: 852.7812\n",
      "Epoch 86/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 878.0052 - mae: 878.0052 - val_loss: 856.3662 - val_mae: 856.3662\n",
      "Epoch 87/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 877.0912 - mae: 877.0912 - val_loss: 851.3555 - val_mae: 851.3555\n",
      "Epoch 88/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.6556 - mae: 878.6556 - val_loss: 851.7153 - val_mae: 851.7153\n",
      "Epoch 89/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.9463 - mae: 878.9463 - val_loss: 855.7608 - val_mae: 855.7608\n",
      "Epoch 90/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.3862 - mae: 878.3862 - val_loss: 850.2144 - val_mae: 850.2144\n",
      "Epoch 91/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 875.9973 - mae: 875.9973 - val_loss: 851.1620 - val_mae: 851.1620\n",
      "Epoch 92/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 876.2580 - mae: 876.2580 - val_loss: 851.3616 - val_mae: 851.3616\n",
      "Epoch 93/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.8807 - mae: 878.8807 - val_loss: 853.3713 - val_mae: 853.3713\n",
      "Epoch 94/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 877.7203 - mae: 877.7203 - val_loss: 851.9503 - val_mae: 851.9503\n",
      "Epoch 95/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.4627 - mae: 880.4627 - val_loss: 856.5961 - val_mae: 856.5961\n",
      "Epoch 96/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 875.0362 - mae: 875.0362 - val_loss: 851.1475 - val_mae: 851.1475\n",
      "Epoch 97/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 876.7448 - mae: 876.7448 - val_loss: 859.7673 - val_mae: 859.7673\n",
      "Epoch 98/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 877.3030 - mae: 877.3030 - val_loss: 851.0115 - val_mae: 851.0115\n",
      "Epoch 99/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 877.2476 - mae: 877.2476 - val_loss: 851.9518 - val_mae: 851.9518\n",
      "Epoch 100/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 876.5032 - mae: 876.5032 - val_loss: 854.4629 - val_mae: 854.4629\n",
      "Fold 6 - Loss: 854.4630, MAE: 854.4630\n",
      "169/169 [==============================] - 0s 513us/step\n",
      "Fold 7 / 7\n",
      "Epoch 1/100\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 2004.6440 - mae: 2004.6440 - val_loss: 997.9019 - val_mae: 997.9019\n",
      "Epoch 2/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 937.4541 - mae: 937.4541 - val_loss: 868.0717 - val_mae: 868.0717\n",
      "Epoch 3/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 888.6901 - mae: 888.6901 - val_loss: 855.6078 - val_mae: 855.6078\n",
      "Epoch 4/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 886.3341 - mae: 886.3341 - val_loss: 853.9891 - val_mae: 853.9891\n",
      "Epoch 5/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 885.3679 - mae: 885.3679 - val_loss: 855.8853 - val_mae: 855.8853\n",
      "Epoch 6/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 885.3812 - mae: 885.3812 - val_loss: 864.0476 - val_mae: 864.0476\n",
      "Epoch 7/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 888.1383 - mae: 888.1383 - val_loss: 856.2394 - val_mae: 856.2394\n",
      "Epoch 8/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.7452 - mae: 882.7452 - val_loss: 856.9075 - val_mae: 856.9075\n",
      "Epoch 9/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.9254 - mae: 883.9254 - val_loss: 860.9079 - val_mae: 860.9079\n",
      "Epoch 10/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 885.4642 - mae: 885.4642 - val_loss: 859.6277 - val_mae: 859.6277\n",
      "Epoch 11/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.4683 - mae: 882.4683 - val_loss: 856.3710 - val_mae: 856.3710\n",
      "Epoch 12/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 884.2654 - mae: 884.2654 - val_loss: 856.3957 - val_mae: 856.3957\n",
      "Epoch 13/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 884.2414 - mae: 884.2414 - val_loss: 857.7214 - val_mae: 857.7214\n",
      "Epoch 14/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.4167 - mae: 883.4167 - val_loss: 854.7139 - val_mae: 854.7139\n",
      "Epoch 15/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.9111 - mae: 882.9111 - val_loss: 856.6068 - val_mae: 856.6068\n",
      "Epoch 16/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 883.7409 - mae: 883.7409 - val_loss: 854.3313 - val_mae: 854.3313\n",
      "Epoch 17/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.2881 - mae: 881.2881 - val_loss: 855.3077 - val_mae: 855.3077\n",
      "Epoch 18/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 884.1832 - mae: 884.1832 - val_loss: 853.9880 - val_mae: 853.9880\n",
      "Epoch 19/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 885.8630 - mae: 885.8630 - val_loss: 853.2162 - val_mae: 853.2162\n",
      "Epoch 20/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 883.8557 - mae: 883.8557 - val_loss: 856.0438 - val_mae: 856.0438\n",
      "Epoch 21/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.6059 - mae: 883.6059 - val_loss: 852.3995 - val_mae: 852.3995\n",
      "Epoch 22/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.9485 - mae: 883.9485 - val_loss: 854.6113 - val_mae: 854.6113\n",
      "Epoch 23/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 884.8122 - mae: 884.8122 - val_loss: 853.5192 - val_mae: 853.5192\n",
      "Epoch 24/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.8969 - mae: 882.8969 - val_loss: 853.6934 - val_mae: 853.6934\n",
      "Epoch 25/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 885.4979 - mae: 885.4979 - val_loss: 851.4565 - val_mae: 851.4565\n",
      "Epoch 26/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.4490 - mae: 882.4490 - val_loss: 857.9979 - val_mae: 857.9979\n",
      "Epoch 27/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 884.0696 - mae: 884.0696 - val_loss: 855.5243 - val_mae: 855.5243\n",
      "Epoch 28/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.5269 - mae: 880.5269 - val_loss: 850.9815 - val_mae: 850.9815\n",
      "Epoch 29/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 885.0695 - mae: 885.0695 - val_loss: 852.1154 - val_mae: 852.1154\n",
      "Epoch 30/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.1724 - mae: 882.1724 - val_loss: 852.7216 - val_mae: 852.7216\n",
      "Epoch 31/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 885.5344 - mae: 885.5344 - val_loss: 854.4286 - val_mae: 854.4286\n",
      "Epoch 32/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.9480 - mae: 882.9480 - val_loss: 859.7118 - val_mae: 859.7118\n",
      "Epoch 33/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.1888 - mae: 883.1888 - val_loss: 856.1012 - val_mae: 856.1012\n",
      "Epoch 34/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.7363 - mae: 881.7363 - val_loss: 856.9481 - val_mae: 856.9481\n",
      "Epoch 35/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.2247 - mae: 882.2247 - val_loss: 851.4025 - val_mae: 851.4025\n",
      "Epoch 36/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.7379 - mae: 882.7379 - val_loss: 855.0142 - val_mae: 855.0142\n",
      "Epoch 37/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.4026 - mae: 881.4026 - val_loss: 850.7963 - val_mae: 850.7963\n",
      "Epoch 38/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 885.5387 - mae: 885.5387 - val_loss: 852.0744 - val_mae: 852.0744\n",
      "Epoch 39/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.8254 - mae: 881.8254 - val_loss: 852.8250 - val_mae: 852.8250\n",
      "Epoch 40/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.9515 - mae: 882.9515 - val_loss: 857.5927 - val_mae: 857.5927\n",
      "Epoch 41/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 883.2224 - mae: 883.2224 - val_loss: 854.2299 - val_mae: 854.2299\n",
      "Epoch 42/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.6120 - mae: 881.6120 - val_loss: 855.0781 - val_mae: 855.0781\n",
      "Epoch 43/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.1758 - mae: 881.1758 - val_loss: 858.7824 - val_mae: 858.7824\n",
      "Epoch 44/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.2325 - mae: 882.2325 - val_loss: 856.0959 - val_mae: 856.0959\n",
      "Epoch 45/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 883.0569 - mae: 883.0569 - val_loss: 851.6652 - val_mae: 851.6652\n",
      "Epoch 46/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.6687 - mae: 881.6687 - val_loss: 856.7244 - val_mae: 856.7244\n",
      "Epoch 47/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.7502 - mae: 880.7502 - val_loss: 851.0935 - val_mae: 851.0935\n",
      "Epoch 48/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.3642 - mae: 882.3642 - val_loss: 853.6063 - val_mae: 853.6063\n",
      "Epoch 49/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.7088 - mae: 882.7088 - val_loss: 851.9201 - val_mae: 851.9201\n",
      "Epoch 50/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.0068 - mae: 883.0068 - val_loss: 852.3698 - val_mae: 852.3698\n",
      "Epoch 51/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.9918 - mae: 880.9918 - val_loss: 853.8027 - val_mae: 853.8027\n",
      "Epoch 52/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.4133 - mae: 881.4133 - val_loss: 852.2733 - val_mae: 852.2733\n",
      "Epoch 53/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.0536 - mae: 881.0536 - val_loss: 856.4283 - val_mae: 856.4283\n",
      "Epoch 54/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.1046 - mae: 881.1046 - val_loss: 856.4005 - val_mae: 856.4005\n",
      "Epoch 55/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.3444 - mae: 882.3444 - val_loss: 855.6390 - val_mae: 855.6390\n",
      "Epoch 56/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.9773 - mae: 882.9773 - val_loss: 853.0197 - val_mae: 853.0197\n",
      "Epoch 57/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 883.1069 - mae: 883.1069 - val_loss: 854.7619 - val_mae: 854.7619\n",
      "Epoch 58/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.8169 - mae: 882.8169 - val_loss: 855.8572 - val_mae: 855.8572\n",
      "Epoch 59/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.6792 - mae: 882.6792 - val_loss: 850.3680 - val_mae: 850.3680\n",
      "Epoch 60/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.5977 - mae: 881.5977 - val_loss: 852.6436 - val_mae: 852.6436\n",
      "Epoch 61/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.3809 - mae: 881.3809 - val_loss: 855.0314 - val_mae: 855.0314\n",
      "Epoch 62/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.1185 - mae: 881.1185 - val_loss: 855.2629 - val_mae: 855.2629\n",
      "Epoch 63/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.9678 - mae: 881.9678 - val_loss: 851.3770 - val_mae: 851.3770\n",
      "Epoch 64/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.8001 - mae: 882.8001 - val_loss: 851.7706 - val_mae: 851.7706\n",
      "Epoch 65/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 883.5889 - mae: 883.5889 - val_loss: 854.8555 - val_mae: 854.8555\n",
      "Epoch 66/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 883.3856 - mae: 883.3856 - val_loss: 855.6402 - val_mae: 855.6402\n",
      "Epoch 67/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.7694 - mae: 882.7694 - val_loss: 852.1946 - val_mae: 852.1946\n",
      "Epoch 68/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.5333 - mae: 882.5333 - val_loss: 853.5201 - val_mae: 853.5201\n",
      "Epoch 69/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.0498 - mae: 881.0498 - val_loss: 857.2535 - val_mae: 857.2535\n",
      "Epoch 70/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.2051 - mae: 881.2051 - val_loss: 852.3455 - val_mae: 852.3455\n",
      "Epoch 71/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.5887 - mae: 881.5887 - val_loss: 854.0513 - val_mae: 854.0513\n",
      "Epoch 72/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.3130 - mae: 881.3130 - val_loss: 854.9111 - val_mae: 854.9111\n",
      "Epoch 73/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 881.8588 - mae: 881.8588 - val_loss: 855.8104 - val_mae: 855.8104\n",
      "Epoch 74/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.6498 - mae: 880.6498 - val_loss: 851.4396 - val_mae: 851.4396\n",
      "Epoch 75/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 882.2401 - mae: 882.2401 - val_loss: 854.6614 - val_mae: 854.6614\n",
      "Epoch 76/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.3260 - mae: 881.3260 - val_loss: 852.4219 - val_mae: 852.4219\n",
      "Epoch 77/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.0392 - mae: 881.0392 - val_loss: 856.6737 - val_mae: 856.6737\n",
      "Epoch 78/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.9114 - mae: 880.9114 - val_loss: 851.4413 - val_mae: 851.4413\n",
      "Epoch 79/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.6887 - mae: 880.6887 - val_loss: 852.3022 - val_mae: 852.3022\n",
      "Epoch 80/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.3205 - mae: 879.3205 - val_loss: 850.8298 - val_mae: 850.8298\n",
      "Epoch 81/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 883.3088 - mae: 883.3088 - val_loss: 851.9386 - val_mae: 851.9386\n",
      "Epoch 82/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.9708 - mae: 880.9708 - val_loss: 851.4821 - val_mae: 851.4821\n",
      "Epoch 83/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.1006 - mae: 881.1006 - val_loss: 852.5926 - val_mae: 852.5926\n",
      "Epoch 84/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.3889 - mae: 881.3889 - val_loss: 850.6738 - val_mae: 850.6738\n",
      "Epoch 85/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.8886 - mae: 880.8886 - val_loss: 856.3737 - val_mae: 856.3737\n",
      "Epoch 86/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.7051 - mae: 880.7051 - val_loss: 852.3317 - val_mae: 852.3317\n",
      "Epoch 87/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.3527 - mae: 880.3527 - val_loss: 853.0276 - val_mae: 853.0276\n",
      "Epoch 88/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.8649 - mae: 879.8649 - val_loss: 853.4115 - val_mae: 853.4115\n",
      "Epoch 89/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.1543 - mae: 879.1543 - val_loss: 851.5744 - val_mae: 851.5744\n",
      "Epoch 90/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.0044 - mae: 880.0044 - val_loss: 859.9411 - val_mae: 859.9411\n",
      "Epoch 91/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.5491 - mae: 879.5491 - val_loss: 854.3899 - val_mae: 854.3899\n",
      "Epoch 92/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.1903 - mae: 879.1903 - val_loss: 857.5117 - val_mae: 857.5117\n",
      "Epoch 93/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 880.1725 - mae: 880.1725 - val_loss: 852.2478 - val_mae: 852.2478\n",
      "Epoch 94/100\n",
      "253/253 [==============================] - 0s 2ms/step - loss: 882.3892 - mae: 882.3892 - val_loss: 856.1810 - val_mae: 856.1810\n",
      "Epoch 95/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 880.5798 - mae: 880.5798 - val_loss: 857.1854 - val_mae: 857.1854\n",
      "Epoch 96/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.7463 - mae: 881.7463 - val_loss: 851.1930 - val_mae: 851.1930\n",
      "Epoch 97/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 883.0801 - mae: 883.0801 - val_loss: 850.1379 - val_mae: 850.1379\n",
      "Epoch 98/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 881.8512 - mae: 881.8512 - val_loss: 850.2080 - val_mae: 850.2080\n",
      "Epoch 99/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 878.7468 - mae: 878.7468 - val_loss: 855.8593 - val_mae: 855.8593\n",
      "Epoch 100/100\n",
      "253/253 [==============================] - 0s 1ms/step - loss: 879.5337 - mae: 879.5337 - val_loss: 853.6472 - val_mae: 853.6472\n",
      "Fold 7 - Loss: 853.6473, MAE: 853.6473\n",
      "169/169 [==============================] - 0s 412us/step\n",
      "[각 Fold별 평균 성능]\n",
      "mae : 856.668957142857\n",
      "mape : 0.3422142857142857\n",
      "mse : 1228866.3173999998\n",
      "rmse : 1108.5071714285714\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "\n",
    "\n",
    "# K-Fold Cross Validation\n",
    "def cross_validate_model(X_train, y_train, n_splits_list):\n",
    "    for n_splits in n_splits_list:\n",
    "        print(f\"\\n--- Cross Validation: {n_splits}-Fold 시작 ---\\n\")\n",
    "        kfold = KFold(n_splits=n_splits, shuffle=True, random_state=7)\n",
    "\n",
    "        fold_no = 1\n",
    "        mae_per_fold = []\n",
    "        mape_per_fold = []\n",
    "        mse_per_fold = []\n",
    "        rmse_per_fold = []\n",
    "        \n",
    "        for train_index, val_index in kfold.split(X_train):\n",
    "            print(f\"Fold {fold_no} / {n_splits}\")\n",
    "            \n",
    "            # 데이터 분할\n",
    "            X_fold_train, X_fold_val = X_train[train_index], X_train[val_index]\n",
    "            y_fold_train, y_fold_val = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "            \n",
    "            # DNN 모델 정의\n",
    "            model = Sequential([\n",
    "                Dense(128, activation='relu', input_shape=(X_fold_train.shape[1],)),\n",
    "                Dropout(0.3),  \n",
    "                Dense(64, activation='relu'),\n",
    "                Dropout(0.2),\n",
    "                Dense(32, activation='relu'), \n",
    "                Dense(1)\n",
    "            ])\n",
    "            \n",
    "            # 모델 컴파일\n",
    "            model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                          loss='mae',\n",
    "                          metrics=['mae'])\n",
    "\n",
    "            # 학습 (GPU 사용)\n",
    "            with tf.device(\"/device:GPU:0\"):\n",
    "                history = model.fit(X_fold_train, y_fold_train, \n",
    "                                    epochs=100,  # 폴드마다 학습 횟수를 조정 가능\n",
    "                                    batch_size=128, \n",
    "                                    validation_data=(X_fold_val, y_fold_val), \n",
    "                                    verbose=1)\n",
    "\n",
    "                # 폴드별 평가\n",
    "                loss, mae = model.evaluate(X_fold_val, y_fold_val, verbose=0)\n",
    "                print(f\"Fold {fold_no} - Loss: {loss:.4f}, MAE: {mae:.4f}\")\n",
    "                \n",
    "                fold_pred = model.predict(X_fold_val)\n",
    "                mae = round(mean_absolute_error(y_fold_val, fold_pred), 4)\n",
    "                mape = round(mean_absolute_percentage_error(y_fold_val, fold_pred), 4)\n",
    "                mse = round(mean_squared_error(y_fold_val, fold_pred), 4)\n",
    "                rmse = round(root_mean_squared_error(y_fold_val, fold_pred), 4)\n",
    "                \n",
    "                mae_per_fold.append(mae)\n",
    "                mape_per_fold.append(mape)\n",
    "                mse_per_fold.append(mse)\n",
    "                rmse_per_fold.append(rmse)                \n",
    "        \n",
    "            fold_no += 1\n",
    "            \n",
    "        print(\"[각 Fold별 평균 성능]\")\n",
    "        print(f\"mae : {np.mean(mae_per_fold)}\")\n",
    "        print(f\"mape : {np.mean(mape_per_fold)}\")\n",
    "        print(f\"mse : {np.mean(mse_per_fold)}\")\n",
    "        print(f\"rmse : {np.mean(rmse_per_fold)}\")\n",
    "        \n",
    "        # 평균 MAE 출력\n",
    "        # print(f\"\\nCross Validation {n_splits}-Fold 결과:\")\n",
    "        # print(f\"MAE 평균: {np.mean(mae_per_fold):.4f}, 표준편차: {np.std(mae_per_fold):.4f}\\n\")\n",
    "\n",
    "# Cross Validation 실행 (3, 5, 7-Fold)\n",
    "n_splits_list = [3, 5, 7]\n",
    "cross_validate_model(X_train2, y_train2, n_splits_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixed K-Fold (K=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 / 5\n",
      "Epoch 1/200\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 2064.5725 - mae: 2064.5725 - val_loss: 1042.5881 - val_mae: 1042.5881\n",
      "Epoch 2/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 952.5894 - mae: 952.5894 - val_loss: 878.0933 - val_mae: 878.0933\n",
      "Epoch 3/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 890.9266 - mae: 890.9266 - val_loss: 861.1250 - val_mae: 861.1250\n",
      "Epoch 4/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 886.7127 - mae: 886.7127 - val_loss: 858.8304 - val_mae: 858.8304\n",
      "Epoch 5/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 887.3256 - mae: 887.3256 - val_loss: 861.3793 - val_mae: 861.3793\n",
      "Epoch 6/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 884.9254 - mae: 884.9254 - val_loss: 863.4688 - val_mae: 863.4688\n",
      "Epoch 7/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 888.4480 - mae: 888.4480 - val_loss: 858.0247 - val_mae: 858.0247\n",
      "Epoch 8/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 884.7084 - mae: 884.7084 - val_loss: 862.9158 - val_mae: 862.9158\n",
      "Epoch 9/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 883.2253 - mae: 883.2253 - val_loss: 859.3965 - val_mae: 859.3965\n",
      "Epoch 10/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 884.5557 - mae: 884.5557 - val_loss: 860.3252 - val_mae: 860.3252\n",
      "Epoch 11/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 885.5714 - mae: 885.5714 - val_loss: 860.7896 - val_mae: 860.7896\n",
      "Epoch 12/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.6801 - mae: 885.6801 - val_loss: 861.2179 - val_mae: 861.2179\n",
      "Epoch 13/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 885.3912 - mae: 885.3912 - val_loss: 862.7902 - val_mae: 862.7902\n",
      "Epoch 14/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 883.2430 - mae: 883.2430 - val_loss: 859.4028 - val_mae: 859.4028\n",
      "Epoch 15/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.0289 - mae: 882.0289 - val_loss: 860.6516 - val_mae: 860.6516\n",
      "Epoch 16/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 884.6366 - mae: 884.6366 - val_loss: 858.9909 - val_mae: 858.9909\n",
      "Epoch 17/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 886.0162 - mae: 886.0162 - val_loss: 860.6749 - val_mae: 860.6749\n",
      "Epoch 18/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 883.4383 - mae: 883.4383 - val_loss: 863.7943 - val_mae: 863.7943\n",
      "Epoch 19/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 885.9913 - mae: 885.9913 - val_loss: 865.5279 - val_mae: 865.5279\n",
      "Epoch 20/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 885.2249 - mae: 885.2249 - val_loss: 857.8015 - val_mae: 857.8015\n",
      "Epoch 21/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 883.8542 - mae: 883.8542 - val_loss: 859.5337 - val_mae: 859.5337\n",
      "Epoch 22/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 883.9177 - mae: 883.9177 - val_loss: 859.4074 - val_mae: 859.4074\n",
      "Epoch 23/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.7242 - mae: 882.7242 - val_loss: 863.3314 - val_mae: 863.3314\n",
      "Epoch 24/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 885.5980 - mae: 885.5980 - val_loss: 860.5736 - val_mae: 860.5736\n",
      "Epoch 25/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.6921 - mae: 882.6921 - val_loss: 858.6929 - val_mae: 858.6929\n",
      "Epoch 26/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.1461 - mae: 885.1461 - val_loss: 864.0765 - val_mae: 864.0765\n",
      "Epoch 27/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.0519 - mae: 885.0519 - val_loss: 860.6107 - val_mae: 860.6107\n",
      "Epoch 28/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.8719 - mae: 883.8719 - val_loss: 867.3966 - val_mae: 867.3966\n",
      "Epoch 29/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 884.5710 - mae: 884.5710 - val_loss: 860.4828 - val_mae: 860.4828\n",
      "Epoch 30/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 882.2471 - mae: 882.2471 - val_loss: 861.4131 - val_mae: 861.4131\n",
      "Epoch 31/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.9053 - mae: 883.9053 - val_loss: 859.4281 - val_mae: 859.4281\n",
      "Epoch 32/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.9490 - mae: 881.9490 - val_loss: 861.4166 - val_mae: 861.4166\n",
      "Epoch 33/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 886.2869 - mae: 886.2869 - val_loss: 860.1175 - val_mae: 860.1175\n",
      "Epoch 34/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.5767 - mae: 885.5767 - val_loss: 857.1098 - val_mae: 857.1098\n",
      "Epoch 35/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.3137 - mae: 882.3137 - val_loss: 856.4874 - val_mae: 856.4874\n",
      "Epoch 36/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 884.4730 - mae: 884.4730 - val_loss: 860.9139 - val_mae: 860.9139\n",
      "Epoch 37/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.7221 - mae: 882.7221 - val_loss: 862.4805 - val_mae: 862.4805\n",
      "Epoch 38/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 885.4401 - mae: 885.4401 - val_loss: 856.8177 - val_mae: 856.8177\n",
      "Epoch 39/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.7479 - mae: 883.7479 - val_loss: 863.7084 - val_mae: 863.7084\n",
      "Epoch 40/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.7892 - mae: 883.7892 - val_loss: 860.3650 - val_mae: 860.3650\n",
      "Epoch 41/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 883.0738 - mae: 883.0738 - val_loss: 856.7637 - val_mae: 856.7637\n",
      "Epoch 42/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.8375 - mae: 883.8375 - val_loss: 862.4155 - val_mae: 862.4155\n",
      "Epoch 43/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.2891 - mae: 882.2891 - val_loss: 861.7191 - val_mae: 861.7191\n",
      "Epoch 44/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.6790 - mae: 882.6790 - val_loss: 858.9016 - val_mae: 858.9016\n",
      "Epoch 45/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.4623 - mae: 882.4623 - val_loss: 861.6119 - val_mae: 861.6119\n",
      "Epoch 46/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.2671 - mae: 883.2671 - val_loss: 858.3779 - val_mae: 858.3779\n",
      "Epoch 47/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.8073 - mae: 880.8073 - val_loss: 856.7580 - val_mae: 856.7580\n",
      "Epoch 48/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 884.5595 - mae: 884.5595 - val_loss: 859.0373 - val_mae: 859.0373\n",
      "Epoch 49/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.9844 - mae: 881.9844 - val_loss: 860.1948 - val_mae: 860.1948\n",
      "Epoch 50/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 882.1180 - mae: 882.1180 - val_loss: 857.4561 - val_mae: 857.4561\n",
      "Epoch 51/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 882.6114 - mae: 882.6114 - val_loss: 857.8502 - val_mae: 857.8502\n",
      "Epoch 52/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 884.1940 - mae: 884.1940 - val_loss: 856.5729 - val_mae: 856.5729\n",
      "Epoch 53/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 884.6815 - mae: 884.6815 - val_loss: 859.1411 - val_mae: 859.1411\n",
      "Epoch 54/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.2988 - mae: 881.2988 - val_loss: 859.9402 - val_mae: 859.9402\n",
      "Epoch 55/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.6765 - mae: 882.6765 - val_loss: 861.2789 - val_mae: 861.2789\n",
      "Epoch 56/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.0082 - mae: 883.0082 - val_loss: 858.3564 - val_mae: 858.3564\n",
      "Epoch 57/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.1036 - mae: 883.1036 - val_loss: 858.8930 - val_mae: 858.8930\n",
      "Epoch 58/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.4796 - mae: 883.4796 - val_loss: 862.4129 - val_mae: 862.4129\n",
      "Epoch 59/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.9971 - mae: 880.9971 - val_loss: 858.8608 - val_mae: 858.8608\n",
      "Epoch 60/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 883.9915 - mae: 883.9915 - val_loss: 858.6274 - val_mae: 858.6274\n",
      "Epoch 61/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 882.7116 - mae: 882.7116 - val_loss: 862.9142 - val_mae: 862.9142\n",
      "Epoch 62/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 884.2013 - mae: 884.2013 - val_loss: 858.6788 - val_mae: 858.6788\n",
      "Epoch 63/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 882.1313 - mae: 882.1313 - val_loss: 859.2611 - val_mae: 859.2611\n",
      "Epoch 64/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 882.4861 - mae: 882.4861 - val_loss: 861.9874 - val_mae: 861.9874\n",
      "Epoch 65/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.0254 - mae: 883.0254 - val_loss: 856.5825 - val_mae: 856.5825\n",
      "Epoch 66/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.9841 - mae: 882.9841 - val_loss: 857.0038 - val_mae: 857.0038\n",
      "Epoch 67/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.1193 - mae: 885.1193 - val_loss: 857.6678 - val_mae: 857.6678\n",
      "Epoch 68/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.9309 - mae: 882.9309 - val_loss: 857.9952 - val_mae: 857.9952\n",
      "Epoch 69/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 880.4185 - mae: 880.4185 - val_loss: 857.6276 - val_mae: 857.6276\n",
      "Epoch 70/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.6294 - mae: 884.6294 - val_loss: 855.8166 - val_mae: 855.8166\n",
      "Epoch 71/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.5185 - mae: 884.5185 - val_loss: 862.5278 - val_mae: 862.5278\n",
      "Epoch 72/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 881.4529 - mae: 881.4529 - val_loss: 864.0203 - val_mae: 864.0203\n",
      "Epoch 73/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.4610 - mae: 883.4610 - val_loss: 857.0474 - val_mae: 857.0474\n",
      "Epoch 74/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 880.6191 - mae: 880.6191 - val_loss: 858.6597 - val_mae: 858.6597\n",
      "Epoch 75/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.7912 - mae: 881.7912 - val_loss: 863.5338 - val_mae: 863.5338\n",
      "Epoch 76/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.6043 - mae: 883.6043 - val_loss: 855.7371 - val_mae: 855.7371\n",
      "Epoch 77/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.9222 - mae: 879.9222 - val_loss: 855.5682 - val_mae: 855.5682\n",
      "Epoch 78/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.9592 - mae: 883.9592 - val_loss: 855.8405 - val_mae: 855.8405\n",
      "Epoch 79/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.6288 - mae: 882.6288 - val_loss: 861.0307 - val_mae: 861.0307\n",
      "Epoch 80/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.8353 - mae: 878.8353 - val_loss: 857.0547 - val_mae: 857.0547\n",
      "Epoch 81/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.3614 - mae: 882.3614 - val_loss: 858.6035 - val_mae: 858.6035\n",
      "Epoch 82/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.3613 - mae: 878.3613 - val_loss: 859.5724 - val_mae: 859.5724\n",
      "Epoch 83/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.6617 - mae: 879.6617 - val_loss: 854.8027 - val_mae: 854.8027\n",
      "Epoch 84/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.7333 - mae: 879.7333 - val_loss: 855.2619 - val_mae: 855.2619\n",
      "Epoch 85/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.5767 - mae: 879.5767 - val_loss: 855.9890 - val_mae: 855.9890\n",
      "Epoch 86/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.0001 - mae: 882.0001 - val_loss: 857.9069 - val_mae: 857.9069\n",
      "Epoch 87/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.4384 - mae: 882.4384 - val_loss: 858.5782 - val_mae: 858.5782\n",
      "Epoch 88/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.5235 - mae: 879.5235 - val_loss: 854.3739 - val_mae: 854.3739\n",
      "Epoch 89/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.4033 - mae: 882.4033 - val_loss: 856.1108 - val_mae: 856.1108\n",
      "Epoch 90/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.7861 - mae: 879.7861 - val_loss: 857.5502 - val_mae: 857.5502\n",
      "Epoch 91/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.9791 - mae: 879.9791 - val_loss: 858.4033 - val_mae: 858.4033\n",
      "Epoch 92/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.1497 - mae: 880.1497 - val_loss: 855.6620 - val_mae: 855.6620\n",
      "Epoch 93/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.6608 - mae: 879.6608 - val_loss: 855.4310 - val_mae: 855.4310\n",
      "Epoch 94/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 879.0364 - mae: 879.0364 - val_loss: 854.8531 - val_mae: 854.8531\n",
      "Epoch 95/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 880.1632 - mae: 880.1632 - val_loss: 856.7933 - val_mae: 856.7933\n",
      "Epoch 96/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.0161 - mae: 876.0161 - val_loss: 854.3558 - val_mae: 854.3558\n",
      "Epoch 97/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.0202 - mae: 879.0202 - val_loss: 857.6627 - val_mae: 857.6627\n",
      "Epoch 98/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.8115 - mae: 878.8115 - val_loss: 854.4952 - val_mae: 854.4952\n",
      "Epoch 99/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.2889 - mae: 879.2889 - val_loss: 854.6570 - val_mae: 854.6570\n",
      "Epoch 100/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.6967 - mae: 877.6967 - val_loss: 855.4785 - val_mae: 855.4785\n",
      "Epoch 101/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.4191 - mae: 878.4191 - val_loss: 855.4188 - val_mae: 855.4188\n",
      "Epoch 102/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 878.5148 - mae: 878.5148 - val_loss: 853.4713 - val_mae: 853.4713\n",
      "Epoch 103/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.0707 - mae: 879.0707 - val_loss: 852.9657 - val_mae: 852.9657\n",
      "Epoch 104/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 878.3440 - mae: 878.3440 - val_loss: 855.7839 - val_mae: 855.7839\n",
      "Epoch 105/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 880.9278 - mae: 880.9278 - val_loss: 853.3356 - val_mae: 853.3356\n",
      "Epoch 106/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.3115 - mae: 877.3115 - val_loss: 853.7269 - val_mae: 853.7269\n",
      "Epoch 107/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 878.7451 - mae: 878.7451 - val_loss: 856.5289 - val_mae: 856.5289\n",
      "Epoch 108/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 877.1606 - mae: 877.1606 - val_loss: 852.9141 - val_mae: 852.9141\n",
      "Epoch 109/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.8458 - mae: 876.8458 - val_loss: 855.1249 - val_mae: 855.1249\n",
      "Epoch 110/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.6905 - mae: 878.6905 - val_loss: 855.9064 - val_mae: 855.9064\n",
      "Epoch 111/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.7123 - mae: 877.7123 - val_loss: 856.1251 - val_mae: 856.1251\n",
      "Epoch 112/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.1637 - mae: 878.1637 - val_loss: 853.3243 - val_mae: 853.3243\n",
      "Epoch 113/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.4517 - mae: 879.4517 - val_loss: 854.2487 - val_mae: 854.2487\n",
      "Epoch 114/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.9229 - mae: 878.9229 - val_loss: 853.3403 - val_mae: 853.3403\n",
      "Epoch 115/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.0693 - mae: 876.0693 - val_loss: 853.1991 - val_mae: 853.1991\n",
      "Epoch 116/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.8703 - mae: 878.8703 - val_loss: 854.1848 - val_mae: 854.1848\n",
      "Epoch 117/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.5267 - mae: 878.5267 - val_loss: 854.9328 - val_mae: 854.9328\n",
      "Epoch 118/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.8898 - mae: 876.8898 - val_loss: 856.8643 - val_mae: 856.8643\n",
      "Epoch 119/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 875.9470 - mae: 875.9470 - val_loss: 852.4105 - val_mae: 852.4105\n",
      "Epoch 120/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.8962 - mae: 876.8962 - val_loss: 856.9444 - val_mae: 856.9444\n",
      "Epoch 121/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.6833 - mae: 877.6833 - val_loss: 852.8491 - val_mae: 852.8491\n",
      "Epoch 122/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.3986 - mae: 876.3986 - val_loss: 855.2938 - val_mae: 855.2938\n",
      "Epoch 123/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.6830 - mae: 877.6830 - val_loss: 852.2023 - val_mae: 852.2023\n",
      "Epoch 124/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.0341 - mae: 877.0341 - val_loss: 853.4680 - val_mae: 853.4680\n",
      "Epoch 125/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.8890 - mae: 877.8890 - val_loss: 852.8276 - val_mae: 852.8276\n",
      "Epoch 126/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.8693 - mae: 876.8693 - val_loss: 863.3158 - val_mae: 863.3158\n",
      "Epoch 127/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 875.5460 - mae: 875.5460 - val_loss: 855.8328 - val_mae: 855.8328\n",
      "Epoch 128/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.7150 - mae: 877.7150 - val_loss: 852.2012 - val_mae: 852.2012\n",
      "Epoch 129/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.0165 - mae: 878.0165 - val_loss: 852.3854 - val_mae: 852.3854\n",
      "Epoch 130/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 874.9670 - mae: 874.9670 - val_loss: 854.6934 - val_mae: 854.6934\n",
      "Epoch 131/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 875.7263 - mae: 875.7263 - val_loss: 853.6229 - val_mae: 853.6229\n",
      "Epoch 132/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.2148 - mae: 876.2148 - val_loss: 852.8525 - val_mae: 852.8525\n",
      "Epoch 133/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.3590 - mae: 878.3590 - val_loss: 856.5021 - val_mae: 856.5021\n",
      "Epoch 134/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 875.4178 - mae: 875.4178 - val_loss: 853.8696 - val_mae: 853.8696\n",
      "Epoch 135/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 875.4597 - mae: 875.4597 - val_loss: 852.0716 - val_mae: 852.0716\n",
      "Epoch 136/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 875.5095 - mae: 875.5095 - val_loss: 854.5578 - val_mae: 854.5578\n",
      "Epoch 137/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 876.9138 - mae: 876.9138 - val_loss: 852.8661 - val_mae: 852.8661\n",
      "Epoch 138/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.8127 - mae: 876.8127 - val_loss: 854.0265 - val_mae: 854.0265\n",
      "Epoch 139/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 874.6824 - mae: 874.6824 - val_loss: 852.4116 - val_mae: 852.4116\n",
      "Epoch 140/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 878.0523 - mae: 878.0523 - val_loss: 854.7669 - val_mae: 854.7669\n",
      "Epoch 141/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 878.3664 - mae: 878.3664 - val_loss: 859.1786 - val_mae: 859.1786\n",
      "Epoch 142/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.4893 - mae: 876.4893 - val_loss: 853.1500 - val_mae: 853.1500\n",
      "Epoch 143/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.1359 - mae: 876.1359 - val_loss: 852.6439 - val_mae: 852.6439\n",
      "Epoch 144/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 876.7716 - mae: 876.7716 - val_loss: 857.6203 - val_mae: 857.6203\n",
      "Epoch 145/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 875.6699 - mae: 875.6699 - val_loss: 853.6958 - val_mae: 853.6958\n",
      "Epoch 146/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 876.9539 - mae: 876.9539 - val_loss: 852.2303 - val_mae: 852.2303\n",
      "Epoch 147/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.1340 - mae: 876.1340 - val_loss: 852.8805 - val_mae: 852.8805\n",
      "Epoch 148/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.1913 - mae: 876.1913 - val_loss: 853.0879 - val_mae: 853.0879\n",
      "Epoch 149/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.0739 - mae: 876.0739 - val_loss: 851.8907 - val_mae: 851.8907\n",
      "Epoch 150/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 873.8766 - mae: 873.8766 - val_loss: 852.4127 - val_mae: 852.4127\n",
      "Epoch 151/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 875.4578 - mae: 875.4578 - val_loss: 853.2601 - val_mae: 853.2601\n",
      "Epoch 152/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 874.5996 - mae: 874.5996 - val_loss: 854.0693 - val_mae: 854.0693\n",
      "Epoch 153/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 876.7858 - mae: 876.7858 - val_loss: 853.1315 - val_mae: 853.1315\n",
      "Epoch 154/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 873.6696 - mae: 873.6696 - val_loss: 852.1439 - val_mae: 852.1439\n",
      "Epoch 155/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 874.1593 - mae: 874.1593 - val_loss: 851.9093 - val_mae: 851.9093\n",
      "Epoch 156/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 874.4974 - mae: 874.4974 - val_loss: 851.7606 - val_mae: 851.7606\n",
      "Epoch 157/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 873.0526 - mae: 873.0526 - val_loss: 855.0479 - val_mae: 855.0479\n",
      "Epoch 158/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 873.9443 - mae: 873.9443 - val_loss: 854.6880 - val_mae: 854.6880\n",
      "Epoch 159/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 875.2509 - mae: 875.2509 - val_loss: 853.1252 - val_mae: 853.1252\n",
      "Epoch 160/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 876.7515 - mae: 876.7515 - val_loss: 855.6649 - val_mae: 855.6649\n",
      "Epoch 161/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 873.6879 - mae: 873.6879 - val_loss: 853.2864 - val_mae: 853.2864\n",
      "Epoch 162/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 875.6255 - mae: 875.6255 - val_loss: 855.6522 - val_mae: 855.6522\n",
      "Epoch 163/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 874.9218 - mae: 874.9218 - val_loss: 852.5872 - val_mae: 852.5872\n",
      "Epoch 164/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 875.0944 - mae: 875.0944 - val_loss: 854.9067 - val_mae: 854.9067\n",
      "Epoch 165/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 874.6317 - mae: 874.6317 - val_loss: 853.2138 - val_mae: 853.2138\n",
      "Epoch 166/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 874.3154 - mae: 874.3154 - val_loss: 851.8405 - val_mae: 851.8405\n",
      "Epoch 167/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 872.7010 - mae: 872.7010 - val_loss: 854.4237 - val_mae: 854.4237\n",
      "Epoch 168/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.2453 - mae: 876.2453 - val_loss: 852.8624 - val_mae: 852.8624\n",
      "Epoch 169/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 875.2702 - mae: 875.2702 - val_loss: 851.7845 - val_mae: 851.7845\n",
      "Epoch 170/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 873.9761 - mae: 873.9761 - val_loss: 852.1141 - val_mae: 852.1141\n",
      "Epoch 171/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 873.7885 - mae: 873.7885 - val_loss: 853.9627 - val_mae: 853.9627\n",
      "Epoch 172/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 874.2380 - mae: 874.2380 - val_loss: 853.7486 - val_mae: 853.7486\n",
      "Epoch 173/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 874.7283 - mae: 874.7283 - val_loss: 853.1865 - val_mae: 853.1865\n",
      "Epoch 174/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 872.0347 - mae: 872.0347 - val_loss: 852.5283 - val_mae: 852.5283\n",
      "Epoch 175/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 871.9643 - mae: 871.9643 - val_loss: 854.8179 - val_mae: 854.8179\n",
      "Epoch 176/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 874.2822 - mae: 874.2822 - val_loss: 854.0489 - val_mae: 854.0489\n",
      "Epoch 177/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 875.1614 - mae: 875.1614 - val_loss: 851.8578 - val_mae: 851.8578\n",
      "Epoch 178/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.4310 - mae: 876.4310 - val_loss: 856.5052 - val_mae: 856.5052\n",
      "Epoch 179/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 874.3528 - mae: 874.3528 - val_loss: 851.6862 - val_mae: 851.6862\n",
      "Epoch 180/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 874.2118 - mae: 874.2118 - val_loss: 855.4524 - val_mae: 855.4524\n",
      "Epoch 181/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 871.4737 - mae: 871.4737 - val_loss: 854.4012 - val_mae: 854.4012\n",
      "Epoch 182/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 872.1448 - mae: 872.1448 - val_loss: 853.2067 - val_mae: 853.2067\n",
      "Epoch 183/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 873.8295 - mae: 873.8295 - val_loss: 854.2612 - val_mae: 854.2612\n",
      "Epoch 184/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 874.0843 - mae: 874.0843 - val_loss: 852.7801 - val_mae: 852.7801\n",
      "Epoch 185/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 874.4456 - mae: 874.4456 - val_loss: 860.5134 - val_mae: 860.5134\n",
      "Epoch 186/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 874.7870 - mae: 874.7870 - val_loss: 856.4586 - val_mae: 856.4586\n",
      "Epoch 187/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 873.3477 - mae: 873.3477 - val_loss: 853.1108 - val_mae: 853.1108\n",
      "Epoch 188/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 875.8499 - mae: 875.8499 - val_loss: 851.7997 - val_mae: 851.7997\n",
      "Epoch 189/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 874.0612 - mae: 874.0612 - val_loss: 857.1910 - val_mae: 857.1910\n",
      "Epoch 190/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 873.3600 - mae: 873.3600 - val_loss: 853.2982 - val_mae: 853.2982\n",
      "Epoch 191/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 872.1384 - mae: 872.1384 - val_loss: 853.2876 - val_mae: 853.2876\n",
      "Epoch 192/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 873.5349 - mae: 873.5349 - val_loss: 851.5191 - val_mae: 851.5191\n",
      "Epoch 193/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 871.8901 - mae: 871.8901 - val_loss: 854.5503 - val_mae: 854.5503\n",
      "Epoch 194/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 874.5485 - mae: 874.5485 - val_loss: 853.1765 - val_mae: 853.1765\n",
      "Epoch 195/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 872.5062 - mae: 872.5062 - val_loss: 851.9577 - val_mae: 851.9577\n",
      "Epoch 196/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 872.5529 - mae: 872.5529 - val_loss: 853.5252 - val_mae: 853.5252\n",
      "Epoch 197/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 873.5354 - mae: 873.5354 - val_loss: 852.9415 - val_mae: 852.9415\n",
      "Epoch 198/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 871.4454 - mae: 871.4454 - val_loss: 855.9136 - val_mae: 855.9136\n",
      "Epoch 199/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 871.4261 - mae: 871.4261 - val_loss: 853.9136 - val_mae: 853.9136\n",
      "Epoch 200/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 872.4056 - mae: 872.4056 - val_loss: 852.5605 - val_mae: 852.5605\n",
      "Fold 1 - Loss: 852.5605, MAE: 852.5605\n",
      "236/236 [==============================] - 0s 604us/step\n",
      "Fold 2 / 5\n",
      "Epoch 1/200\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 2105.3708 - mae: 2105.3708 - val_loss: 1067.3198 - val_mae: 1067.3198\n",
      "Epoch 2/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 960.5990 - mae: 960.5990 - val_loss: 885.5503 - val_mae: 885.5503\n",
      "Epoch 3/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 894.4702 - mae: 894.4702 - val_loss: 861.5694 - val_mae: 861.5694\n",
      "Epoch 4/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 889.6755 - mae: 889.6755 - val_loss: 866.1683 - val_mae: 866.1683\n",
      "Epoch 5/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 886.4004 - mae: 886.4004 - val_loss: 862.5188 - val_mae: 862.5188\n",
      "Epoch 6/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 887.6794 - mae: 887.6794 - val_loss: 859.4621 - val_mae: 859.4621\n",
      "Epoch 7/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 888.0200 - mae: 888.0200 - val_loss: 860.5834 - val_mae: 860.5834\n",
      "Epoch 8/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 887.2388 - mae: 887.2388 - val_loss: 858.5894 - val_mae: 858.5894\n",
      "Epoch 9/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 887.9429 - mae: 887.9429 - val_loss: 855.6424 - val_mae: 855.6424\n",
      "Epoch 10/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 888.5717 - mae: 888.5717 - val_loss: 859.7022 - val_mae: 859.7022\n",
      "Epoch 11/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 888.9991 - mae: 888.9991 - val_loss: 856.4753 - val_mae: 856.4753\n",
      "Epoch 12/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 887.1459 - mae: 887.1459 - val_loss: 864.0412 - val_mae: 864.0412\n",
      "Epoch 13/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 884.0270 - mae: 884.0270 - val_loss: 855.4097 - val_mae: 855.4097\n",
      "Epoch 14/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 886.3795 - mae: 886.3795 - val_loss: 856.5912 - val_mae: 856.5912\n",
      "Epoch 15/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.3796 - mae: 884.3796 - val_loss: 860.5971 - val_mae: 860.5971\n",
      "Epoch 16/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 887.9805 - mae: 887.9805 - val_loss: 859.5404 - val_mae: 859.5404\n",
      "Epoch 17/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.3890 - mae: 885.3890 - val_loss: 855.9384 - val_mae: 855.9384\n",
      "Epoch 18/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 886.3914 - mae: 886.3914 - val_loss: 858.2115 - val_mae: 858.2115\n",
      "Epoch 19/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 886.3533 - mae: 886.3533 - val_loss: 855.9354 - val_mae: 855.9354\n",
      "Epoch 20/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 887.4058 - mae: 887.4058 - val_loss: 855.8297 - val_mae: 855.8297\n",
      "Epoch 21/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 886.9182 - mae: 886.9182 - val_loss: 854.9763 - val_mae: 854.9763\n",
      "Epoch 22/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.4993 - mae: 885.4993 - val_loss: 859.9112 - val_mae: 859.9112\n",
      "Epoch 23/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.6526 - mae: 885.6526 - val_loss: 858.2693 - val_mae: 858.2693\n",
      "Epoch 24/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 887.2275 - mae: 887.2275 - val_loss: 860.2916 - val_mae: 860.2916\n",
      "Epoch 25/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.7423 - mae: 884.7423 - val_loss: 862.7207 - val_mae: 862.7207\n",
      "Epoch 26/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.9673 - mae: 885.9673 - val_loss: 859.5855 - val_mae: 859.5855\n",
      "Epoch 27/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.5266 - mae: 882.5266 - val_loss: 858.5161 - val_mae: 858.5161\n",
      "Epoch 28/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.2084 - mae: 885.2084 - val_loss: 858.2431 - val_mae: 858.2431\n",
      "Epoch 29/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.7892 - mae: 885.7892 - val_loss: 855.4340 - val_mae: 855.4340\n",
      "Epoch 30/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.8434 - mae: 885.8434 - val_loss: 856.7994 - val_mae: 856.7994\n",
      "Epoch 31/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.9253 - mae: 885.9253 - val_loss: 855.9178 - val_mae: 855.9178\n",
      "Epoch 32/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.8865 - mae: 884.8865 - val_loss: 856.1754 - val_mae: 856.1754\n",
      "Epoch 33/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.6741 - mae: 883.6741 - val_loss: 858.1647 - val_mae: 858.1647\n",
      "Epoch 34/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.4756 - mae: 885.4756 - val_loss: 854.5215 - val_mae: 854.5215\n",
      "Epoch 35/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.2440 - mae: 884.2440 - val_loss: 857.0401 - val_mae: 857.0401\n",
      "Epoch 36/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.2673 - mae: 884.2673 - val_loss: 861.0419 - val_mae: 861.0419\n",
      "Epoch 37/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 887.6194 - mae: 887.6194 - val_loss: 858.4713 - val_mae: 858.4713\n",
      "Epoch 38/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.9865 - mae: 884.9865 - val_loss: 854.6019 - val_mae: 854.6019\n",
      "Epoch 39/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.6564 - mae: 885.6564 - val_loss: 856.1403 - val_mae: 856.1403\n",
      "Epoch 40/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.4088 - mae: 883.4088 - val_loss: 856.3232 - val_mae: 856.3232\n",
      "Epoch 41/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.3757 - mae: 882.3757 - val_loss: 859.2739 - val_mae: 859.2739\n",
      "Epoch 42/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.6645 - mae: 884.6645 - val_loss: 855.7272 - val_mae: 855.7272\n",
      "Epoch 43/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.0235 - mae: 884.0235 - val_loss: 857.3834 - val_mae: 857.3834\n",
      "Epoch 44/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.6528 - mae: 884.6528 - val_loss: 855.4906 - val_mae: 855.4906\n",
      "Epoch 45/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.3599 - mae: 884.3599 - val_loss: 861.8598 - val_mae: 861.8598\n",
      "Epoch 46/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.6785 - mae: 884.6785 - val_loss: 861.1691 - val_mae: 861.1691\n",
      "Epoch 47/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 886.2137 - mae: 886.2137 - val_loss: 860.2610 - val_mae: 860.2610\n",
      "Epoch 48/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 886.1677 - mae: 886.1677 - val_loss: 857.2462 - val_mae: 857.2462\n",
      "Epoch 49/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.2758 - mae: 884.2758 - val_loss: 856.7978 - val_mae: 856.7978\n",
      "Epoch 50/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.0508 - mae: 884.0508 - val_loss: 860.8182 - val_mae: 860.8182\n",
      "Epoch 51/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.7487 - mae: 884.7487 - val_loss: 864.6976 - val_mae: 864.6976\n",
      "Epoch 52/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.1825 - mae: 883.1825 - val_loss: 855.9186 - val_mae: 855.9186\n",
      "Epoch 53/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.7893 - mae: 881.7893 - val_loss: 862.0250 - val_mae: 862.0250\n",
      "Epoch 54/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 886.8947 - mae: 886.8947 - val_loss: 853.8132 - val_mae: 853.8132\n",
      "Epoch 55/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.2700 - mae: 883.2700 - val_loss: 855.1030 - val_mae: 855.1030\n",
      "Epoch 56/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.9280 - mae: 884.9280 - val_loss: 854.5679 - val_mae: 854.5679\n",
      "Epoch 57/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.9604 - mae: 883.9604 - val_loss: 862.0571 - val_mae: 862.0571\n",
      "Epoch 58/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.5026 - mae: 883.5026 - val_loss: 856.1954 - val_mae: 856.1954\n",
      "Epoch 59/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.2446 - mae: 884.2446 - val_loss: 855.7413 - val_mae: 855.7413\n",
      "Epoch 60/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.1071 - mae: 885.1071 - val_loss: 855.7424 - val_mae: 855.7424\n",
      "Epoch 61/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.8358 - mae: 884.8358 - val_loss: 852.4691 - val_mae: 852.4691\n",
      "Epoch 62/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.1310 - mae: 882.1310 - val_loss: 853.9691 - val_mae: 853.9691\n",
      "Epoch 63/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.2876 - mae: 881.2876 - val_loss: 855.1261 - val_mae: 855.1261\n",
      "Epoch 64/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.8515 - mae: 883.8515 - val_loss: 853.2465 - val_mae: 853.2465\n",
      "Epoch 65/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.5618 - mae: 882.5618 - val_loss: 853.3680 - val_mae: 853.3680\n",
      "Epoch 66/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.6492 - mae: 880.6492 - val_loss: 858.2352 - val_mae: 858.2352\n",
      "Epoch 67/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.0002 - mae: 882.0002 - val_loss: 858.5703 - val_mae: 858.5703\n",
      "Epoch 68/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.6107 - mae: 881.6107 - val_loss: 853.8370 - val_mae: 853.8370\n",
      "Epoch 69/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.2073 - mae: 881.2073 - val_loss: 854.4604 - val_mae: 854.4604\n",
      "Epoch 70/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.3394 - mae: 883.3394 - val_loss: 853.3809 - val_mae: 853.3809\n",
      "Epoch 71/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.8745 - mae: 884.8745 - val_loss: 852.1285 - val_mae: 852.1285\n",
      "Epoch 72/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.1949 - mae: 881.1949 - val_loss: 852.9011 - val_mae: 852.9011\n",
      "Epoch 73/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.6161 - mae: 880.6161 - val_loss: 857.6026 - val_mae: 857.6026\n",
      "Epoch 74/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.6657 - mae: 883.6657 - val_loss: 852.5696 - val_mae: 852.5696\n",
      "Epoch 75/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.0685 - mae: 883.0685 - val_loss: 855.0394 - val_mae: 855.0394\n",
      "Epoch 76/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.0010 - mae: 884.0010 - val_loss: 853.2867 - val_mae: 853.2867\n",
      "Epoch 77/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.4664 - mae: 882.4664 - val_loss: 852.9867 - val_mae: 852.9867\n",
      "Epoch 78/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.1185 - mae: 883.1185 - val_loss: 854.1436 - val_mae: 854.1436\n",
      "Epoch 79/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.3274 - mae: 882.3274 - val_loss: 857.8728 - val_mae: 857.8728\n",
      "Epoch 80/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.6428 - mae: 879.6428 - val_loss: 853.3175 - val_mae: 853.3175\n",
      "Epoch 81/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.2136 - mae: 880.2136 - val_loss: 854.9360 - val_mae: 854.9360\n",
      "Epoch 82/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.4113 - mae: 881.4113 - val_loss: 851.2736 - val_mae: 851.2736\n",
      "Epoch 83/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.5135 - mae: 882.5135 - val_loss: 851.7668 - val_mae: 851.7668\n",
      "Epoch 84/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.5004 - mae: 883.5004 - val_loss: 853.2879 - val_mae: 853.2879\n",
      "Epoch 85/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.0231 - mae: 883.0231 - val_loss: 853.4767 - val_mae: 853.4767\n",
      "Epoch 86/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.1075 - mae: 884.1075 - val_loss: 855.0032 - val_mae: 855.0032\n",
      "Epoch 87/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.3823 - mae: 883.3823 - val_loss: 854.0527 - val_mae: 854.0527\n",
      "Epoch 88/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.7093 - mae: 880.7093 - val_loss: 851.5709 - val_mae: 851.5709\n",
      "Epoch 89/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.6625 - mae: 879.6625 - val_loss: 855.5127 - val_mae: 855.5127\n",
      "Epoch 90/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.9089 - mae: 879.9089 - val_loss: 852.2503 - val_mae: 852.2503\n",
      "Epoch 91/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.6547 - mae: 879.6547 - val_loss: 856.3595 - val_mae: 856.3595\n",
      "Epoch 92/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.8295 - mae: 881.8295 - val_loss: 852.5416 - val_mae: 852.5416\n",
      "Epoch 93/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.1237 - mae: 880.1237 - val_loss: 852.9770 - val_mae: 852.9770\n",
      "Epoch 94/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.8861 - mae: 879.8861 - val_loss: 851.3955 - val_mae: 851.3955\n",
      "Epoch 95/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.2977 - mae: 882.2977 - val_loss: 850.4564 - val_mae: 850.4564\n",
      "Epoch 96/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.1354 - mae: 880.1354 - val_loss: 850.3734 - val_mae: 850.3734\n",
      "Epoch 97/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.0306 - mae: 881.0306 - val_loss: 852.0034 - val_mae: 852.0034\n",
      "Epoch 98/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.5396 - mae: 883.5396 - val_loss: 850.9739 - val_mae: 850.9739\n",
      "Epoch 99/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.8156 - mae: 880.8156 - val_loss: 851.0396 - val_mae: 851.0396\n",
      "Epoch 100/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.2940 - mae: 882.2940 - val_loss: 854.3723 - val_mae: 854.3723\n",
      "Epoch 101/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.1827 - mae: 883.1827 - val_loss: 851.1777 - val_mae: 851.1777\n",
      "Epoch 102/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.3550 - mae: 879.3550 - val_loss: 851.9796 - val_mae: 851.9796\n",
      "Epoch 103/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.8612 - mae: 880.8612 - val_loss: 853.8686 - val_mae: 853.8686\n",
      "Epoch 104/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.5931 - mae: 881.5931 - val_loss: 858.1328 - val_mae: 858.1328\n",
      "Epoch 105/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.4020 - mae: 881.4020 - val_loss: 855.0620 - val_mae: 855.0620\n",
      "Epoch 106/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.0264 - mae: 881.0264 - val_loss: 858.1738 - val_mae: 858.1738\n",
      "Epoch 107/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.9498 - mae: 880.9498 - val_loss: 850.9185 - val_mae: 850.9185\n",
      "Epoch 108/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.6590 - mae: 880.6590 - val_loss: 851.8622 - val_mae: 851.8622\n",
      "Epoch 109/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.4819 - mae: 879.4819 - val_loss: 853.3907 - val_mae: 853.3907\n",
      "Epoch 110/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.5717 - mae: 878.5717 - val_loss: 853.9318 - val_mae: 853.9318\n",
      "Epoch 111/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.5867 - mae: 879.5867 - val_loss: 854.2532 - val_mae: 854.2532\n",
      "Epoch 112/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.0276 - mae: 881.0276 - val_loss: 850.4203 - val_mae: 850.4203\n",
      "Epoch 113/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.4573 - mae: 880.4573 - val_loss: 852.8492 - val_mae: 852.8492\n",
      "Epoch 114/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.9612 - mae: 877.9612 - val_loss: 851.1081 - val_mae: 851.1081\n",
      "Epoch 115/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.7778 - mae: 878.7778 - val_loss: 850.3834 - val_mae: 850.3834\n",
      "Epoch 116/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.0926 - mae: 880.0926 - val_loss: 851.8160 - val_mae: 851.8160\n",
      "Epoch 117/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.8610 - mae: 881.8610 - val_loss: 852.9177 - val_mae: 852.9177\n",
      "Epoch 118/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.4813 - mae: 879.4813 - val_loss: 850.7571 - val_mae: 850.7571\n",
      "Epoch 119/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.0768 - mae: 878.0768 - val_loss: 850.1243 - val_mae: 850.1243\n",
      "Epoch 120/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.8345 - mae: 880.8345 - val_loss: 850.5067 - val_mae: 850.5067\n",
      "Epoch 121/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.1425 - mae: 881.1425 - val_loss: 851.9981 - val_mae: 851.9981\n",
      "Epoch 122/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.0525 - mae: 880.0525 - val_loss: 850.8776 - val_mae: 850.8776\n",
      "Epoch 123/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.4382 - mae: 879.4382 - val_loss: 850.7374 - val_mae: 850.7374\n",
      "Epoch 124/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.5917 - mae: 878.5917 - val_loss: 851.6331 - val_mae: 851.6331\n",
      "Epoch 125/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.2924 - mae: 881.2924 - val_loss: 851.4835 - val_mae: 851.4835\n",
      "Epoch 126/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.8689 - mae: 880.8689 - val_loss: 854.5515 - val_mae: 854.5515\n",
      "Epoch 127/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.0594 - mae: 878.0594 - val_loss: 854.7349 - val_mae: 854.7349\n",
      "Epoch 128/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.6450 - mae: 878.6450 - val_loss: 850.3123 - val_mae: 850.3123\n",
      "Epoch 129/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.4252 - mae: 877.4252 - val_loss: 859.6513 - val_mae: 859.6513\n",
      "Epoch 130/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.9417 - mae: 878.9417 - val_loss: 850.3903 - val_mae: 850.3903\n",
      "Epoch 131/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.2640 - mae: 879.2640 - val_loss: 850.4734 - val_mae: 850.4734\n",
      "Epoch 132/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.7178 - mae: 877.7178 - val_loss: 852.2296 - val_mae: 852.2296\n",
      "Epoch 133/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.4841 - mae: 879.4841 - val_loss: 850.3942 - val_mae: 850.3942\n",
      "Epoch 134/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.9508 - mae: 878.9508 - val_loss: 850.2939 - val_mae: 850.2939\n",
      "Epoch 135/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.2801 - mae: 878.2801 - val_loss: 851.2921 - val_mae: 851.2921\n",
      "Epoch 136/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.0450 - mae: 881.0450 - val_loss: 850.8199 - val_mae: 850.8199\n",
      "Epoch 137/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.1932 - mae: 879.1932 - val_loss: 850.7102 - val_mae: 850.7102\n",
      "Epoch 138/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.1368 - mae: 880.1368 - val_loss: 852.6901 - val_mae: 852.6901\n",
      "Epoch 139/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.5529 - mae: 878.5529 - val_loss: 850.4692 - val_mae: 850.4692\n",
      "Epoch 140/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 875.1557 - mae: 875.1557 - val_loss: 850.7303 - val_mae: 850.7303\n",
      "Epoch 141/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 878.1177 - mae: 878.1177 - val_loss: 853.7463 - val_mae: 853.7463\n",
      "Epoch 142/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 881.3375 - mae: 881.3375 - val_loss: 850.4051 - val_mae: 850.4051\n",
      "Epoch 143/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 878.3644 - mae: 878.3644 - val_loss: 851.2277 - val_mae: 851.2277\n",
      "Epoch 144/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 877.7043 - mae: 877.7043 - val_loss: 853.4604 - val_mae: 853.4604\n",
      "Epoch 145/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.0425 - mae: 880.0425 - val_loss: 850.2830 - val_mae: 850.2830\n",
      "Epoch 146/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.3699 - mae: 879.3699 - val_loss: 854.6268 - val_mae: 854.6268\n",
      "Epoch 147/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.2348 - mae: 878.2348 - val_loss: 849.9977 - val_mae: 849.9977\n",
      "Epoch 148/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.3262 - mae: 879.3262 - val_loss: 852.3483 - val_mae: 852.3483\n",
      "Epoch 149/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.7104 - mae: 877.7104 - val_loss: 851.0848 - val_mae: 851.0848\n",
      "Epoch 150/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.1871 - mae: 876.1871 - val_loss: 852.0093 - val_mae: 852.0093\n",
      "Epoch 151/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.6303 - mae: 878.6303 - val_loss: 851.4035 - val_mae: 851.4035\n",
      "Epoch 152/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.5987 - mae: 878.5987 - val_loss: 852.8124 - val_mae: 852.8124\n",
      "Epoch 153/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.2245 - mae: 878.2245 - val_loss: 853.0190 - val_mae: 853.0190\n",
      "Epoch 154/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.2598 - mae: 876.2598 - val_loss: 851.4082 - val_mae: 851.4082\n",
      "Epoch 155/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.7368 - mae: 877.7368 - val_loss: 851.6450 - val_mae: 851.6450\n",
      "Epoch 156/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.2536 - mae: 876.2536 - val_loss: 850.7456 - val_mae: 850.7456\n",
      "Epoch 157/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.1149 - mae: 879.1149 - val_loss: 850.6879 - val_mae: 850.6879\n",
      "Epoch 158/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.9557 - mae: 878.9557 - val_loss: 854.3467 - val_mae: 854.3467\n",
      "Epoch 159/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.0585 - mae: 878.0585 - val_loss: 850.6996 - val_mae: 850.6996\n",
      "Epoch 160/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 879.3492 - mae: 879.3492 - val_loss: 853.1356 - val_mae: 853.1356\n",
      "Epoch 161/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.1271 - mae: 877.1271 - val_loss: 857.7972 - val_mae: 857.7972\n",
      "Epoch 162/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 877.4359 - mae: 877.4359 - val_loss: 851.2174 - val_mae: 851.2174\n",
      "Epoch 163/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.2137 - mae: 878.2137 - val_loss: 850.6568 - val_mae: 850.6568\n",
      "Epoch 164/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.4257 - mae: 878.4257 - val_loss: 850.6998 - val_mae: 850.6998\n",
      "Epoch 165/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.4388 - mae: 876.4388 - val_loss: 851.4003 - val_mae: 851.4003\n",
      "Epoch 166/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.3116 - mae: 877.3116 - val_loss: 851.5015 - val_mae: 851.5015\n",
      "Epoch 167/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.6620 - mae: 877.6620 - val_loss: 850.9263 - val_mae: 850.9263\n",
      "Epoch 168/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.0836 - mae: 877.0836 - val_loss: 851.8453 - val_mae: 851.8453\n",
      "Epoch 169/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.9362 - mae: 880.9362 - val_loss: 855.0366 - val_mae: 855.0366\n",
      "Epoch 170/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.8854 - mae: 876.8854 - val_loss: 850.7495 - val_mae: 850.7495\n",
      "Epoch 171/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.5186 - mae: 877.5186 - val_loss: 852.0675 - val_mae: 852.0675\n",
      "Epoch 172/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.3562 - mae: 876.3562 - val_loss: 853.8782 - val_mae: 853.8782\n",
      "Epoch 173/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.1456 - mae: 877.1456 - val_loss: 855.9380 - val_mae: 855.9380\n",
      "Epoch 174/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.7404 - mae: 877.7404 - val_loss: 855.8951 - val_mae: 855.8951\n",
      "Epoch 175/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.5118 - mae: 877.5118 - val_loss: 851.5638 - val_mae: 851.5638\n",
      "Epoch 176/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.7219 - mae: 876.7219 - val_loss: 853.7952 - val_mae: 853.7952\n",
      "Epoch 177/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.7232 - mae: 877.7232 - val_loss: 853.9954 - val_mae: 853.9954\n",
      "Epoch 178/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.9453 - mae: 877.9453 - val_loss: 851.4022 - val_mae: 851.4022\n",
      "Epoch 179/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 874.7816 - mae: 874.7816 - val_loss: 850.3375 - val_mae: 850.3375\n",
      "Epoch 180/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 875.2123 - mae: 875.2123 - val_loss: 852.3236 - val_mae: 852.3236\n",
      "Epoch 181/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 875.9902 - mae: 875.9902 - val_loss: 851.1594 - val_mae: 851.1594\n",
      "Epoch 182/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.7709 - mae: 877.7709 - val_loss: 852.0752 - val_mae: 852.0752\n",
      "Epoch 183/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 875.2017 - mae: 875.2017 - val_loss: 851.9766 - val_mae: 851.9766\n",
      "Epoch 184/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.6182 - mae: 876.6182 - val_loss: 850.6097 - val_mae: 850.6097\n",
      "Epoch 185/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 875.5869 - mae: 875.5869 - val_loss: 851.8210 - val_mae: 851.8210\n",
      "Epoch 186/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.8271 - mae: 877.8271 - val_loss: 853.5264 - val_mae: 853.5264\n",
      "Epoch 187/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.3868 - mae: 878.3868 - val_loss: 850.9951 - val_mae: 850.9951\n",
      "Epoch 188/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 874.2373 - mae: 874.2373 - val_loss: 850.9021 - val_mae: 850.9021\n",
      "Epoch 189/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 875.7081 - mae: 875.7081 - val_loss: 851.9033 - val_mae: 851.9033\n",
      "Epoch 190/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 875.2909 - mae: 875.2909 - val_loss: 850.1813 - val_mae: 850.1813\n",
      "Epoch 191/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 874.9239 - mae: 874.9239 - val_loss: 849.7163 - val_mae: 849.7163\n",
      "Epoch 192/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.4738 - mae: 876.4738 - val_loss: 853.0871 - val_mae: 853.0871\n",
      "Epoch 193/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 874.7089 - mae: 874.7089 - val_loss: 850.7549 - val_mae: 850.7549\n",
      "Epoch 194/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.0586 - mae: 876.0586 - val_loss: 850.9194 - val_mae: 850.9194\n",
      "Epoch 195/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 875.4804 - mae: 875.4804 - val_loss: 851.6577 - val_mae: 851.6577\n",
      "Epoch 196/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.6270 - mae: 876.6270 - val_loss: 852.8732 - val_mae: 852.8732\n",
      "Epoch 197/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 874.4006 - mae: 874.4006 - val_loss: 855.3442 - val_mae: 855.3442\n",
      "Epoch 198/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.1746 - mae: 876.1746 - val_loss: 854.8426 - val_mae: 854.8426\n",
      "Epoch 199/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 871.4369 - mae: 871.4369 - val_loss: 851.8312 - val_mae: 851.8312\n",
      "Epoch 200/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 874.6572 - mae: 874.6572 - val_loss: 850.3638 - val_mae: 850.3638\n",
      "Fold 2 - Loss: 850.3638, MAE: 850.3638\n",
      "236/236 [==============================] - 0s 464us/step\n",
      "Fold 3 / 5\n",
      "Epoch 1/200\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 2124.1470 - mae: 2124.1470 - val_loss: 1039.2418 - val_mae: 1039.2418\n",
      "Epoch 2/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 958.4584 - mae: 958.4584 - val_loss: 877.0192 - val_mae: 877.0192\n",
      "Epoch 3/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 891.8152 - mae: 891.8152 - val_loss: 865.4581 - val_mae: 865.4581\n",
      "Epoch 4/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 887.6494 - mae: 887.6494 - val_loss: 862.1708 - val_mae: 862.1708\n",
      "Epoch 5/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.5966 - mae: 885.5966 - val_loss: 864.7723 - val_mae: 864.7723\n",
      "Epoch 6/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.8365 - mae: 883.8365 - val_loss: 867.5308 - val_mae: 867.5308\n",
      "Epoch 7/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 886.9427 - mae: 886.9427 - val_loss: 863.5090 - val_mae: 863.5090\n",
      "Epoch 8/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 887.5494 - mae: 887.5494 - val_loss: 864.7051 - val_mae: 864.7051\n",
      "Epoch 9/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.4729 - mae: 884.4729 - val_loss: 861.9388 - val_mae: 861.9388\n",
      "Epoch 10/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 887.9059 - mae: 887.9059 - val_loss: 865.4498 - val_mae: 865.4498\n",
      "Epoch 11/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.5935 - mae: 885.5935 - val_loss: 860.6154 - val_mae: 860.6154\n",
      "Epoch 12/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.7724 - mae: 882.7724 - val_loss: 861.5536 - val_mae: 861.5536\n",
      "Epoch 13/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 887.0482 - mae: 887.0482 - val_loss: 864.8317 - val_mae: 864.8317\n",
      "Epoch 14/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.2460 - mae: 884.2460 - val_loss: 860.2798 - val_mae: 860.2798\n",
      "Epoch 15/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.8548 - mae: 883.8548 - val_loss: 861.2451 - val_mae: 861.2451\n",
      "Epoch 16/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.3744 - mae: 884.3744 - val_loss: 863.7295 - val_mae: 863.7295\n",
      "Epoch 17/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.6624 - mae: 882.6624 - val_loss: 859.3553 - val_mae: 859.3553\n",
      "Epoch 18/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.5724 - mae: 884.5724 - val_loss: 867.4833 - val_mae: 867.4833\n",
      "Epoch 19/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.1318 - mae: 885.1318 - val_loss: 860.4002 - val_mae: 860.4002\n",
      "Epoch 20/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.7083 - mae: 883.7083 - val_loss: 862.7835 - val_mae: 862.7835\n",
      "Epoch 21/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.0121 - mae: 885.0121 - val_loss: 861.7982 - val_mae: 861.7982\n",
      "Epoch 22/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.3790 - mae: 882.3790 - val_loss: 859.0986 - val_mae: 859.0986\n",
      "Epoch 23/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.5381 - mae: 881.5381 - val_loss: 862.2061 - val_mae: 862.2061\n",
      "Epoch 24/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.7574 - mae: 884.7574 - val_loss: 867.0187 - val_mae: 867.0187\n",
      "Epoch 25/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.7722 - mae: 882.7722 - val_loss: 861.2489 - val_mae: 861.2489\n",
      "Epoch 26/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.3883 - mae: 881.3883 - val_loss: 859.3901 - val_mae: 859.3901\n",
      "Epoch 27/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 881.5867 - mae: 881.5867 - val_loss: 858.9847 - val_mae: 858.9847\n",
      "Epoch 28/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 883.2029 - mae: 883.2029 - val_loss: 866.5826 - val_mae: 866.5826\n",
      "Epoch 29/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.7724 - mae: 883.7724 - val_loss: 859.6996 - val_mae: 859.6996\n",
      "Epoch 30/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.7839 - mae: 882.7839 - val_loss: 860.5329 - val_mae: 860.5329\n",
      "Epoch 31/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.2625 - mae: 882.2625 - val_loss: 862.3184 - val_mae: 862.3184\n",
      "Epoch 32/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.3621 - mae: 882.3621 - val_loss: 860.2410 - val_mae: 860.2410\n",
      "Epoch 33/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.1635 - mae: 883.1635 - val_loss: 861.8096 - val_mae: 861.8096\n",
      "Epoch 34/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.4950 - mae: 883.4950 - val_loss: 860.3279 - val_mae: 860.3279\n",
      "Epoch 35/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.1793 - mae: 882.1793 - val_loss: 859.9725 - val_mae: 859.9725\n",
      "Epoch 36/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.1550 - mae: 881.1550 - val_loss: 860.9967 - val_mae: 860.9967\n",
      "Epoch 37/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.7332 - mae: 881.7332 - val_loss: 861.0204 - val_mae: 861.0204\n",
      "Epoch 38/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.5723 - mae: 883.5723 - val_loss: 868.6172 - val_mae: 868.6172\n",
      "Epoch 39/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.9167 - mae: 883.9167 - val_loss: 868.1525 - val_mae: 868.1525\n",
      "Epoch 40/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.1185 - mae: 883.1185 - val_loss: 862.8957 - val_mae: 862.8957\n",
      "Epoch 41/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 886.4719 - mae: 886.4719 - val_loss: 863.8361 - val_mae: 863.8361\n",
      "Epoch 42/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.2061 - mae: 885.2061 - val_loss: 864.6218 - val_mae: 864.6218\n",
      "Epoch 43/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.3676 - mae: 885.3676 - val_loss: 862.7357 - val_mae: 862.7357\n",
      "Epoch 44/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.5311 - mae: 883.5311 - val_loss: 866.5785 - val_mae: 866.5785\n",
      "Epoch 45/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.2472 - mae: 880.2472 - val_loss: 861.3362 - val_mae: 861.3362\n",
      "Epoch 46/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.7888 - mae: 883.7888 - val_loss: 861.4105 - val_mae: 861.4105\n",
      "Epoch 47/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.8225 - mae: 881.8225 - val_loss: 861.9734 - val_mae: 861.9734\n",
      "Epoch 48/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.9942 - mae: 882.9942 - val_loss: 861.1917 - val_mae: 861.1917\n",
      "Epoch 49/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.0396 - mae: 880.0396 - val_loss: 862.1769 - val_mae: 862.1769\n",
      "Epoch 50/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.8941 - mae: 880.8941 - val_loss: 861.3689 - val_mae: 861.3689\n",
      "Epoch 51/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.5961 - mae: 883.5961 - val_loss: 861.7933 - val_mae: 861.7933\n",
      "Epoch 52/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.5474 - mae: 882.5474 - val_loss: 867.7128 - val_mae: 867.7128\n",
      "Epoch 53/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.0673 - mae: 884.0673 - val_loss: 858.7769 - val_mae: 858.7769\n",
      "Epoch 54/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.9861 - mae: 883.9861 - val_loss: 862.8146 - val_mae: 862.8146\n",
      "Epoch 55/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.7695 - mae: 882.7695 - val_loss: 860.5691 - val_mae: 860.5691\n",
      "Epoch 56/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.4015 - mae: 883.4015 - val_loss: 861.4928 - val_mae: 861.4928\n",
      "Epoch 57/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.1600 - mae: 883.1600 - val_loss: 859.1812 - val_mae: 859.1812\n",
      "Epoch 58/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.7437 - mae: 882.7437 - val_loss: 860.3034 - val_mae: 860.3034\n",
      "Epoch 59/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.0744 - mae: 882.0744 - val_loss: 862.3925 - val_mae: 862.3925\n",
      "Epoch 60/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.7215 - mae: 882.7215 - val_loss: 859.3716 - val_mae: 859.3716\n",
      "Epoch 61/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.2593 - mae: 881.2593 - val_loss: 859.4630 - val_mae: 859.4630\n",
      "Epoch 62/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.8978 - mae: 882.8978 - val_loss: 862.2711 - val_mae: 862.2711\n",
      "Epoch 63/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.5602 - mae: 882.5602 - val_loss: 861.4222 - val_mae: 861.4222\n",
      "Epoch 64/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.8300 - mae: 880.8300 - val_loss: 863.0459 - val_mae: 863.0459\n",
      "Epoch 65/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.4568 - mae: 882.4568 - val_loss: 861.2017 - val_mae: 861.2017\n",
      "Epoch 66/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.0436 - mae: 880.0436 - val_loss: 860.3109 - val_mae: 860.3109\n",
      "Epoch 67/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.1042 - mae: 880.1042 - val_loss: 858.8228 - val_mae: 858.8228\n",
      "Epoch 68/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 880.1349 - mae: 880.1349 - val_loss: 861.8160 - val_mae: 861.8160\n",
      "Epoch 69/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 881.8613 - mae: 881.8613 - val_loss: 858.1899 - val_mae: 858.1899\n",
      "Epoch 70/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.2906 - mae: 879.2906 - val_loss: 860.7316 - val_mae: 860.7316\n",
      "Epoch 71/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.1636 - mae: 882.1636 - val_loss: 863.2394 - val_mae: 863.2394\n",
      "Epoch 72/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.2879 - mae: 882.2879 - val_loss: 859.4445 - val_mae: 859.4445\n",
      "Epoch 73/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.2209 - mae: 880.2209 - val_loss: 858.5012 - val_mae: 858.5012\n",
      "Epoch 74/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.2936 - mae: 883.2936 - val_loss: 858.2527 - val_mae: 858.2527\n",
      "Epoch 75/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.4495 - mae: 881.4495 - val_loss: 860.5507 - val_mae: 860.5507\n",
      "Epoch 76/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.1173 - mae: 880.1173 - val_loss: 860.2449 - val_mae: 860.2449\n",
      "Epoch 77/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.8853 - mae: 878.8853 - val_loss: 859.0948 - val_mae: 859.0948\n",
      "Epoch 78/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.4806 - mae: 878.4806 - val_loss: 858.7354 - val_mae: 858.7354\n",
      "Epoch 79/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.9537 - mae: 881.9537 - val_loss: 860.9376 - val_mae: 860.9376\n",
      "Epoch 80/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.6419 - mae: 880.6419 - val_loss: 857.4971 - val_mae: 857.4971\n",
      "Epoch 81/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.0390 - mae: 881.0390 - val_loss: 861.4590 - val_mae: 861.4590\n",
      "Epoch 82/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.5711 - mae: 881.5711 - val_loss: 858.6172 - val_mae: 858.6172\n",
      "Epoch 83/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.1297 - mae: 882.1297 - val_loss: 860.0026 - val_mae: 860.0026\n",
      "Epoch 84/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.0719 - mae: 882.0719 - val_loss: 857.4854 - val_mae: 857.4854\n",
      "Epoch 85/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.4221 - mae: 880.4221 - val_loss: 863.1514 - val_mae: 863.1514\n",
      "Epoch 86/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.1317 - mae: 880.1317 - val_loss: 858.5981 - val_mae: 858.5981\n",
      "Epoch 87/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.6537 - mae: 879.6537 - val_loss: 858.5589 - val_mae: 858.5589\n",
      "Epoch 88/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.1050 - mae: 881.1050 - val_loss: 859.1719 - val_mae: 859.1719\n",
      "Epoch 89/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.3842 - mae: 880.3842 - val_loss: 857.7556 - val_mae: 857.7556\n",
      "Epoch 90/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.5433 - mae: 879.5433 - val_loss: 861.8880 - val_mae: 861.8880\n",
      "Epoch 91/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.1109 - mae: 879.1109 - val_loss: 858.8763 - val_mae: 858.8763\n",
      "Epoch 92/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.8583 - mae: 880.8583 - val_loss: 859.0457 - val_mae: 859.0457\n",
      "Epoch 93/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.4733 - mae: 879.4733 - val_loss: 856.9828 - val_mae: 856.9828\n",
      "Epoch 94/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 881.2488 - mae: 881.2488 - val_loss: 859.2184 - val_mae: 859.2184\n",
      "Epoch 95/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 879.9888 - mae: 879.9888 - val_loss: 858.0746 - val_mae: 858.0746\n",
      "Epoch 96/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 876.3907 - mae: 876.3907 - val_loss: 858.5240 - val_mae: 858.5240\n",
      "Epoch 97/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.4583 - mae: 877.4583 - val_loss: 857.2148 - val_mae: 857.2148\n",
      "Epoch 98/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.9586 - mae: 879.9586 - val_loss: 864.1063 - val_mae: 864.1063\n",
      "Epoch 99/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.8647 - mae: 878.8647 - val_loss: 858.0696 - val_mae: 858.0696\n",
      "Epoch 100/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.8135 - mae: 877.8135 - val_loss: 858.0790 - val_mae: 858.0790\n",
      "Epoch 101/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.3322 - mae: 877.3322 - val_loss: 856.2462 - val_mae: 856.2462\n",
      "Epoch 102/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.7654 - mae: 877.7654 - val_loss: 858.7738 - val_mae: 858.7738\n",
      "Epoch 103/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 878.8924 - mae: 878.8924 - val_loss: 860.1558 - val_mae: 860.1558\n",
      "Epoch 104/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 878.3459 - mae: 878.3459 - val_loss: 855.9294 - val_mae: 855.9294\n",
      "Epoch 105/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 876.3730 - mae: 876.3730 - val_loss: 864.0469 - val_mae: 864.0469\n",
      "Epoch 106/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 878.4296 - mae: 878.4296 - val_loss: 856.9232 - val_mae: 856.9232\n",
      "Epoch 107/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.6982 - mae: 877.6982 - val_loss: 858.1358 - val_mae: 858.1358\n",
      "Epoch 108/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.5187 - mae: 877.5187 - val_loss: 860.8284 - val_mae: 860.8284\n",
      "Epoch 109/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.5881 - mae: 876.5881 - val_loss: 858.1183 - val_mae: 858.1183\n",
      "Epoch 110/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.4496 - mae: 878.4496 - val_loss: 856.6214 - val_mae: 856.6214\n",
      "Epoch 111/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.0753 - mae: 879.0753 - val_loss: 858.3086 - val_mae: 858.3086\n",
      "Epoch 112/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.6985 - mae: 876.6985 - val_loss: 855.6317 - val_mae: 855.6317\n",
      "Epoch 113/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.2711 - mae: 877.2711 - val_loss: 855.6277 - val_mae: 855.6277\n",
      "Epoch 114/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.5327 - mae: 879.5327 - val_loss: 858.1743 - val_mae: 858.1743\n",
      "Epoch 115/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.3976 - mae: 878.3976 - val_loss: 855.6326 - val_mae: 855.6326\n",
      "Epoch 116/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.5163 - mae: 876.5163 - val_loss: 861.6336 - val_mae: 861.6336\n",
      "Epoch 117/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 877.3844 - mae: 877.3844 - val_loss: 855.5586 - val_mae: 855.5586\n",
      "Epoch 118/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.2166 - mae: 878.2166 - val_loss: 859.9371 - val_mae: 859.9371\n",
      "Epoch 119/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 875.3870 - mae: 875.3870 - val_loss: 856.5299 - val_mae: 856.5299\n",
      "Epoch 120/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.2079 - mae: 877.2079 - val_loss: 856.8715 - val_mae: 856.8715\n",
      "Epoch 121/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.5759 - mae: 877.5759 - val_loss: 855.6805 - val_mae: 855.6805\n",
      "Epoch 122/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.5509 - mae: 876.5509 - val_loss: 855.5930 - val_mae: 855.5930\n",
      "Epoch 123/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.6561 - mae: 879.6561 - val_loss: 858.7955 - val_mae: 858.7955\n",
      "Epoch 124/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 875.4137 - mae: 875.4137 - val_loss: 856.3051 - val_mae: 856.3051\n",
      "Epoch 125/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.9196 - mae: 876.9196 - val_loss: 858.7868 - val_mae: 858.7868\n",
      "Epoch 126/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.4404 - mae: 877.4404 - val_loss: 856.5646 - val_mae: 856.5646\n",
      "Epoch 127/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 878.1290 - mae: 878.1290 - val_loss: 861.1269 - val_mae: 861.1269\n",
      "Epoch 128/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 877.5181 - mae: 877.5181 - val_loss: 856.9083 - val_mae: 856.9083\n",
      "Epoch 129/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 877.1837 - mae: 877.1837 - val_loss: 855.6924 - val_mae: 855.6924\n",
      "Epoch 130/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.6923 - mae: 876.6923 - val_loss: 856.2501 - val_mae: 856.2501\n",
      "Epoch 131/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 876.2918 - mae: 876.2918 - val_loss: 861.1763 - val_mae: 861.1763\n",
      "Epoch 132/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 877.7054 - mae: 877.7054 - val_loss: 862.7059 - val_mae: 862.7059\n",
      "Epoch 133/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 877.6538 - mae: 877.6538 - val_loss: 855.3839 - val_mae: 855.3839\n",
      "Epoch 134/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.6734 - mae: 876.6734 - val_loss: 855.2310 - val_mae: 855.2310\n",
      "Epoch 135/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 874.9193 - mae: 874.9193 - val_loss: 855.2313 - val_mae: 855.2313\n",
      "Epoch 136/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 876.3058 - mae: 876.3058 - val_loss: 854.5118 - val_mae: 854.5118\n",
      "Epoch 137/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 877.6290 - mae: 877.6290 - val_loss: 858.7023 - val_mae: 858.7023\n",
      "Epoch 138/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 876.2817 - mae: 876.2817 - val_loss: 854.9584 - val_mae: 854.9584\n",
      "Epoch 139/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 875.5124 - mae: 875.5124 - val_loss: 855.9595 - val_mae: 855.9595\n",
      "Epoch 140/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 875.8199 - mae: 875.8199 - val_loss: 854.4758 - val_mae: 854.4758\n",
      "Epoch 141/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.4929 - mae: 876.4929 - val_loss: 855.5547 - val_mae: 855.5547\n",
      "Epoch 142/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.3413 - mae: 877.3413 - val_loss: 856.5515 - val_mae: 856.5515\n",
      "Epoch 143/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 875.8767 - mae: 875.8767 - val_loss: 856.4335 - val_mae: 856.4335\n",
      "Epoch 144/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 875.0386 - mae: 875.0386 - val_loss: 860.2194 - val_mae: 860.2194\n",
      "Epoch 145/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 875.2292 - mae: 875.2292 - val_loss: 859.0992 - val_mae: 859.0992\n",
      "Epoch 146/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 875.1391 - mae: 875.1391 - val_loss: 854.6893 - val_mae: 854.6893\n",
      "Epoch 147/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 875.6854 - mae: 875.6854 - val_loss: 856.0493 - val_mae: 856.0493\n",
      "Epoch 148/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 875.5918 - mae: 875.5918 - val_loss: 855.5693 - val_mae: 855.5693\n",
      "Epoch 149/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 875.5779 - mae: 875.5779 - val_loss: 855.4076 - val_mae: 855.4076\n",
      "Epoch 150/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.1373 - mae: 878.1373 - val_loss: 856.0582 - val_mae: 856.0582\n",
      "Epoch 151/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 875.8807 - mae: 875.8807 - val_loss: 860.4352 - val_mae: 860.4352\n",
      "Epoch 152/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 873.7012 - mae: 873.7012 - val_loss: 856.5464 - val_mae: 856.5464\n",
      "Epoch 153/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 875.2469 - mae: 875.2469 - val_loss: 857.5924 - val_mae: 857.5924\n",
      "Epoch 154/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 872.8389 - mae: 872.8389 - val_loss: 854.9211 - val_mae: 854.9211\n",
      "Epoch 155/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 873.7567 - mae: 873.7567 - val_loss: 856.4836 - val_mae: 856.4836\n",
      "Epoch 156/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 875.6830 - mae: 875.6830 - val_loss: 856.6324 - val_mae: 856.6324\n",
      "Epoch 157/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 873.1293 - mae: 873.1293 - val_loss: 857.0350 - val_mae: 857.0350\n",
      "Epoch 158/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 874.4045 - mae: 874.4045 - val_loss: 854.9738 - val_mae: 854.9738\n",
      "Epoch 159/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 875.5742 - mae: 875.5742 - val_loss: 859.9858 - val_mae: 859.9858\n",
      "Epoch 160/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 874.5792 - mae: 874.5792 - val_loss: 855.8182 - val_mae: 855.8182\n",
      "Epoch 161/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 873.6124 - mae: 873.6124 - val_loss: 854.9314 - val_mae: 854.9314\n",
      "Epoch 162/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 873.1509 - mae: 873.1509 - val_loss: 857.8819 - val_mae: 857.8819\n",
      "Epoch 163/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 874.6036 - mae: 874.6036 - val_loss: 855.3347 - val_mae: 855.3347\n",
      "Epoch 164/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 874.7208 - mae: 874.7208 - val_loss: 855.8962 - val_mae: 855.8962\n",
      "Epoch 165/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 874.8905 - mae: 874.8905 - val_loss: 856.8776 - val_mae: 856.8776\n",
      "Epoch 166/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 873.2819 - mae: 873.2819 - val_loss: 856.3259 - val_mae: 856.3259\n",
      "Epoch 167/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 874.8003 - mae: 874.8003 - val_loss: 858.9666 - val_mae: 858.9666\n",
      "Epoch 168/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 873.3947 - mae: 873.3947 - val_loss: 854.9952 - val_mae: 854.9952\n",
      "Epoch 169/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 875.0405 - mae: 875.0405 - val_loss: 855.3303 - val_mae: 855.3303\n",
      "Epoch 170/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 873.9999 - mae: 873.9999 - val_loss: 858.8678 - val_mae: 858.8678\n",
      "Epoch 171/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 874.7728 - mae: 874.7728 - val_loss: 857.8949 - val_mae: 857.8949\n",
      "Epoch 172/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 873.1428 - mae: 873.1428 - val_loss: 855.2819 - val_mae: 855.2819\n",
      "Epoch 173/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 873.1406 - mae: 873.1406 - val_loss: 855.6634 - val_mae: 855.6634\n",
      "Epoch 174/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 875.9554 - mae: 875.9554 - val_loss: 856.0165 - val_mae: 856.0165\n",
      "Epoch 175/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 872.9280 - mae: 872.9280 - val_loss: 855.0025 - val_mae: 855.0025\n",
      "Epoch 176/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 872.2975 - mae: 872.2975 - val_loss: 860.3239 - val_mae: 860.3239\n",
      "Epoch 177/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 871.9581 - mae: 871.9581 - val_loss: 855.0213 - val_mae: 855.0213\n",
      "Epoch 178/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 873.7421 - mae: 873.7421 - val_loss: 855.2653 - val_mae: 855.2653\n",
      "Epoch 179/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 874.9763 - mae: 874.9763 - val_loss: 860.6415 - val_mae: 860.6415\n",
      "Epoch 180/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.4047 - mae: 876.4047 - val_loss: 855.1115 - val_mae: 855.1115\n",
      "Epoch 181/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 874.0378 - mae: 874.0378 - val_loss: 855.3337 - val_mae: 855.3337\n",
      "Epoch 182/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 874.1993 - mae: 874.1993 - val_loss: 859.5099 - val_mae: 859.5099\n",
      "Epoch 183/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.4540 - mae: 876.4540 - val_loss: 855.4442 - val_mae: 855.4442\n",
      "Epoch 184/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 872.6085 - mae: 872.6085 - val_loss: 855.2665 - val_mae: 855.2665\n",
      "Epoch 185/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 871.6710 - mae: 871.6710 - val_loss: 857.0540 - val_mae: 857.0540\n",
      "Epoch 186/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 873.0961 - mae: 873.0961 - val_loss: 855.6290 - val_mae: 855.6290\n",
      "Epoch 187/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 874.1197 - mae: 874.1197 - val_loss: 855.4084 - val_mae: 855.4084\n",
      "Epoch 188/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 871.0920 - mae: 871.0920 - val_loss: 856.8240 - val_mae: 856.8240\n",
      "Epoch 189/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 872.2920 - mae: 872.2920 - val_loss: 856.3622 - val_mae: 856.3622\n",
      "Epoch 190/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 871.1956 - mae: 871.1956 - val_loss: 856.2360 - val_mae: 856.2360\n",
      "Epoch 191/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 872.5970 - mae: 872.5970 - val_loss: 859.8457 - val_mae: 859.8457\n",
      "Epoch 192/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 870.9271 - mae: 870.9271 - val_loss: 855.5607 - val_mae: 855.5607\n",
      "Epoch 193/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 871.6812 - mae: 871.6812 - val_loss: 858.3333 - val_mae: 858.3333\n",
      "Epoch 194/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 874.1190 - mae: 874.1190 - val_loss: 855.4261 - val_mae: 855.4261\n",
      "Epoch 195/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 869.5928 - mae: 869.5928 - val_loss: 855.6002 - val_mae: 855.6002\n",
      "Epoch 196/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 873.3846 - mae: 873.3846 - val_loss: 856.7358 - val_mae: 856.7358\n",
      "Epoch 197/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 872.5275 - mae: 872.5275 - val_loss: 856.5978 - val_mae: 856.5978\n",
      "Epoch 198/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 875.3130 - mae: 875.3130 - val_loss: 855.6327 - val_mae: 855.6327\n",
      "Epoch 199/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 872.5621 - mae: 872.5621 - val_loss: 856.0801 - val_mae: 856.0801\n",
      "Epoch 200/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 871.4144 - mae: 871.4144 - val_loss: 856.3557 - val_mae: 856.3557\n",
      "Fold 3 - Loss: 856.3556, MAE: 856.3556\n",
      "236/236 [==============================] - 0s 518us/step\n",
      "Fold 4 / 5\n",
      "Epoch 1/200\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 2079.5222 - mae: 2079.5222 - val_loss: 1050.8353 - val_mae: 1050.8353\n",
      "Epoch 2/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 951.8341 - mae: 951.8341 - val_loss: 893.0737 - val_mae: 893.0737\n",
      "Epoch 3/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 888.5320 - mae: 888.5320 - val_loss: 877.3353 - val_mae: 877.3353\n",
      "Epoch 4/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.3793 - mae: 884.3793 - val_loss: 874.9822 - val_mae: 874.9822\n",
      "Epoch 5/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.3262 - mae: 884.3262 - val_loss: 874.5928 - val_mae: 874.5928\n",
      "Epoch 6/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.4148 - mae: 881.4148 - val_loss: 872.7532 - val_mae: 872.7532\n",
      "Epoch 7/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.6948 - mae: 883.6948 - val_loss: 872.9808 - val_mae: 872.9808\n",
      "Epoch 8/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.5845 - mae: 881.5845 - val_loss: 875.8075 - val_mae: 875.8075\n",
      "Epoch 9/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.2309 - mae: 882.2309 - val_loss: 870.8508 - val_mae: 870.8508\n",
      "Epoch 10/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.3300 - mae: 881.3300 - val_loss: 871.7344 - val_mae: 871.7344\n",
      "Epoch 11/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.6677 - mae: 880.6677 - val_loss: 879.9606 - val_mae: 879.9606\n",
      "Epoch 12/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.4708 - mae: 881.4708 - val_loss: 871.8882 - val_mae: 871.8882\n",
      "Epoch 13/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.6135 - mae: 881.6135 - val_loss: 876.5741 - val_mae: 876.5741\n",
      "Epoch 14/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.1271 - mae: 881.1271 - val_loss: 876.3710 - val_mae: 876.3710\n",
      "Epoch 15/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.5977 - mae: 881.5977 - val_loss: 871.1355 - val_mae: 871.1355\n",
      "Epoch 16/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.7887 - mae: 880.7887 - val_loss: 873.8665 - val_mae: 873.8665\n",
      "Epoch 17/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.9141 - mae: 880.9141 - val_loss: 872.1668 - val_mae: 872.1668\n",
      "Epoch 18/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.0690 - mae: 881.0690 - val_loss: 870.7460 - val_mae: 870.7460\n",
      "Epoch 19/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.6458 - mae: 881.6458 - val_loss: 875.7219 - val_mae: 875.7219\n",
      "Epoch 20/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.6722 - mae: 877.6722 - val_loss: 872.4293 - val_mae: 872.4293\n",
      "Epoch 21/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.7159 - mae: 880.7159 - val_loss: 876.5914 - val_mae: 876.5914\n",
      "Epoch 22/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.7333 - mae: 880.7333 - val_loss: 870.6432 - val_mae: 870.6432\n",
      "Epoch 23/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 882.1462 - mae: 882.1462 - val_loss: 869.4614 - val_mae: 869.4614\n",
      "Epoch 24/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 877.9576 - mae: 877.9576 - val_loss: 880.3176 - val_mae: 880.3176\n",
      "Epoch 25/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 879.1608 - mae: 879.1608 - val_loss: 872.7520 - val_mae: 872.7520\n",
      "Epoch 26/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 879.5732 - mae: 879.5732 - val_loss: 873.8293 - val_mae: 873.8293\n",
      "Epoch 27/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 880.7928 - mae: 880.7928 - val_loss: 877.8378 - val_mae: 877.8378\n",
      "Epoch 28/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.5592 - mae: 879.5592 - val_loss: 882.0689 - val_mae: 882.0689\n",
      "Epoch 29/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.6220 - mae: 877.6220 - val_loss: 874.4627 - val_mae: 874.4627\n",
      "Epoch 30/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.1683 - mae: 881.1683 - val_loss: 872.6413 - val_mae: 872.6413\n",
      "Epoch 31/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.7344 - mae: 880.7344 - val_loss: 869.5637 - val_mae: 869.5637\n",
      "Epoch 32/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.7418 - mae: 880.7418 - val_loss: 873.1304 - val_mae: 873.1304\n",
      "Epoch 33/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.3152 - mae: 880.3152 - val_loss: 871.6472 - val_mae: 871.6472\n",
      "Epoch 34/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.3157 - mae: 880.3157 - val_loss: 871.9877 - val_mae: 871.9877\n",
      "Epoch 35/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.2277 - mae: 879.2277 - val_loss: 878.8654 - val_mae: 878.8654\n",
      "Epoch 36/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.0339 - mae: 878.0339 - val_loss: 871.0662 - val_mae: 871.0662\n",
      "Epoch 37/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.5783 - mae: 879.5783 - val_loss: 873.5666 - val_mae: 873.5666\n",
      "Epoch 38/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.4109 - mae: 880.4109 - val_loss: 872.0659 - val_mae: 872.0659\n",
      "Epoch 39/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.8619 - mae: 876.8619 - val_loss: 870.7803 - val_mae: 870.7803\n",
      "Epoch 40/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.7225 - mae: 880.7225 - val_loss: 871.5369 - val_mae: 871.5369\n",
      "Epoch 41/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.0812 - mae: 877.0812 - val_loss: 871.3577 - val_mae: 871.3577\n",
      "Epoch 42/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.0651 - mae: 877.0651 - val_loss: 872.8612 - val_mae: 872.8612\n",
      "Epoch 43/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.8300 - mae: 880.8300 - val_loss: 873.8090 - val_mae: 873.8090\n",
      "Epoch 44/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.8813 - mae: 878.8813 - val_loss: 875.2166 - val_mae: 875.2166\n",
      "Epoch 45/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.5223 - mae: 880.5223 - val_loss: 873.3375 - val_mae: 873.3375\n",
      "Epoch 46/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.3035 - mae: 877.3035 - val_loss: 878.6438 - val_mae: 878.6438\n",
      "Epoch 47/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.5139 - mae: 879.5139 - val_loss: 874.1423 - val_mae: 874.1423\n",
      "Epoch 48/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.7056 - mae: 877.7056 - val_loss: 876.1826 - val_mae: 876.1826\n",
      "Epoch 49/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.5734 - mae: 877.5734 - val_loss: 874.4485 - val_mae: 874.4485\n",
      "Epoch 50/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.4022 - mae: 878.4022 - val_loss: 871.9980 - val_mae: 871.9980\n",
      "Epoch 51/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.2930 - mae: 880.2930 - val_loss: 869.0025 - val_mae: 869.0025\n",
      "Epoch 52/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.2833 - mae: 878.2833 - val_loss: 871.9871 - val_mae: 871.9871\n",
      "Epoch 53/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.8868 - mae: 878.8868 - val_loss: 871.1023 - val_mae: 871.1023\n",
      "Epoch 54/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.3550 - mae: 877.3550 - val_loss: 873.1552 - val_mae: 873.1552\n",
      "Epoch 55/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.0732 - mae: 879.0732 - val_loss: 870.7768 - val_mae: 870.7768\n",
      "Epoch 56/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.3036 - mae: 878.3036 - val_loss: 873.5745 - val_mae: 873.5745\n",
      "Epoch 57/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.7273 - mae: 879.7273 - val_loss: 869.0264 - val_mae: 869.0264\n",
      "Epoch 58/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.8335 - mae: 876.8335 - val_loss: 872.9922 - val_mae: 872.9922\n",
      "Epoch 59/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.4695 - mae: 879.4695 - val_loss: 871.6477 - val_mae: 871.6477\n",
      "Epoch 60/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.2562 - mae: 877.2562 - val_loss: 870.0087 - val_mae: 870.0087\n",
      "Epoch 61/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.6494 - mae: 878.6494 - val_loss: 874.6844 - val_mae: 874.6844\n",
      "Epoch 62/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.9091 - mae: 877.9091 - val_loss: 871.6992 - val_mae: 871.6992\n",
      "Epoch 63/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.7626 - mae: 876.7626 - val_loss: 871.0470 - val_mae: 871.0470\n",
      "Epoch 64/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.0756 - mae: 879.0756 - val_loss: 870.1968 - val_mae: 870.1968\n",
      "Epoch 65/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.4105 - mae: 877.4105 - val_loss: 875.2216 - val_mae: 875.2216\n",
      "Epoch 66/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.1841 - mae: 880.1841 - val_loss: 871.2289 - val_mae: 871.2289\n",
      "Epoch 67/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.2279 - mae: 880.2279 - val_loss: 869.7311 - val_mae: 869.7311\n",
      "Epoch 68/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.1515 - mae: 878.1515 - val_loss: 870.4827 - val_mae: 870.4827\n",
      "Epoch 69/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.2552 - mae: 879.2552 - val_loss: 876.6100 - val_mae: 876.6100\n",
      "Epoch 70/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.3039 - mae: 879.3039 - val_loss: 873.1362 - val_mae: 873.1362\n",
      "Epoch 71/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.6013 - mae: 878.6013 - val_loss: 870.7700 - val_mae: 870.7700\n",
      "Epoch 72/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.6414 - mae: 877.6414 - val_loss: 873.3169 - val_mae: 873.3169\n",
      "Epoch 73/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.5005 - mae: 876.5005 - val_loss: 869.0946 - val_mae: 869.0946\n",
      "Epoch 74/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.0329 - mae: 876.0329 - val_loss: 868.4654 - val_mae: 868.4654\n",
      "Epoch 75/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.7473 - mae: 876.7473 - val_loss: 871.8910 - val_mae: 871.8910\n",
      "Epoch 76/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.2899 - mae: 878.2899 - val_loss: 868.1177 - val_mae: 868.1177\n",
      "Epoch 77/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.7598 - mae: 876.7598 - val_loss: 872.8167 - val_mae: 872.8167\n",
      "Epoch 78/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.5150 - mae: 877.5150 - val_loss: 869.8174 - val_mae: 869.8174\n",
      "Epoch 79/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.9949 - mae: 876.9949 - val_loss: 867.9242 - val_mae: 867.9242\n",
      "Epoch 80/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.1555 - mae: 877.1555 - val_loss: 874.3264 - val_mae: 874.3264\n",
      "Epoch 81/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.7217 - mae: 878.7217 - val_loss: 870.2598 - val_mae: 870.2598\n",
      "Epoch 82/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.0705 - mae: 877.0705 - val_loss: 867.9706 - val_mae: 867.9706\n",
      "Epoch 83/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.4742 - mae: 878.4742 - val_loss: 873.5887 - val_mae: 873.5887\n",
      "Epoch 84/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.2194 - mae: 878.2194 - val_loss: 872.0029 - val_mae: 872.0029\n",
      "Epoch 85/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.2529 - mae: 876.2529 - val_loss: 872.7718 - val_mae: 872.7718\n",
      "Epoch 86/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 874.9642 - mae: 874.9642 - val_loss: 869.6342 - val_mae: 869.6342\n",
      "Epoch 87/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.0207 - mae: 878.0207 - val_loss: 872.6065 - val_mae: 872.6065\n",
      "Epoch 88/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 875.3433 - mae: 875.3433 - val_loss: 873.9392 - val_mae: 873.9392\n",
      "Epoch 89/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 875.3420 - mae: 875.3420 - val_loss: 869.5917 - val_mae: 869.5917\n",
      "Epoch 90/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 875.8846 - mae: 875.8846 - val_loss: 869.3563 - val_mae: 869.3563\n",
      "Epoch 91/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.7438 - mae: 876.7438 - val_loss: 872.1739 - val_mae: 872.1739\n",
      "Epoch 92/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 875.4968 - mae: 875.4968 - val_loss: 869.5671 - val_mae: 869.5671\n",
      "Epoch 93/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 874.8524 - mae: 874.8524 - val_loss: 871.8508 - val_mae: 871.8508\n",
      "Epoch 94/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.3404 - mae: 876.3404 - val_loss: 875.6151 - val_mae: 875.6151\n",
      "Epoch 95/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.3030 - mae: 877.3030 - val_loss: 871.2883 - val_mae: 871.2883\n",
      "Epoch 96/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.7129 - mae: 876.7129 - val_loss: 869.3963 - val_mae: 869.3963\n",
      "Epoch 97/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.5632 - mae: 876.5632 - val_loss: 870.9381 - val_mae: 870.9381\n",
      "Epoch 98/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.3697 - mae: 876.3697 - val_loss: 866.6438 - val_mae: 866.6438\n",
      "Epoch 99/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 874.5976 - mae: 874.5976 - val_loss: 867.7179 - val_mae: 867.7179\n",
      "Epoch 100/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 875.5981 - mae: 875.5981 - val_loss: 869.1845 - val_mae: 869.1845\n",
      "Epoch 101/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 874.2775 - mae: 874.2775 - val_loss: 867.2982 - val_mae: 867.2982\n",
      "Epoch 102/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 873.4169 - mae: 873.4169 - val_loss: 867.5075 - val_mae: 867.5075\n",
      "Epoch 103/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 874.6417 - mae: 874.6417 - val_loss: 869.7209 - val_mae: 869.7209\n",
      "Epoch 104/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 875.0652 - mae: 875.0652 - val_loss: 866.7170 - val_mae: 866.7170\n",
      "Epoch 105/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.6387 - mae: 876.6387 - val_loss: 865.9649 - val_mae: 865.9649\n",
      "Epoch 106/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 875.2544 - mae: 875.2544 - val_loss: 866.5170 - val_mae: 866.5170\n",
      "Epoch 107/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 875.5258 - mae: 875.5258 - val_loss: 866.8038 - val_mae: 866.8038\n",
      "Epoch 108/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.6102 - mae: 876.6102 - val_loss: 869.2720 - val_mae: 869.2720\n",
      "Epoch 109/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 875.5576 - mae: 875.5576 - val_loss: 868.3007 - val_mae: 868.3007\n",
      "Epoch 110/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 872.2315 - mae: 872.2315 - val_loss: 867.6326 - val_mae: 867.6326\n",
      "Epoch 111/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 871.3749 - mae: 871.3749 - val_loss: 870.2945 - val_mae: 870.2945\n",
      "Epoch 112/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 874.6592 - mae: 874.6592 - val_loss: 867.1234 - val_mae: 867.1234\n",
      "Epoch 113/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 874.9713 - mae: 874.9713 - val_loss: 869.2453 - val_mae: 869.2453\n",
      "Epoch 114/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 874.1934 - mae: 874.1934 - val_loss: 866.6708 - val_mae: 866.6708\n",
      "Epoch 115/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 872.6010 - mae: 872.6010 - val_loss: 866.6229 - val_mae: 866.6229\n",
      "Epoch 116/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 875.4600 - mae: 875.4600 - val_loss: 866.1121 - val_mae: 866.1121\n",
      "Epoch 117/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 873.5864 - mae: 873.5864 - val_loss: 867.3978 - val_mae: 867.3978\n",
      "Epoch 118/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 874.1992 - mae: 874.1992 - val_loss: 865.0051 - val_mae: 865.0051\n",
      "Epoch 119/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 873.9082 - mae: 873.9082 - val_loss: 869.5645 - val_mae: 869.5645\n",
      "Epoch 120/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 872.2880 - mae: 872.2880 - val_loss: 866.2819 - val_mae: 866.2819\n",
      "Epoch 121/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 874.9382 - mae: 874.9382 - val_loss: 869.5787 - val_mae: 869.5787\n",
      "Epoch 122/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 872.2594 - mae: 872.2594 - val_loss: 866.2658 - val_mae: 866.2658\n",
      "Epoch 123/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 870.9838 - mae: 870.9838 - val_loss: 870.4432 - val_mae: 870.4432\n",
      "Epoch 124/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 874.3442 - mae: 874.3442 - val_loss: 866.2084 - val_mae: 866.2084\n",
      "Epoch 125/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 872.6406 - mae: 872.6406 - val_loss: 870.9019 - val_mae: 870.9019\n",
      "Epoch 126/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 872.4750 - mae: 872.4750 - val_loss: 868.9894 - val_mae: 868.9894\n",
      "Epoch 127/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 874.5132 - mae: 874.5132 - val_loss: 868.5818 - val_mae: 868.5818\n",
      "Epoch 128/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 875.1309 - mae: 875.1309 - val_loss: 865.9590 - val_mae: 865.9590\n",
      "Epoch 129/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 873.4796 - mae: 873.4796 - val_loss: 871.6218 - val_mae: 871.6218\n",
      "Epoch 130/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 871.4518 - mae: 871.4518 - val_loss: 869.4821 - val_mae: 869.4821\n",
      "Epoch 131/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 872.2651 - mae: 872.2651 - val_loss: 868.7944 - val_mae: 868.7944\n",
      "Epoch 132/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 874.8801 - mae: 874.8801 - val_loss: 864.6137 - val_mae: 864.6137\n",
      "Epoch 133/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 871.7614 - mae: 871.7614 - val_loss: 865.8625 - val_mae: 865.8625\n",
      "Epoch 134/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 870.9604 - mae: 870.9604 - val_loss: 867.5944 - val_mae: 867.5944\n",
      "Epoch 135/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 875.1509 - mae: 875.1509 - val_loss: 867.9283 - val_mae: 867.9283\n",
      "Epoch 136/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 874.1951 - mae: 874.1951 - val_loss: 865.3046 - val_mae: 865.3046\n",
      "Epoch 137/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 873.5406 - mae: 873.5406 - val_loss: 864.9459 - val_mae: 864.9459\n",
      "Epoch 138/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 872.2427 - mae: 872.2427 - val_loss: 864.9340 - val_mae: 864.9340\n",
      "Epoch 139/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 872.0085 - mae: 872.0085 - val_loss: 869.5218 - val_mae: 869.5218\n",
      "Epoch 140/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 873.7445 - mae: 873.7445 - val_loss: 868.7318 - val_mae: 868.7318\n",
      "Epoch 141/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 871.1140 - mae: 871.1140 - val_loss: 867.9449 - val_mae: 867.9449\n",
      "Epoch 142/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 870.9077 - mae: 870.9077 - val_loss: 868.0674 - val_mae: 868.0674\n",
      "Epoch 143/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 871.0311 - mae: 871.0311 - val_loss: 864.5141 - val_mae: 864.5141\n",
      "Epoch 144/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 873.9135 - mae: 873.9135 - val_loss: 868.7175 - val_mae: 868.7175\n",
      "Epoch 145/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 872.2148 - mae: 872.2148 - val_loss: 869.4141 - val_mae: 869.4141\n",
      "Epoch 146/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 870.0930 - mae: 870.0930 - val_loss: 867.3635 - val_mae: 867.3635\n",
      "Epoch 147/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 873.2383 - mae: 873.2383 - val_loss: 865.8225 - val_mae: 865.8225\n",
      "Epoch 148/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 872.9481 - mae: 872.9481 - val_loss: 868.2002 - val_mae: 868.2002\n",
      "Epoch 149/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 872.0140 - mae: 872.0140 - val_loss: 867.2705 - val_mae: 867.2705\n",
      "Epoch 150/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 871.7001 - mae: 871.7001 - val_loss: 864.7296 - val_mae: 864.7296\n",
      "Epoch 151/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 870.5089 - mae: 870.5089 - val_loss: 867.5412 - val_mae: 867.5412\n",
      "Epoch 152/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 871.4814 - mae: 871.4814 - val_loss: 867.4243 - val_mae: 867.4243\n",
      "Epoch 153/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 872.7396 - mae: 872.7396 - val_loss: 871.4559 - val_mae: 871.4559\n",
      "Epoch 154/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 870.1823 - mae: 870.1823 - val_loss: 867.4322 - val_mae: 867.4322\n",
      "Epoch 155/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 870.0334 - mae: 870.0334 - val_loss: 865.2574 - val_mae: 865.2574\n",
      "Epoch 156/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 871.3466 - mae: 871.3466 - val_loss: 869.2350 - val_mae: 869.2350\n",
      "Epoch 157/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 871.2216 - mae: 871.2216 - val_loss: 868.2955 - val_mae: 868.2955\n",
      "Epoch 158/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 869.0835 - mae: 869.0835 - val_loss: 868.0325 - val_mae: 868.0325\n",
      "Epoch 159/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 872.0633 - mae: 872.0633 - val_loss: 864.6817 - val_mae: 864.6817\n",
      "Epoch 160/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 872.1609 - mae: 872.1609 - val_loss: 867.5773 - val_mae: 867.5773\n",
      "Epoch 161/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 871.3533 - mae: 871.3533 - val_loss: 867.5750 - val_mae: 867.5750\n",
      "Epoch 162/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 870.4935 - mae: 870.4935 - val_loss: 864.5110 - val_mae: 864.5110\n",
      "Epoch 163/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 871.1039 - mae: 871.1039 - val_loss: 867.5229 - val_mae: 867.5229\n",
      "Epoch 164/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 871.9869 - mae: 871.9869 - val_loss: 866.4876 - val_mae: 866.4876\n",
      "Epoch 165/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 873.0894 - mae: 873.0894 - val_loss: 864.6948 - val_mae: 864.6948\n",
      "Epoch 166/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 868.1043 - mae: 868.1043 - val_loss: 866.7819 - val_mae: 866.7819\n",
      "Epoch 167/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 871.6583 - mae: 871.6583 - val_loss: 864.4991 - val_mae: 864.4991\n",
      "Epoch 168/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 869.5549 - mae: 869.5549 - val_loss: 870.3361 - val_mae: 870.3361\n",
      "Epoch 169/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 868.7246 - mae: 868.7246 - val_loss: 867.1216 - val_mae: 867.1216\n",
      "Epoch 170/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 870.4432 - mae: 870.4432 - val_loss: 865.5876 - val_mae: 865.5876\n",
      "Epoch 171/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 871.3089 - mae: 871.3089 - val_loss: 869.0547 - val_mae: 869.0547\n",
      "Epoch 172/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 873.0020 - mae: 873.0020 - val_loss: 867.8396 - val_mae: 867.8396\n",
      "Epoch 173/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 871.3848 - mae: 871.3848 - val_loss: 866.5419 - val_mae: 866.5419\n",
      "Epoch 174/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 871.1902 - mae: 871.1902 - val_loss: 865.6996 - val_mae: 865.6996\n",
      "Epoch 175/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 870.6923 - mae: 870.6923 - val_loss: 868.8503 - val_mae: 868.8503\n",
      "Epoch 176/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 871.3014 - mae: 871.3014 - val_loss: 871.5854 - val_mae: 871.5854\n",
      "Epoch 177/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 870.0977 - mae: 870.0977 - val_loss: 866.5978 - val_mae: 866.5978\n",
      "Epoch 178/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 869.5811 - mae: 869.5811 - val_loss: 870.2824 - val_mae: 870.2824\n",
      "Epoch 179/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 869.8619 - mae: 869.8619 - val_loss: 865.6381 - val_mae: 865.6381\n",
      "Epoch 180/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 870.4574 - mae: 870.4574 - val_loss: 864.1085 - val_mae: 864.1085\n",
      "Epoch 181/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 869.5529 - mae: 869.5529 - val_loss: 865.9523 - val_mae: 865.9523\n",
      "Epoch 182/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 869.8789 - mae: 869.8789 - val_loss: 865.3179 - val_mae: 865.3179\n",
      "Epoch 183/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 868.7798 - mae: 868.7798 - val_loss: 864.5889 - val_mae: 864.5889\n",
      "Epoch 184/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 868.8136 - mae: 868.8136 - val_loss: 866.0558 - val_mae: 866.0558\n",
      "Epoch 185/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 871.5658 - mae: 871.5658 - val_loss: 868.5610 - val_mae: 868.5610\n",
      "Epoch 186/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 868.3684 - mae: 868.3684 - val_loss: 865.3542 - val_mae: 865.3542\n",
      "Epoch 187/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 869.2300 - mae: 869.2300 - val_loss: 872.0965 - val_mae: 872.0965\n",
      "Epoch 188/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 866.8067 - mae: 866.8067 - val_loss: 865.4428 - val_mae: 865.4428\n",
      "Epoch 189/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 868.6996 - mae: 868.6996 - val_loss: 866.5713 - val_mae: 866.5713\n",
      "Epoch 190/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 871.4618 - mae: 871.4618 - val_loss: 864.7267 - val_mae: 864.7267\n",
      "Epoch 191/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 867.9397 - mae: 867.9397 - val_loss: 864.4350 - val_mae: 864.4350\n",
      "Epoch 192/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 869.6895 - mae: 869.6895 - val_loss: 868.5724 - val_mae: 868.5724\n",
      "Epoch 193/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 867.9490 - mae: 867.9490 - val_loss: 865.3176 - val_mae: 865.3176\n",
      "Epoch 194/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 869.7399 - mae: 869.7399 - val_loss: 865.5469 - val_mae: 865.5469\n",
      "Epoch 195/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 867.5032 - mae: 867.5032 - val_loss: 865.6660 - val_mae: 865.6660\n",
      "Epoch 196/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 868.7408 - mae: 868.7408 - val_loss: 866.3168 - val_mae: 866.3168\n",
      "Epoch 197/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 869.0292 - mae: 869.0292 - val_loss: 864.7939 - val_mae: 864.7939\n",
      "Epoch 198/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 866.0933 - mae: 866.0933 - val_loss: 863.9118 - val_mae: 863.9118\n",
      "Epoch 199/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 870.5319 - mae: 870.5319 - val_loss: 866.7843 - val_mae: 866.7843\n",
      "Epoch 200/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 871.3076 - mae: 871.3076 - val_loss: 866.0995 - val_mae: 866.0995\n",
      "Fold 4 - Loss: 866.0995, MAE: 866.0995\n",
      "236/236 [==============================] - 0s 452us/step\n",
      "Fold 5 / 5\n",
      "Epoch 1/200\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 2170.6340 - mae: 2170.6340 - val_loss: 1037.7975 - val_mae: 1037.7975\n",
      "Epoch 2/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 973.4340 - mae: 973.4340 - val_loss: 867.2235 - val_mae: 867.2235\n",
      "Epoch 3/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 894.6553 - mae: 894.6553 - val_loss: 847.7032 - val_mae: 847.7032\n",
      "Epoch 4/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 892.1576 - mae: 892.1576 - val_loss: 844.5952 - val_mae: 844.5952\n",
      "Epoch 5/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 888.3929 - mae: 888.3929 - val_loss: 846.0007 - val_mae: 846.0007\n",
      "Epoch 6/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 890.6166 - mae: 890.6166 - val_loss: 844.8619 - val_mae: 844.8619\n",
      "Epoch 7/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 890.1319 - mae: 890.1319 - val_loss: 847.1533 - val_mae: 847.1533\n",
      "Epoch 8/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 889.4791 - mae: 889.4791 - val_loss: 845.8828 - val_mae: 845.8828\n",
      "Epoch 9/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 889.3426 - mae: 889.3426 - val_loss: 843.4470 - val_mae: 843.4470\n",
      "Epoch 10/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 886.0681 - mae: 886.0681 - val_loss: 850.5588 - val_mae: 850.5588\n",
      "Epoch 11/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 888.8500 - mae: 888.8500 - val_loss: 847.4178 - val_mae: 847.4178\n",
      "Epoch 12/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 890.0598 - mae: 890.0598 - val_loss: 845.4046 - val_mae: 845.4046\n",
      "Epoch 13/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 886.9805 - mae: 886.9805 - val_loss: 846.6073 - val_mae: 846.6073\n",
      "Epoch 14/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 888.6084 - mae: 888.6084 - val_loss: 846.4133 - val_mae: 846.4133\n",
      "Epoch 15/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 885.7703 - mae: 885.7703 - val_loss: 843.6019 - val_mae: 843.6019\n",
      "Epoch 16/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 885.9460 - mae: 885.9460 - val_loss: 844.1390 - val_mae: 844.1390\n",
      "Epoch 17/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 888.8274 - mae: 888.8274 - val_loss: 843.9956 - val_mae: 843.9956\n",
      "Epoch 18/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.2412 - mae: 885.2412 - val_loss: 843.5173 - val_mae: 843.5173\n",
      "Epoch 19/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 888.1700 - mae: 888.1700 - val_loss: 844.0355 - val_mae: 844.0355\n",
      "Epoch 20/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 887.8658 - mae: 887.8658 - val_loss: 849.7571 - val_mae: 849.7571\n",
      "Epoch 21/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 887.6929 - mae: 887.6929 - val_loss: 845.4952 - val_mae: 845.4952\n",
      "Epoch 22/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 887.5376 - mae: 887.5376 - val_loss: 844.4977 - val_mae: 844.4977\n",
      "Epoch 23/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 888.0511 - mae: 888.0511 - val_loss: 844.1685 - val_mae: 844.1685\n",
      "Epoch 24/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 887.2535 - mae: 887.2535 - val_loss: 844.0063 - val_mae: 844.0063\n",
      "Epoch 25/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 886.9774 - mae: 886.9774 - val_loss: 847.4423 - val_mae: 847.4423\n",
      "Epoch 26/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 885.1840 - mae: 885.1840 - val_loss: 844.5589 - val_mae: 844.5589\n",
      "Epoch 27/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 888.0630 - mae: 888.0630 - val_loss: 843.4822 - val_mae: 843.4822\n",
      "Epoch 28/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 888.4106 - mae: 888.4106 - val_loss: 845.3406 - val_mae: 845.3406\n",
      "Epoch 29/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 888.1454 - mae: 888.1454 - val_loss: 851.3148 - val_mae: 851.3148\n",
      "Epoch 30/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.4741 - mae: 885.4741 - val_loss: 846.6392 - val_mae: 846.6392\n",
      "Epoch 31/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 888.5530 - mae: 888.5530 - val_loss: 844.2250 - val_mae: 844.2250\n",
      "Epoch 32/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 888.9394 - mae: 888.9394 - val_loss: 843.1141 - val_mae: 843.1141\n",
      "Epoch 33/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.4919 - mae: 884.4919 - val_loss: 854.7552 - val_mae: 854.7552\n",
      "Epoch 34/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 888.7527 - mae: 888.7527 - val_loss: 843.9755 - val_mae: 843.9755\n",
      "Epoch 35/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 888.5173 - mae: 888.5173 - val_loss: 843.9774 - val_mae: 843.9774\n",
      "Epoch 36/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 886.3749 - mae: 886.3749 - val_loss: 843.4149 - val_mae: 843.4149\n",
      "Epoch 37/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 883.7435 - mae: 883.7435 - val_loss: 853.2225 - val_mae: 853.2225\n",
      "Epoch 38/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 887.1435 - mae: 887.1435 - val_loss: 842.4975 - val_mae: 842.4975\n",
      "Epoch 39/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 888.9249 - mae: 888.9249 - val_loss: 844.6842 - val_mae: 844.6842\n",
      "Epoch 40/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 887.8112 - mae: 887.8112 - val_loss: 845.0176 - val_mae: 845.0176\n",
      "Epoch 41/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 888.0516 - mae: 888.0516 - val_loss: 843.6058 - val_mae: 843.6058\n",
      "Epoch 42/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 886.4402 - mae: 886.4402 - val_loss: 844.2625 - val_mae: 844.2625\n",
      "Epoch 43/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 886.5742 - mae: 886.5742 - val_loss: 844.2880 - val_mae: 844.2880\n",
      "Epoch 44/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 885.4081 - mae: 885.4081 - val_loss: 842.0673 - val_mae: 842.0673\n",
      "Epoch 45/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 885.0817 - mae: 885.0817 - val_loss: 841.5943 - val_mae: 841.5943\n",
      "Epoch 46/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 885.1262 - mae: 885.1262 - val_loss: 845.7594 - val_mae: 845.7594\n",
      "Epoch 47/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 885.5540 - mae: 885.5540 - val_loss: 841.7399 - val_mae: 841.7399\n",
      "Epoch 48/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 888.0286 - mae: 888.0286 - val_loss: 843.6068 - val_mae: 843.6068\n",
      "Epoch 49/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 886.3527 - mae: 886.3527 - val_loss: 843.4081 - val_mae: 843.4081\n",
      "Epoch 50/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 886.9590 - mae: 886.9590 - val_loss: 846.1611 - val_mae: 846.1611\n",
      "Epoch 51/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 885.6547 - mae: 885.6547 - val_loss: 844.1932 - val_mae: 844.1932\n",
      "Epoch 52/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 886.7937 - mae: 886.7937 - val_loss: 844.7916 - val_mae: 844.7916\n",
      "Epoch 53/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 885.5967 - mae: 885.5967 - val_loss: 841.9051 - val_mae: 841.9051\n",
      "Epoch 54/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 885.6427 - mae: 885.6427 - val_loss: 847.4940 - val_mae: 847.4940\n",
      "Epoch 55/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 887.1343 - mae: 887.1343 - val_loss: 846.3767 - val_mae: 846.3767\n",
      "Epoch 56/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 885.7894 - mae: 885.7894 - val_loss: 842.1785 - val_mae: 842.1785\n",
      "Epoch 57/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 886.0464 - mae: 886.0464 - val_loss: 851.9561 - val_mae: 851.9561\n",
      "Epoch 58/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 886.1663 - mae: 886.1663 - val_loss: 842.6819 - val_mae: 842.6819\n",
      "Epoch 59/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.4730 - mae: 885.4730 - val_loss: 843.2247 - val_mae: 843.2247\n",
      "Epoch 60/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 883.6152 - mae: 883.6152 - val_loss: 848.6801 - val_mae: 848.6801\n",
      "Epoch 61/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 886.5359 - mae: 886.5359 - val_loss: 841.5672 - val_mae: 841.5672\n",
      "Epoch 62/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.8169 - mae: 885.8169 - val_loss: 848.0292 - val_mae: 848.0292\n",
      "Epoch 63/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 885.3521 - mae: 885.3521 - val_loss: 841.9164 - val_mae: 841.9164\n",
      "Epoch 64/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 886.3608 - mae: 886.3608 - val_loss: 847.4932 - val_mae: 847.4932\n",
      "Epoch 65/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 885.7543 - mae: 885.7543 - val_loss: 841.9943 - val_mae: 841.9943\n",
      "Epoch 66/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.4626 - mae: 885.4626 - val_loss: 842.7287 - val_mae: 842.7287\n",
      "Epoch 67/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 886.0036 - mae: 886.0036 - val_loss: 844.6686 - val_mae: 844.6686\n",
      "Epoch 68/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 887.4060 - mae: 887.4060 - val_loss: 845.9879 - val_mae: 845.9879\n",
      "Epoch 69/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.3521 - mae: 884.3521 - val_loss: 846.7172 - val_mae: 846.7172\n",
      "Epoch 70/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 886.3948 - mae: 886.3948 - val_loss: 843.3320 - val_mae: 843.3320\n",
      "Epoch 71/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.8444 - mae: 884.8444 - val_loss: 845.2501 - val_mae: 845.2501\n",
      "Epoch 72/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.1060 - mae: 884.1060 - val_loss: 841.7158 - val_mae: 841.7158\n",
      "Epoch 73/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 886.2159 - mae: 886.2159 - val_loss: 843.0499 - val_mae: 843.0499\n",
      "Epoch 74/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.9386 - mae: 885.9386 - val_loss: 844.4160 - val_mae: 844.4160\n",
      "Epoch 75/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.6914 - mae: 883.6914 - val_loss: 841.3654 - val_mae: 841.3654\n",
      "Epoch 76/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.6379 - mae: 885.6379 - val_loss: 843.3928 - val_mae: 843.3928\n",
      "Epoch 77/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.7839 - mae: 885.7839 - val_loss: 842.2634 - val_mae: 842.2634\n",
      "Epoch 78/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.2535 - mae: 883.2535 - val_loss: 846.3512 - val_mae: 846.3512\n",
      "Epoch 79/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.0603 - mae: 885.0603 - val_loss: 848.5637 - val_mae: 848.5637\n",
      "Epoch 80/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.9673 - mae: 885.9673 - val_loss: 843.6781 - val_mae: 843.6781\n",
      "Epoch 81/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.2542 - mae: 885.2542 - val_loss: 847.1208 - val_mae: 847.1208\n",
      "Epoch 82/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.9460 - mae: 885.9460 - val_loss: 842.5932 - val_mae: 842.5932\n",
      "Epoch 83/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.5265 - mae: 884.5265 - val_loss: 843.8665 - val_mae: 843.8665\n",
      "Epoch 84/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 886.1158 - mae: 886.1158 - val_loss: 844.8792 - val_mae: 844.8792\n",
      "Epoch 85/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.8773 - mae: 885.8773 - val_loss: 841.5518 - val_mae: 841.5518\n",
      "Epoch 86/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.1204 - mae: 884.1204 - val_loss: 847.0561 - val_mae: 847.0561\n",
      "Epoch 87/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.9072 - mae: 882.9072 - val_loss: 842.6951 - val_mae: 842.6951\n",
      "Epoch 88/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.9764 - mae: 883.9764 - val_loss: 841.0327 - val_mae: 841.0327\n",
      "Epoch 89/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.8037 - mae: 885.8037 - val_loss: 845.6668 - val_mae: 845.6668\n",
      "Epoch 90/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 886.2512 - mae: 886.2512 - val_loss: 842.9740 - val_mae: 842.9740\n",
      "Epoch 91/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.8860 - mae: 882.8860 - val_loss: 843.3621 - val_mae: 843.3621\n",
      "Epoch 92/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.9575 - mae: 880.9575 - val_loss: 843.1593 - val_mae: 843.1593\n",
      "Epoch 93/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.4815 - mae: 884.4815 - val_loss: 841.7509 - val_mae: 841.7509\n",
      "Epoch 94/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.5350 - mae: 884.5350 - val_loss: 845.9938 - val_mae: 845.9938\n",
      "Epoch 95/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 885.1989 - mae: 885.1989 - val_loss: 841.4722 - val_mae: 841.4722\n",
      "Epoch 96/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.9376 - mae: 883.9376 - val_loss: 845.2475 - val_mae: 845.2475\n",
      "Epoch 97/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.6723 - mae: 882.6723 - val_loss: 841.9983 - val_mae: 841.9983\n",
      "Epoch 98/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 886.0079 - mae: 886.0079 - val_loss: 847.3239 - val_mae: 847.3239\n",
      "Epoch 99/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.3113 - mae: 883.3113 - val_loss: 843.2866 - val_mae: 843.2866\n",
      "Epoch 100/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.9335 - mae: 883.9335 - val_loss: 840.7853 - val_mae: 840.7853\n",
      "Epoch 101/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.9570 - mae: 882.9570 - val_loss: 839.8461 - val_mae: 839.8461\n",
      "Epoch 102/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.4113 - mae: 883.4113 - val_loss: 841.0027 - val_mae: 841.0027\n",
      "Epoch 103/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.7131 - mae: 880.7131 - val_loss: 850.9277 - val_mae: 850.9277\n",
      "Epoch 104/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.9667 - mae: 882.9667 - val_loss: 839.7242 - val_mae: 839.7242\n",
      "Epoch 105/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.3049 - mae: 882.3049 - val_loss: 839.3264 - val_mae: 839.3264\n",
      "Epoch 106/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.5823 - mae: 883.5823 - val_loss: 839.5275 - val_mae: 839.5275\n",
      "Epoch 107/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.8030 - mae: 881.8030 - val_loss: 838.8160 - val_mae: 838.8160\n",
      "Epoch 108/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.9818 - mae: 881.9818 - val_loss: 840.6954 - val_mae: 840.6954\n",
      "Epoch 109/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.7695 - mae: 883.7695 - val_loss: 841.6906 - val_mae: 841.6906\n",
      "Epoch 110/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 884.0138 - mae: 884.0138 - val_loss: 838.9985 - val_mae: 838.9985\n",
      "Epoch 111/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.2188 - mae: 880.2188 - val_loss: 838.8551 - val_mae: 838.8551\n",
      "Epoch 112/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.5740 - mae: 883.5740 - val_loss: 838.8604 - val_mae: 838.8604\n",
      "Epoch 113/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.7200 - mae: 882.7200 - val_loss: 839.4615 - val_mae: 839.4615\n",
      "Epoch 114/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.2306 - mae: 882.2306 - val_loss: 840.1140 - val_mae: 840.1140\n",
      "Epoch 115/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.9109 - mae: 881.9109 - val_loss: 839.3095 - val_mae: 839.3095\n",
      "Epoch 116/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.4476 - mae: 883.4476 - val_loss: 839.2222 - val_mae: 839.2222\n",
      "Epoch 117/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.0104 - mae: 881.0104 - val_loss: 839.0549 - val_mae: 839.0549\n",
      "Epoch 118/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.2765 - mae: 880.2765 - val_loss: 838.3588 - val_mae: 838.3588\n",
      "Epoch 119/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.0024 - mae: 880.0024 - val_loss: 842.9704 - val_mae: 842.9704\n",
      "Epoch 120/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.8361 - mae: 882.8361 - val_loss: 844.5787 - val_mae: 844.5787\n",
      "Epoch 121/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.0060 - mae: 882.0060 - val_loss: 843.0112 - val_mae: 843.0112\n",
      "Epoch 122/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.7944 - mae: 880.7944 - val_loss: 838.1779 - val_mae: 838.1779\n",
      "Epoch 123/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.9677 - mae: 882.9677 - val_loss: 841.1471 - val_mae: 841.1471\n",
      "Epoch 124/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.1216 - mae: 883.1216 - val_loss: 839.4122 - val_mae: 839.4122\n",
      "Epoch 125/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.6992 - mae: 881.6992 - val_loss: 845.1891 - val_mae: 845.1891\n",
      "Epoch 126/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.4810 - mae: 879.4810 - val_loss: 838.6196 - val_mae: 838.6196\n",
      "Epoch 127/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.1572 - mae: 881.1572 - val_loss: 838.2461 - val_mae: 838.2461\n",
      "Epoch 128/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.8890 - mae: 881.8890 - val_loss: 839.1273 - val_mae: 839.1273\n",
      "Epoch 129/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.2047 - mae: 880.2047 - val_loss: 840.0726 - val_mae: 840.0726\n",
      "Epoch 130/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.7582 - mae: 881.7582 - val_loss: 838.0400 - val_mae: 838.0400\n",
      "Epoch 131/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.2286 - mae: 880.2286 - val_loss: 841.7463 - val_mae: 841.7463\n",
      "Epoch 132/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.6535 - mae: 882.6535 - val_loss: 841.4752 - val_mae: 841.4752\n",
      "Epoch 133/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.5922 - mae: 882.5922 - val_loss: 838.1591 - val_mae: 838.1591\n",
      "Epoch 134/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.2933 - mae: 881.2933 - val_loss: 837.4904 - val_mae: 837.4904\n",
      "Epoch 135/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.6635 - mae: 876.6635 - val_loss: 840.2908 - val_mae: 840.2908\n",
      "Epoch 136/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 883.2944 - mae: 883.2944 - val_loss: 838.2431 - val_mae: 838.2431\n",
      "Epoch 137/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.2127 - mae: 879.2127 - val_loss: 839.5004 - val_mae: 839.5004\n",
      "Epoch 138/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 882.0513 - mae: 882.0513 - val_loss: 840.7994 - val_mae: 840.7994\n",
      "Epoch 139/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.0099 - mae: 880.0099 - val_loss: 838.0531 - val_mae: 838.0531\n",
      "Epoch 140/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.4920 - mae: 881.4920 - val_loss: 840.0373 - val_mae: 840.0373\n",
      "Epoch 141/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.4828 - mae: 878.4828 - val_loss: 838.7768 - val_mae: 838.7768\n",
      "Epoch 142/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.1682 - mae: 881.1682 - val_loss: 838.0632 - val_mae: 838.0632\n",
      "Epoch 143/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.6525 - mae: 881.6525 - val_loss: 838.9182 - val_mae: 838.9182\n",
      "Epoch 144/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.9750 - mae: 880.9750 - val_loss: 839.4755 - val_mae: 839.4755\n",
      "Epoch 145/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.4110 - mae: 879.4110 - val_loss: 837.7283 - val_mae: 837.7283\n",
      "Epoch 146/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.2595 - mae: 881.2595 - val_loss: 838.8180 - val_mae: 838.8180\n",
      "Epoch 147/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.5706 - mae: 878.5706 - val_loss: 840.5745 - val_mae: 840.5745\n",
      "Epoch 148/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.8202 - mae: 880.8202 - val_loss: 837.5730 - val_mae: 837.5730\n",
      "Epoch 149/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 881.0719 - mae: 881.0719 - val_loss: 844.1353 - val_mae: 844.1353\n",
      "Epoch 150/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.2148 - mae: 877.2148 - val_loss: 837.4616 - val_mae: 837.4616\n",
      "Epoch 151/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.8929 - mae: 880.8929 - val_loss: 837.7325 - val_mae: 837.7325\n",
      "Epoch 152/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.4904 - mae: 878.4904 - val_loss: 838.1501 - val_mae: 838.1501\n",
      "Epoch 153/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.8338 - mae: 877.8338 - val_loss: 846.3468 - val_mae: 846.3468\n",
      "Epoch 154/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.2228 - mae: 880.2228 - val_loss: 837.7343 - val_mae: 837.7343\n",
      "Epoch 155/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.8577 - mae: 878.8577 - val_loss: 839.2484 - val_mae: 839.2484\n",
      "Epoch 156/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.6293 - mae: 879.6293 - val_loss: 837.5879 - val_mae: 837.5879\n",
      "Epoch 157/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.6497 - mae: 878.6497 - val_loss: 840.3975 - val_mae: 840.3975\n",
      "Epoch 158/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.4468 - mae: 878.4468 - val_loss: 843.8489 - val_mae: 843.8489\n",
      "Epoch 159/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 876.8352 - mae: 876.8352 - val_loss: 837.6127 - val_mae: 837.6127\n",
      "Epoch 160/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.1213 - mae: 878.1213 - val_loss: 840.6221 - val_mae: 840.6221\n",
      "Epoch 161/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 878.9167 - mae: 878.9167 - val_loss: 840.1039 - val_mae: 840.1039\n",
      "Epoch 162/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 879.5372 - mae: 879.5372 - val_loss: 837.3401 - val_mae: 837.3401\n",
      "Epoch 163/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 877.9032 - mae: 877.9032 - val_loss: 839.8633 - val_mae: 839.8633\n",
      "Epoch 164/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 878.1102 - mae: 878.1102 - val_loss: 839.9152 - val_mae: 839.9152\n",
      "Epoch 165/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.8755 - mae: 878.8755 - val_loss: 840.0793 - val_mae: 840.0793\n",
      "Epoch 166/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 877.7944 - mae: 877.7944 - val_loss: 837.3763 - val_mae: 837.3763\n",
      "Epoch 167/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 879.7751 - mae: 879.7751 - val_loss: 842.0873 - val_mae: 842.0873\n",
      "Epoch 168/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.4465 - mae: 877.4465 - val_loss: 839.7186 - val_mae: 839.7186\n",
      "Epoch 169/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 878.9894 - mae: 878.9894 - val_loss: 837.2029 - val_mae: 837.2029\n",
      "Epoch 170/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 876.8621 - mae: 876.8621 - val_loss: 838.1536 - val_mae: 838.1536\n",
      "Epoch 171/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 877.8503 - mae: 877.8503 - val_loss: 838.4203 - val_mae: 838.4203\n",
      "Epoch 172/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.7153 - mae: 878.7153 - val_loss: 844.1349 - val_mae: 844.1349\n",
      "Epoch 173/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.7723 - mae: 878.7723 - val_loss: 838.8958 - val_mae: 838.8958\n",
      "Epoch 174/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.8065 - mae: 877.8065 - val_loss: 838.9694 - val_mae: 838.9694\n",
      "Epoch 175/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 877.4020 - mae: 877.4020 - val_loss: 837.2378 - val_mae: 837.2378\n",
      "Epoch 176/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 878.2566 - mae: 878.2566 - val_loss: 839.4309 - val_mae: 839.4309\n",
      "Epoch 177/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 880.1149 - mae: 880.1149 - val_loss: 837.4370 - val_mae: 837.4370\n",
      "Epoch 178/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 880.1182 - mae: 880.1182 - val_loss: 839.2292 - val_mae: 839.2292\n",
      "Epoch 179/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 879.0618 - mae: 879.0618 - val_loss: 837.5234 - val_mae: 837.5234\n",
      "Epoch 180/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 877.8015 - mae: 877.8015 - val_loss: 843.2908 - val_mae: 843.2908\n",
      "Epoch 181/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.7781 - mae: 879.7781 - val_loss: 836.7936 - val_mae: 836.7936\n",
      "Epoch 182/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 877.2976 - mae: 877.2976 - val_loss: 839.0026 - val_mae: 839.0026\n",
      "Epoch 183/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 878.7878 - mae: 878.7878 - val_loss: 840.7605 - val_mae: 840.7605\n",
      "Epoch 184/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 877.5226 - mae: 877.5226 - val_loss: 839.3127 - val_mae: 839.3127\n",
      "Epoch 185/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 877.1462 - mae: 877.1462 - val_loss: 841.5063 - val_mae: 841.5063\n",
      "Epoch 186/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 878.9415 - mae: 878.9415 - val_loss: 838.6948 - val_mae: 838.6948\n",
      "Epoch 187/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 877.0601 - mae: 877.0601 - val_loss: 839.3995 - val_mae: 839.3995\n",
      "Epoch 188/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 878.9991 - mae: 878.9991 - val_loss: 839.8473 - val_mae: 839.8473\n",
      "Epoch 189/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 880.2089 - mae: 880.2089 - val_loss: 841.1190 - val_mae: 841.1190\n",
      "Epoch 190/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 877.3585 - mae: 877.3585 - val_loss: 837.5248 - val_mae: 837.5248\n",
      "Epoch 191/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 877.5762 - mae: 877.5762 - val_loss: 838.7095 - val_mae: 838.7095\n",
      "Epoch 192/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 875.5958 - mae: 875.5958 - val_loss: 840.0887 - val_mae: 840.0887\n",
      "Epoch 193/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 878.0049 - mae: 878.0049 - val_loss: 838.4818 - val_mae: 838.4818\n",
      "Epoch 194/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 876.3358 - mae: 876.3358 - val_loss: 840.0827 - val_mae: 840.0827\n",
      "Epoch 195/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 875.9189 - mae: 875.9189 - val_loss: 837.8696 - val_mae: 837.8696\n",
      "Epoch 196/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 876.0428 - mae: 876.0428 - val_loss: 837.2868 - val_mae: 837.2868\n",
      "Epoch 197/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 877.6002 - mae: 877.6002 - val_loss: 838.2182 - val_mae: 838.2182\n",
      "Epoch 198/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 877.8749 - mae: 877.8749 - val_loss: 838.2205 - val_mae: 838.2205\n",
      "Epoch 199/200\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 877.2689 - mae: 877.2689 - val_loss: 837.3208 - val_mae: 837.3208\n",
      "Epoch 200/200\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 879.6521 - mae: 879.6521 - val_loss: 837.2150 - val_mae: 837.2150\n",
      "Fold 5 - Loss: 837.2150, MAE: 837.2150\n",
      "236/236 [==============================] - 0s 486us/step\n",
      "\n",
      "Cross Validation 5-Fold 결과:\n",
      "MAE 평균: 852.5188, 표준편차: 9.3596\n",
      "\n",
      "[각 Fold별 평균 성능]\n",
      "mae : 852.5188421386717\n",
      "mape : 0.34403999999999996\n",
      "mse : 1222869.59758\n",
      "rmse : 1105.7597400000002\n",
      "295/295 [==============================] - 0s 446us/step\n",
      "[Test results]\n",
      "MAPE: 0.3466\n",
      "MAE: 850.1513\n",
      "MSE: 1.2018e+06\n",
      "MSE: 1201797.7804\n",
      "RMSE: 1096.2654\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "# 3-Fold Cross Validation\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=7)\n",
    "mae_per_fold = []\n",
    "mape_per_fold = []\n",
    "mse_per_fold = []\n",
    "rmse_per_fold = []\n",
    "\n",
    "fold_no = 1\n",
    "for train_index, val_index in kfold.split(X_train2):\n",
    "    print(f\"Fold {fold_no} / 5\")\n",
    "    \n",
    "    # 데이터 분할\n",
    "    X_fold_train, X_fold_val = X_train2[train_index], X_train2[val_index]\n",
    "    y_fold_train, y_fold_val = y_train2.iloc[train_index], y_train2.iloc[val_index]\n",
    "    \n",
    "    # 모델 정의\n",
    "    model2 = Sequential([\n",
    "        Dense(128, activation='relu', input_shape=(X_fold_train.shape[1],)),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    \n",
    "    # 모델 컴파일\n",
    "    model2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='mae',\n",
    "                  metrics=['mae'])\n",
    "    \n",
    "    # 학습\n",
    "    with tf.device(\"/device:GPU:0\"):\n",
    "        model2.fit(X_fold_train, y_fold_train,\n",
    "                  epochs=200, \n",
    "                  batch_size=128, \n",
    "                  validation_data=(X_fold_val, y_fold_val), \n",
    "                  verbose=1)\n",
    "        \n",
    "        # 폴드별 평가\n",
    "        loss, mae = model2.evaluate(X_fold_val, y_fold_val, verbose=0)\n",
    "        print(f\"Fold {fold_no} - Loss: {loss:.4f}, MAE: {mae:.4f}\")\n",
    "        mae_per_fold.append(mae)\n",
    "    \n",
    "    fold_pred = model2.predict(X_fold_val)\n",
    "    mae = round(mean_absolute_error(y_fold_val, fold_pred), 4)\n",
    "    mape = round(mean_absolute_percentage_error(y_fold_val, fold_pred), 4)\n",
    "    mse = round(mean_squared_error(y_fold_val, fold_pred), 4)\n",
    "    rmse = round(root_mean_squared_error(y_fold_val, fold_pred), 4)\n",
    "    mae_per_fold.append(mae)\n",
    "    mape_per_fold.append(mape)\n",
    "    mse_per_fold.append(mse)\n",
    "    rmse_per_fold.append(rmse)\n",
    "    \n",
    "    fold_no += 1\n",
    "\n",
    "# 평균 MAE와 표준편차 계산\n",
    "print(f\"\\nCross Validation 5-Fold 결과:\")\n",
    "print(f\"MAE 평균: {np.mean(mae_per_fold):.4f}, 표준편차: {np.std(mae_per_fold):.4f}\\n\")\n",
    "\n",
    "print(\"[5-Fold 평균 성능]\")\n",
    "print(f\"mae : {np.mean(mae_per_fold)}\")\n",
    "print(f\"mape : {np.mean(mape_per_fold)}\")\n",
    "print(f\"mse : {np.mean(mse_per_fold)}\")\n",
    "print(f\"rmse : {np.mean(rmse_per_fold)}\")\n",
    "# 최종 평가 (test set 사용)\n",
    "ensemble_pred_2 = model2.predict(X_test2)\n",
    "print_test_results2(y_test2, ensemble_pred_2)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "IEEE_Access",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
